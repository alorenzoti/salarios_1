2023-03-03 16:25:56,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 16:25:56,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 16:25:56,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 16:25:56,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 16:25:57,717:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-03 16:26:30,338:INFO:PyCaret ClassificationExperiment
2023-03-03 16:26:30,339:INFO:Logging name: clf-default-name
2023-03-03 16:26:30,339:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-03 16:26:30,339:INFO:version 3.0.0.rc9
2023-03-03 16:26:30,340:INFO:Initializing setup()
2023-03-03 16:26:30,340:INFO:self.USI: f441
2023-03-03 16:26:30,340:INFO:self._variable_keys: {'gpu_n_jobs_param', 'pipeline', 'memory', 'data', 'fold_generator', 'y', 'X_test', 'target_param', '_ml_usecase', 'X_train', 'fold_groups_param', 'fix_imbalance', 'y_test', 'seed', 'gpu_param', 'exp_id', 'y_train', 'fold_shuffle_param', 'log_plots_param', '_available_plots', 'n_jobs_param', 'html_param', 'logging_param', 'USI', 'idx', 'X', 'exp_name_log', 'is_multiclass'}
2023-03-03 16:26:30,340:INFO:Checking environment
2023-03-03 16:26:30,340:INFO:python_version: 3.9.13
2023-03-03 16:26:30,341:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-03 16:26:30,341:INFO:machine: AMD64
2023-03-03 16:26:30,341:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-03 16:26:30,341:INFO:Memory: svmem(total=17009516544, available=3393830912, percent=80.0, used=13615685632, free=3393830912)
2023-03-03 16:26:30,341:INFO:Physical Core: 4
2023-03-03 16:26:30,341:INFO:Logical Core: 8
2023-03-03 16:26:30,342:INFO:Checking libraries
2023-03-03 16:26:30,342:INFO:System:
2023-03-03 16:26:30,342:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-03 16:26:30,342:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-03 16:26:30,342:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-03 16:26:30,342:INFO:PyCaret required dependencies:
2023-03-03 16:26:30,342:INFO:                 pip: 22.2.2
2023-03-03 16:26:30,342:INFO:          setuptools: 63.4.1
2023-03-03 16:26:30,342:INFO:             pycaret: 3.0.0rc9
2023-03-03 16:26:30,343:INFO:             IPython: 7.31.1
2023-03-03 16:26:30,343:INFO:          ipywidgets: 7.6.5
2023-03-03 16:26:30,343:INFO:                tqdm: 4.64.1
2023-03-03 16:26:30,343:INFO:               numpy: 1.21.5
2023-03-03 16:26:30,343:INFO:              pandas: 1.4.4
2023-03-03 16:26:30,343:INFO:              jinja2: 2.11.3
2023-03-03 16:26:30,343:INFO:               scipy: 1.9.1
2023-03-03 16:26:30,343:INFO:              joblib: 1.2.0
2023-03-03 16:26:30,343:INFO:             sklearn: 1.0.2
2023-03-03 16:26:30,343:INFO:                pyod: 1.0.7
2023-03-03 16:26:30,344:INFO:            imblearn: 0.10.1
2023-03-03 16:26:30,344:INFO:   category_encoders: 2.6.0
2023-03-03 16:26:30,344:INFO:            lightgbm: 3.3.5
2023-03-03 16:26:30,344:INFO:               numba: 0.55.1
2023-03-03 16:26:30,344:INFO:            requests: 2.28.1
2023-03-03 16:26:30,344:INFO:          matplotlib: 3.5.2
2023-03-03 16:26:30,344:INFO:          scikitplot: 0.3.7
2023-03-03 16:26:30,344:INFO:         yellowbrick: 1.5
2023-03-03 16:26:30,344:INFO:              plotly: 5.9.0
2023-03-03 16:26:30,344:INFO:             kaleido: 0.2.1
2023-03-03 16:26:30,345:INFO:         statsmodels: 0.13.2
2023-03-03 16:26:30,345:INFO:              sktime: 0.16.1
2023-03-03 16:26:30,345:INFO:               tbats: 1.1.2
2023-03-03 16:26:30,345:INFO:            pmdarima: 2.0.2
2023-03-03 16:26:30,345:INFO:              psutil: 5.9.0
2023-03-03 16:26:30,346:INFO:PyCaret optional dependencies:
2023-03-03 16:26:30,393:INFO:                shap: Not installed
2023-03-03 16:26:30,393:INFO:           interpret: Not installed
2023-03-03 16:26:30,393:INFO:                umap: Not installed
2023-03-03 16:26:30,393:INFO:    pandas_profiling: Not installed
2023-03-03 16:26:30,395:INFO:  explainerdashboard: Not installed
2023-03-03 16:26:30,395:INFO:             autoviz: Not installed
2023-03-03 16:26:30,395:INFO:           fairlearn: Not installed
2023-03-03 16:26:30,395:INFO:             xgboost: Not installed
2023-03-03 16:26:30,395:INFO:            catboost: Not installed
2023-03-03 16:26:30,395:INFO:              kmodes: Not installed
2023-03-03 16:26:30,395:INFO:             mlxtend: Not installed
2023-03-03 16:26:30,395:INFO:       statsforecast: Not installed
2023-03-03 16:26:30,395:INFO:        tune_sklearn: Not installed
2023-03-03 16:26:30,395:INFO:                 ray: Not installed
2023-03-03 16:26:30,395:INFO:            hyperopt: Not installed
2023-03-03 16:26:30,395:INFO:              optuna: Not installed
2023-03-03 16:26:30,395:INFO:               skopt: Not installed
2023-03-03 16:26:30,395:INFO:              mlflow: Not installed
2023-03-03 16:26:30,395:INFO:              gradio: Not installed
2023-03-03 16:26:30,395:INFO:             fastapi: Not installed
2023-03-03 16:26:30,395:INFO:             uvicorn: Not installed
2023-03-03 16:26:30,395:INFO:              m2cgen: Not installed
2023-03-03 16:26:30,395:INFO:           evidently: Not installed
2023-03-03 16:26:30,395:INFO:               fugue: Not installed
2023-03-03 16:26:30,395:INFO:           streamlit: Not installed
2023-03-03 16:26:30,395:INFO:             prophet: Not installed
2023-03-03 16:26:30,395:INFO:None
2023-03-03 16:26:30,396:INFO:Set up data.
2023-03-03 16:27:14,027:WARNING:C:\Users\Alvaro\AppData\Local\Temp\ipykernel_15312\109572210.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  outliers = outliers.append(results)

2023-03-03 16:27:14,035:WARNING:C:\Users\Alvaro\AppData\Local\Temp\ipykernel_15312\109572210.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  outliers = outliers.append(results)

2023-03-03 16:27:14,042:WARNING:C:\Users\Alvaro\AppData\Local\Temp\ipykernel_15312\109572210.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  outliers = outliers.append(results)

2023-03-03 16:27:14,047:WARNING:C:\Users\Alvaro\AppData\Local\Temp\ipykernel_15312\109572210.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  outliers = outliers.append(results)

2023-03-03 16:27:28,042:INFO:PyCaret ClassificationExperiment
2023-03-03 16:27:28,055:INFO:Logging name: clf-default-name
2023-03-03 16:27:28,055:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-03 16:27:28,056:INFO:version 3.0.0.rc9
2023-03-03 16:27:28,056:INFO:Initializing setup()
2023-03-03 16:27:28,056:INFO:self.USI: 481d
2023-03-03 16:27:28,056:INFO:self._variable_keys: {'gpu_n_jobs_param', 'pipeline', 'memory', 'data', 'fold_generator', 'y', 'X_test', 'target_param', '_ml_usecase', 'X_train', 'fold_groups_param', 'fix_imbalance', 'y_test', 'seed', 'gpu_param', 'exp_id', 'y_train', 'fold_shuffle_param', 'log_plots_param', '_available_plots', 'n_jobs_param', 'html_param', 'logging_param', 'USI', 'idx', 'X', 'exp_name_log', 'is_multiclass'}
2023-03-03 16:27:28,056:INFO:Checking environment
2023-03-03 16:27:28,056:INFO:python_version: 3.9.13
2023-03-03 16:27:28,056:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-03 16:27:28,056:INFO:machine: AMD64
2023-03-03 16:27:28,057:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-03 16:27:28,057:INFO:Memory: svmem(total=17009516544, available=3362242560, percent=80.2, used=13647273984, free=3362242560)
2023-03-03 16:27:28,057:INFO:Physical Core: 4
2023-03-03 16:27:28,057:INFO:Logical Core: 8
2023-03-03 16:27:28,057:INFO:Checking libraries
2023-03-03 16:27:28,057:INFO:System:
2023-03-03 16:27:28,058:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-03 16:27:28,058:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-03 16:27:28,058:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-03 16:27:28,058:INFO:PyCaret required dependencies:
2023-03-03 16:27:28,058:INFO:                 pip: 22.2.2
2023-03-03 16:27:28,059:INFO:          setuptools: 63.4.1
2023-03-03 16:27:28,059:INFO:             pycaret: 3.0.0rc9
2023-03-03 16:27:28,059:INFO:             IPython: 7.31.1
2023-03-03 16:27:28,059:INFO:          ipywidgets: 7.6.5
2023-03-03 16:27:28,059:INFO:                tqdm: 4.64.1
2023-03-03 16:27:28,059:INFO:               numpy: 1.21.5
2023-03-03 16:27:28,059:INFO:              pandas: 1.4.4
2023-03-03 16:27:28,060:INFO:              jinja2: 2.11.3
2023-03-03 16:27:28,060:INFO:               scipy: 1.9.1
2023-03-03 16:27:28,060:INFO:              joblib: 1.2.0
2023-03-03 16:27:28,060:INFO:             sklearn: 1.0.2
2023-03-03 16:27:28,061:INFO:                pyod: 1.0.7
2023-03-03 16:27:28,061:INFO:            imblearn: 0.10.1
2023-03-03 16:27:28,061:INFO:   category_encoders: 2.6.0
2023-03-03 16:27:28,062:INFO:            lightgbm: 3.3.5
2023-03-03 16:27:28,062:INFO:               numba: 0.55.1
2023-03-03 16:27:28,062:INFO:            requests: 2.28.1
2023-03-03 16:27:28,062:INFO:          matplotlib: 3.5.2
2023-03-03 16:27:28,062:INFO:          scikitplot: 0.3.7
2023-03-03 16:27:28,063:INFO:         yellowbrick: 1.5
2023-03-03 16:27:28,063:INFO:              plotly: 5.9.0
2023-03-03 16:27:28,063:INFO:             kaleido: 0.2.1
2023-03-03 16:27:28,063:INFO:         statsmodels: 0.13.2
2023-03-03 16:27:28,064:INFO:              sktime: 0.16.1
2023-03-03 16:27:28,064:INFO:               tbats: 1.1.2
2023-03-03 16:27:28,064:INFO:            pmdarima: 2.0.2
2023-03-03 16:27:28,064:INFO:              psutil: 5.9.0
2023-03-03 16:27:28,064:INFO:PyCaret optional dependencies:
2023-03-03 16:27:28,065:INFO:                shap: Not installed
2023-03-03 16:27:28,065:INFO:           interpret: Not installed
2023-03-03 16:27:28,066:INFO:                umap: Not installed
2023-03-03 16:27:28,066:INFO:    pandas_profiling: Not installed
2023-03-03 16:27:28,066:INFO:  explainerdashboard: Not installed
2023-03-03 16:27:28,066:INFO:             autoviz: Not installed
2023-03-03 16:27:28,066:INFO:           fairlearn: Not installed
2023-03-03 16:27:28,067:INFO:             xgboost: Not installed
2023-03-03 16:27:28,067:INFO:            catboost: Not installed
2023-03-03 16:27:28,067:INFO:              kmodes: Not installed
2023-03-03 16:27:28,067:INFO:             mlxtend: Not installed
2023-03-03 16:27:28,067:INFO:       statsforecast: Not installed
2023-03-03 16:27:28,068:INFO:        tune_sklearn: Not installed
2023-03-03 16:27:28,068:INFO:                 ray: Not installed
2023-03-03 16:27:28,068:INFO:            hyperopt: Not installed
2023-03-03 16:27:28,068:INFO:              optuna: Not installed
2023-03-03 16:27:28,068:INFO:               skopt: Not installed
2023-03-03 16:27:28,068:INFO:              mlflow: Not installed
2023-03-03 16:27:28,069:INFO:              gradio: Not installed
2023-03-03 16:27:28,069:INFO:             fastapi: Not installed
2023-03-03 16:27:28,069:INFO:             uvicorn: Not installed
2023-03-03 16:27:28,069:INFO:              m2cgen: Not installed
2023-03-03 16:27:28,069:INFO:           evidently: Not installed
2023-03-03 16:27:28,069:INFO:               fugue: Not installed
2023-03-03 16:27:28,070:INFO:           streamlit: Not installed
2023-03-03 16:27:28,070:INFO:             prophet: Not installed
2023-03-03 16:27:28,070:INFO:None
2023-03-03 16:27:28,070:INFO:Set up data.
2023-03-03 16:27:28,096:INFO:Set up train/test split.
2023-03-03 16:29:51,398:INFO:PyCaret ClassificationExperiment
2023-03-03 16:29:51,401:INFO:Logging name: clf-default-name
2023-03-03 16:29:51,401:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-03 16:29:51,401:INFO:version 3.0.0.rc9
2023-03-03 16:29:51,401:INFO:Initializing setup()
2023-03-03 16:29:51,401:INFO:self.USI: cb37
2023-03-03 16:29:51,401:INFO:self._variable_keys: {'gpu_n_jobs_param', 'pipeline', 'memory', 'data', 'fold_generator', 'y', 'X_test', 'target_param', '_ml_usecase', 'X_train', 'fold_groups_param', 'fix_imbalance', 'y_test', 'seed', 'gpu_param', 'exp_id', 'y_train', 'fold_shuffle_param', 'log_plots_param', '_available_plots', 'n_jobs_param', 'html_param', 'logging_param', 'USI', 'idx', 'X', 'exp_name_log', 'is_multiclass'}
2023-03-03 16:29:51,401:INFO:Checking environment
2023-03-03 16:29:51,401:INFO:python_version: 3.9.13
2023-03-03 16:29:51,401:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-03 16:29:51,401:INFO:machine: AMD64
2023-03-03 16:29:51,402:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-03 16:29:51,402:INFO:Memory: svmem(total=17009516544, available=3346968576, percent=80.3, used=13662547968, free=3346968576)
2023-03-03 16:29:51,402:INFO:Physical Core: 4
2023-03-03 16:29:51,403:INFO:Logical Core: 8
2023-03-03 16:29:51,403:INFO:Checking libraries
2023-03-03 16:29:51,403:INFO:System:
2023-03-03 16:29:51,403:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-03 16:29:51,403:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-03 16:29:51,403:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-03 16:29:51,403:INFO:PyCaret required dependencies:
2023-03-03 16:29:51,403:INFO:                 pip: 22.2.2
2023-03-03 16:29:51,403:INFO:          setuptools: 63.4.1
2023-03-03 16:29:51,403:INFO:             pycaret: 3.0.0rc9
2023-03-03 16:29:51,403:INFO:             IPython: 7.31.1
2023-03-03 16:29:51,403:INFO:          ipywidgets: 7.6.5
2023-03-03 16:29:51,403:INFO:                tqdm: 4.64.1
2023-03-03 16:29:51,403:INFO:               numpy: 1.21.5
2023-03-03 16:29:51,403:INFO:              pandas: 1.4.4
2023-03-03 16:29:51,403:INFO:              jinja2: 2.11.3
2023-03-03 16:29:51,403:INFO:               scipy: 1.9.1
2023-03-03 16:29:51,403:INFO:              joblib: 1.2.0
2023-03-03 16:29:51,403:INFO:             sklearn: 1.0.2
2023-03-03 16:29:51,404:INFO:                pyod: 1.0.7
2023-03-03 16:29:51,404:INFO:            imblearn: 0.10.1
2023-03-03 16:29:51,404:INFO:   category_encoders: 2.6.0
2023-03-03 16:29:51,404:INFO:            lightgbm: 3.3.5
2023-03-03 16:29:51,404:INFO:               numba: 0.55.1
2023-03-03 16:29:51,404:INFO:            requests: 2.28.1
2023-03-03 16:29:51,404:INFO:          matplotlib: 3.5.2
2023-03-03 16:29:51,404:INFO:          scikitplot: 0.3.7
2023-03-03 16:29:51,404:INFO:         yellowbrick: 1.5
2023-03-03 16:29:51,404:INFO:              plotly: 5.9.0
2023-03-03 16:29:51,404:INFO:             kaleido: 0.2.1
2023-03-03 16:29:51,405:INFO:         statsmodels: 0.13.2
2023-03-03 16:29:51,405:INFO:              sktime: 0.16.1
2023-03-03 16:29:51,405:INFO:               tbats: 1.1.2
2023-03-03 16:29:51,405:INFO:            pmdarima: 2.0.2
2023-03-03 16:29:51,405:INFO:              psutil: 5.9.0
2023-03-03 16:29:51,406:INFO:PyCaret optional dependencies:
2023-03-03 16:29:51,406:INFO:                shap: Not installed
2023-03-03 16:29:51,406:INFO:           interpret: Not installed
2023-03-03 16:29:51,406:INFO:                umap: Not installed
2023-03-03 16:29:51,406:INFO:    pandas_profiling: Not installed
2023-03-03 16:29:51,406:INFO:  explainerdashboard: Not installed
2023-03-03 16:29:51,406:INFO:             autoviz: Not installed
2023-03-03 16:29:51,406:INFO:           fairlearn: Not installed
2023-03-03 16:29:51,406:INFO:             xgboost: Not installed
2023-03-03 16:29:51,406:INFO:            catboost: Not installed
2023-03-03 16:29:51,406:INFO:              kmodes: Not installed
2023-03-03 16:29:51,406:INFO:             mlxtend: Not installed
2023-03-03 16:29:51,406:INFO:       statsforecast: Not installed
2023-03-03 16:29:51,406:INFO:        tune_sklearn: Not installed
2023-03-03 16:29:51,406:INFO:                 ray: Not installed
2023-03-03 16:29:51,406:INFO:            hyperopt: Not installed
2023-03-03 16:29:51,407:INFO:              optuna: Not installed
2023-03-03 16:29:51,408:INFO:               skopt: Not installed
2023-03-03 16:29:51,408:INFO:              mlflow: Not installed
2023-03-03 16:29:51,408:INFO:              gradio: Not installed
2023-03-03 16:29:51,408:INFO:             fastapi: Not installed
2023-03-03 16:29:51,408:INFO:             uvicorn: Not installed
2023-03-03 16:29:51,408:INFO:              m2cgen: Not installed
2023-03-03 16:29:51,408:INFO:           evidently: Not installed
2023-03-03 16:29:51,408:INFO:               fugue: Not installed
2023-03-03 16:29:51,408:INFO:           streamlit: Not installed
2023-03-03 16:29:51,408:INFO:             prophet: Not installed
2023-03-03 16:29:51,408:INFO:None
2023-03-03 16:29:51,408:INFO:Set up data.
2023-03-03 16:29:51,426:INFO:Set up train/test split.
2023-03-03 16:35:30,037:INFO:PyCaret ClassificationExperiment
2023-03-03 16:35:30,038:INFO:Logging name: clf-default-name
2023-03-03 16:35:30,038:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-03 16:35:30,038:INFO:version 3.0.0.rc9
2023-03-03 16:35:30,038:INFO:Initializing setup()
2023-03-03 16:35:30,038:INFO:self.USI: a025
2023-03-03 16:35:30,038:INFO:self._variable_keys: {'gpu_n_jobs_param', 'pipeline', 'memory', 'data', 'fold_generator', 'y', 'X_test', 'target_param', '_ml_usecase', 'X_train', 'fold_groups_param', 'fix_imbalance', 'y_test', 'seed', 'gpu_param', 'exp_id', 'y_train', 'fold_shuffle_param', 'log_plots_param', '_available_plots', 'n_jobs_param', 'html_param', 'logging_param', 'USI', 'idx', 'X', 'exp_name_log', 'is_multiclass'}
2023-03-03 16:35:30,039:INFO:Checking environment
2023-03-03 16:35:30,039:INFO:python_version: 3.9.13
2023-03-03 16:35:30,039:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-03 16:35:30,039:INFO:machine: AMD64
2023-03-03 16:35:30,040:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-03 16:35:30,040:INFO:Memory: svmem(total=17009516544, available=4446887936, percent=73.9, used=12562628608, free=4446887936)
2023-03-03 16:35:30,040:INFO:Physical Core: 4
2023-03-03 16:35:30,040:INFO:Logical Core: 8
2023-03-03 16:35:30,041:INFO:Checking libraries
2023-03-03 16:35:30,041:INFO:System:
2023-03-03 16:35:30,041:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-03 16:35:30,041:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-03 16:35:30,042:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-03 16:35:30,042:INFO:PyCaret required dependencies:
2023-03-03 16:35:30,042:INFO:                 pip: 22.2.2
2023-03-03 16:35:30,042:INFO:          setuptools: 63.4.1
2023-03-03 16:35:30,042:INFO:             pycaret: 3.0.0rc9
2023-03-03 16:35:30,042:INFO:             IPython: 7.31.1
2023-03-03 16:35:30,042:INFO:          ipywidgets: 7.6.5
2023-03-03 16:35:30,043:INFO:                tqdm: 4.64.1
2023-03-03 16:35:30,043:INFO:               numpy: 1.21.5
2023-03-03 16:35:30,043:INFO:              pandas: 1.4.4
2023-03-03 16:35:30,043:INFO:              jinja2: 2.11.3
2023-03-03 16:35:30,043:INFO:               scipy: 1.9.1
2023-03-03 16:35:30,043:INFO:              joblib: 1.2.0
2023-03-03 16:35:30,043:INFO:             sklearn: 1.0.2
2023-03-03 16:35:30,044:INFO:                pyod: 1.0.7
2023-03-03 16:35:30,044:INFO:            imblearn: 0.10.1
2023-03-03 16:35:30,044:INFO:   category_encoders: 2.6.0
2023-03-03 16:35:30,044:INFO:            lightgbm: 3.3.5
2023-03-03 16:35:30,045:INFO:               numba: 0.55.1
2023-03-03 16:35:30,045:INFO:            requests: 2.28.1
2023-03-03 16:35:30,045:INFO:          matplotlib: 3.5.2
2023-03-03 16:35:30,045:INFO:          scikitplot: 0.3.7
2023-03-03 16:35:30,045:INFO:         yellowbrick: 1.5
2023-03-03 16:35:30,046:INFO:              plotly: 5.9.0
2023-03-03 16:35:30,046:INFO:             kaleido: 0.2.1
2023-03-03 16:35:30,046:INFO:         statsmodels: 0.13.2
2023-03-03 16:35:30,046:INFO:              sktime: 0.16.1
2023-03-03 16:35:30,046:INFO:               tbats: 1.1.2
2023-03-03 16:35:30,046:INFO:            pmdarima: 2.0.2
2023-03-03 16:35:30,047:INFO:              psutil: 5.9.0
2023-03-03 16:35:30,047:INFO:PyCaret optional dependencies:
2023-03-03 16:35:30,047:INFO:                shap: Not installed
2023-03-03 16:35:30,047:INFO:           interpret: Not installed
2023-03-03 16:35:30,047:INFO:                umap: Not installed
2023-03-03 16:35:30,047:INFO:    pandas_profiling: Not installed
2023-03-03 16:35:30,048:INFO:  explainerdashboard: Not installed
2023-03-03 16:35:30,048:INFO:             autoviz: Not installed
2023-03-03 16:35:30,048:INFO:           fairlearn: Not installed
2023-03-03 16:35:30,048:INFO:             xgboost: Not installed
2023-03-03 16:35:30,048:INFO:            catboost: Not installed
2023-03-03 16:35:30,048:INFO:              kmodes: Not installed
2023-03-03 16:35:30,048:INFO:             mlxtend: Not installed
2023-03-03 16:35:30,049:INFO:       statsforecast: Not installed
2023-03-03 16:35:30,049:INFO:        tune_sklearn: Not installed
2023-03-03 16:35:30,049:INFO:                 ray: Not installed
2023-03-03 16:35:30,049:INFO:            hyperopt: Not installed
2023-03-03 16:35:30,049:INFO:              optuna: Not installed
2023-03-03 16:35:30,049:INFO:               skopt: Not installed
2023-03-03 16:35:30,049:INFO:              mlflow: Not installed
2023-03-03 16:35:30,049:INFO:              gradio: Not installed
2023-03-03 16:35:30,049:INFO:             fastapi: Not installed
2023-03-03 16:35:30,050:INFO:             uvicorn: Not installed
2023-03-03 16:35:30,050:INFO:              m2cgen: Not installed
2023-03-03 16:35:30,050:INFO:           evidently: Not installed
2023-03-03 16:35:30,050:INFO:               fugue: Not installed
2023-03-03 16:35:30,050:INFO:           streamlit: Not installed
2023-03-03 16:35:30,050:INFO:             prophet: Not installed
2023-03-03 16:35:30,051:INFO:None
2023-03-03 16:35:30,051:INFO:Set up data.
2023-03-03 16:35:30,071:INFO:Set up train/test split.
2023-03-03 17:01:04,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 17:01:04,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 17:01:04,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 17:01:04,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-03 17:01:05,664:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-03 17:01:33,277:INFO:PyCaret ClassificationExperiment
2023-03-03 17:01:33,278:INFO:Logging name: clf-default-name
2023-03-03 17:01:33,278:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-03 17:01:33,278:INFO:version 3.0.0.rc9
2023-03-03 17:01:33,278:INFO:Initializing setup()
2023-03-03 17:01:33,278:INFO:self.USI: 0480
2023-03-03 17:01:33,278:INFO:self._variable_keys: {'logging_param', 'exp_name_log', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'idx', 'y', 'target_param', 'fold_groups_param', 'X_test', 'y_test', 'memory', 'data', 'log_plots_param', 'gpu_param', 'X', 'y_train', 'USI', 'seed', 'X_train', 'is_multiclass', '_available_plots', 'fold_generator', '_ml_usecase', 'fold_shuffle_param', 'fix_imbalance', 'n_jobs_param'}
2023-03-03 17:01:33,278:INFO:Checking environment
2023-03-03 17:01:33,278:INFO:python_version: 3.9.13
2023-03-03 17:01:33,278:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-03 17:01:33,278:INFO:machine: AMD64
2023-03-03 17:01:33,278:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-03 17:01:33,278:INFO:Memory: svmem(total=17009516544, available=4332417024, percent=74.5, used=12677099520, free=4332417024)
2023-03-03 17:01:33,279:INFO:Physical Core: 4
2023-03-03 17:01:33,279:INFO:Logical Core: 8
2023-03-03 17:01:33,279:INFO:Checking libraries
2023-03-03 17:01:33,279:INFO:System:
2023-03-03 17:01:33,279:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-03 17:01:33,279:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-03 17:01:33,279:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-03 17:01:33,279:INFO:PyCaret required dependencies:
2023-03-03 17:01:33,279:INFO:                 pip: 22.2.2
2023-03-03 17:01:33,279:INFO:          setuptools: 63.4.1
2023-03-03 17:01:33,279:INFO:             pycaret: 3.0.0rc9
2023-03-03 17:01:33,279:INFO:             IPython: 7.31.1
2023-03-03 17:01:33,279:INFO:          ipywidgets: 7.6.5
2023-03-03 17:01:33,279:INFO:                tqdm: 4.64.1
2023-03-03 17:01:33,279:INFO:               numpy: 1.21.5
2023-03-03 17:01:33,279:INFO:              pandas: 1.4.4
2023-03-03 17:01:33,279:INFO:              jinja2: 2.11.3
2023-03-03 17:01:33,279:INFO:               scipy: 1.9.1
2023-03-03 17:01:33,279:INFO:              joblib: 1.2.0
2023-03-03 17:01:33,279:INFO:             sklearn: 1.0.2
2023-03-03 17:01:33,280:INFO:                pyod: 1.0.7
2023-03-03 17:01:33,280:INFO:            imblearn: 0.10.1
2023-03-03 17:01:33,280:INFO:   category_encoders: 2.6.0
2023-03-03 17:01:33,280:INFO:            lightgbm: 3.3.5
2023-03-03 17:01:33,280:INFO:               numba: 0.55.1
2023-03-03 17:01:33,280:INFO:            requests: 2.28.1
2023-03-03 17:01:33,280:INFO:          matplotlib: 3.5.2
2023-03-03 17:01:33,280:INFO:          scikitplot: 0.3.7
2023-03-03 17:01:33,280:INFO:         yellowbrick: 1.5
2023-03-03 17:01:33,280:INFO:              plotly: 5.9.0
2023-03-03 17:01:33,280:INFO:             kaleido: 0.2.1
2023-03-03 17:01:33,280:INFO:         statsmodels: 0.13.2
2023-03-03 17:01:33,280:INFO:              sktime: 0.16.1
2023-03-03 17:01:33,280:INFO:               tbats: 1.1.2
2023-03-03 17:01:33,280:INFO:            pmdarima: 2.0.2
2023-03-03 17:01:33,280:INFO:              psutil: 5.9.0
2023-03-03 17:01:33,280:INFO:PyCaret optional dependencies:
2023-03-03 17:01:33,301:INFO:                shap: Not installed
2023-03-03 17:01:33,302:INFO:           interpret: Not installed
2023-03-03 17:01:33,302:INFO:                umap: Not installed
2023-03-03 17:01:33,302:INFO:    pandas_profiling: Not installed
2023-03-03 17:01:33,302:INFO:  explainerdashboard: Not installed
2023-03-03 17:01:33,302:INFO:             autoviz: Not installed
2023-03-03 17:01:33,302:INFO:           fairlearn: Not installed
2023-03-03 17:01:33,302:INFO:             xgboost: 1.7.4
2023-03-03 17:01:33,302:INFO:            catboost: Not installed
2023-03-03 17:01:33,302:INFO:              kmodes: Not installed
2023-03-03 17:01:33,302:INFO:             mlxtend: Not installed
2023-03-03 17:01:33,302:INFO:       statsforecast: Not installed
2023-03-03 17:01:33,302:INFO:        tune_sklearn: Not installed
2023-03-03 17:01:33,302:INFO:                 ray: Not installed
2023-03-03 17:01:33,302:INFO:            hyperopt: Not installed
2023-03-03 17:01:33,302:INFO:              optuna: Not installed
2023-03-03 17:01:33,302:INFO:               skopt: Not installed
2023-03-03 17:01:33,302:INFO:              mlflow: Not installed
2023-03-03 17:01:33,302:INFO:              gradio: Not installed
2023-03-03 17:01:33,302:INFO:             fastapi: Not installed
2023-03-03 17:01:33,302:INFO:             uvicorn: Not installed
2023-03-03 17:01:33,303:INFO:              m2cgen: Not installed
2023-03-03 17:01:33,303:INFO:           evidently: Not installed
2023-03-03 17:01:33,303:INFO:               fugue: Not installed
2023-03-03 17:01:33,303:INFO:           streamlit: Not installed
2023-03-03 17:01:33,303:INFO:             prophet: Not installed
2023-03-03 17:01:33,303:INFO:None
2023-03-03 17:01:33,303:INFO:Set up data.
2023-03-03 17:01:33,311:INFO:Set up train/test split.
2023-03-03 22:06:22,524:INFO:PyCaret ClassificationExperiment
2023-03-03 22:06:22,528:INFO:Logging name: clf-default-name
2023-03-03 22:06:22,528:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-03 22:06:22,529:INFO:version 3.0.0.rc9
2023-03-03 22:06:22,529:INFO:Initializing setup()
2023-03-03 22:06:22,529:INFO:self.USI: b156
2023-03-03 22:06:22,530:INFO:self._variable_keys: {'logging_param', 'exp_name_log', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'idx', 'y', 'target_param', 'fold_groups_param', 'X_test', 'y_test', 'memory', 'data', 'log_plots_param', 'gpu_param', 'X', 'y_train', 'USI', 'seed', 'X_train', 'is_multiclass', '_available_plots', 'fold_generator', '_ml_usecase', 'fold_shuffle_param', 'fix_imbalance', 'n_jobs_param'}
2023-03-03 22:06:22,531:INFO:Checking environment
2023-03-03 22:06:22,531:INFO:python_version: 3.9.13
2023-03-03 22:06:22,531:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-03 22:06:22,532:INFO:machine: AMD64
2023-03-03 22:06:22,532:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-03 22:06:22,534:INFO:Memory: svmem(total=17009516544, available=5290860544, percent=68.9, used=11718656000, free=5290860544)
2023-03-03 22:06:22,534:INFO:Physical Core: 4
2023-03-03 22:06:22,534:INFO:Logical Core: 8
2023-03-03 22:06:22,534:INFO:Checking libraries
2023-03-03 22:06:22,535:INFO:System:
2023-03-03 22:06:22,535:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-03 22:06:22,536:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-03 22:06:22,536:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-03 22:06:22,536:INFO:PyCaret required dependencies:
2023-03-03 22:06:22,540:INFO:                 pip: 22.2.2
2023-03-03 22:06:22,540:INFO:          setuptools: 63.4.1
2023-03-03 22:06:22,540:INFO:             pycaret: 3.0.0rc9
2023-03-03 22:06:22,540:INFO:             IPython: 7.31.1
2023-03-03 22:06:22,540:INFO:          ipywidgets: 7.6.5
2023-03-03 22:06:22,541:INFO:                tqdm: 4.64.1
2023-03-03 22:06:22,541:INFO:               numpy: 1.21.5
2023-03-03 22:06:22,541:INFO:              pandas: 1.4.4
2023-03-03 22:06:22,541:INFO:              jinja2: 2.11.3
2023-03-03 22:06:22,541:INFO:               scipy: 1.9.1
2023-03-03 22:06:22,541:INFO:              joblib: 1.2.0
2023-03-03 22:06:22,541:INFO:             sklearn: 1.0.2
2023-03-03 22:06:22,541:INFO:                pyod: 1.0.7
2023-03-03 22:06:22,541:INFO:            imblearn: 0.10.1
2023-03-03 22:06:22,542:INFO:   category_encoders: 2.6.0
2023-03-03 22:06:22,542:INFO:            lightgbm: 3.3.5
2023-03-03 22:06:22,542:INFO:               numba: 0.55.1
2023-03-03 22:06:22,542:INFO:            requests: 2.28.1
2023-03-03 22:06:22,542:INFO:          matplotlib: 3.5.2
2023-03-03 22:06:22,543:INFO:          scikitplot: 0.3.7
2023-03-03 22:06:22,543:INFO:         yellowbrick: 1.5
2023-03-03 22:06:22,543:INFO:              plotly: 5.9.0
2023-03-03 22:06:22,543:INFO:             kaleido: 0.2.1
2023-03-03 22:06:22,543:INFO:         statsmodels: 0.13.2
2023-03-03 22:06:22,544:INFO:              sktime: 0.16.1
2023-03-03 22:06:22,544:INFO:               tbats: 1.1.2
2023-03-03 22:06:22,544:INFO:            pmdarima: 2.0.2
2023-03-03 22:06:22,544:INFO:              psutil: 5.9.0
2023-03-03 22:06:22,544:INFO:PyCaret optional dependencies:
2023-03-03 22:06:22,545:INFO:                shap: Not installed
2023-03-03 22:06:22,545:INFO:           interpret: Not installed
2023-03-03 22:06:22,545:INFO:                umap: Not installed
2023-03-03 22:06:22,545:INFO:    pandas_profiling: Not installed
2023-03-03 22:06:22,545:INFO:  explainerdashboard: Not installed
2023-03-03 22:06:22,546:INFO:             autoviz: Not installed
2023-03-03 22:06:22,546:INFO:           fairlearn: Not installed
2023-03-03 22:06:22,546:INFO:             xgboost: 1.7.4
2023-03-03 22:06:22,546:INFO:            catboost: Not installed
2023-03-03 22:06:22,546:INFO:              kmodes: Not installed
2023-03-03 22:06:22,546:INFO:             mlxtend: Not installed
2023-03-03 22:06:22,546:INFO:       statsforecast: Not installed
2023-03-03 22:06:22,547:INFO:        tune_sklearn: Not installed
2023-03-03 22:06:22,547:INFO:                 ray: Not installed
2023-03-03 22:06:22,547:INFO:            hyperopt: Not installed
2023-03-03 22:06:22,547:INFO:              optuna: Not installed
2023-03-03 22:06:22,547:INFO:               skopt: Not installed
2023-03-03 22:06:22,547:INFO:              mlflow: Not installed
2023-03-03 22:06:22,547:INFO:              gradio: Not installed
2023-03-03 22:06:22,547:INFO:             fastapi: Not installed
2023-03-03 22:06:22,548:INFO:             uvicorn: Not installed
2023-03-03 22:06:22,548:INFO:              m2cgen: Not installed
2023-03-03 22:06:22,548:INFO:           evidently: Not installed
2023-03-03 22:06:22,548:INFO:               fugue: Not installed
2023-03-03 22:06:22,548:INFO:           streamlit: Not installed
2023-03-03 22:06:22,548:INFO:             prophet: Not installed
2023-03-03 22:06:22,548:INFO:None
2023-03-03 22:06:22,549:INFO:Set up data.
2023-03-03 22:06:22,643:INFO:Set up train/test split.
2023-03-03 22:06:55,215:INFO:PyCaret ClassificationExperiment
2023-03-03 22:06:55,216:INFO:Logging name: clf-default-name
2023-03-03 22:06:55,216:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-03 22:06:55,216:INFO:version 3.0.0.rc9
2023-03-03 22:06:55,216:INFO:Initializing setup()
2023-03-03 22:06:55,217:INFO:self.USI: 6933
2023-03-03 22:06:55,217:INFO:self._variable_keys: {'logging_param', 'exp_name_log', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'idx', 'y', 'target_param', 'fold_groups_param', 'X_test', 'y_test', 'memory', 'data', 'log_plots_param', 'gpu_param', 'X', 'y_train', 'USI', 'seed', 'X_train', 'is_multiclass', '_available_plots', 'fold_generator', '_ml_usecase', 'fold_shuffle_param', 'fix_imbalance', 'n_jobs_param'}
2023-03-03 22:06:55,217:INFO:Checking environment
2023-03-03 22:06:55,217:INFO:python_version: 3.9.13
2023-03-03 22:06:55,217:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-03 22:06:55,218:INFO:machine: AMD64
2023-03-03 22:06:55,218:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-03 22:06:55,218:INFO:Memory: svmem(total=17009516544, available=4864712704, percent=71.4, used=12144803840, free=4864712704)
2023-03-03 22:06:55,218:INFO:Physical Core: 4
2023-03-03 22:06:55,218:INFO:Logical Core: 8
2023-03-03 22:06:55,218:INFO:Checking libraries
2023-03-03 22:06:55,219:INFO:System:
2023-03-03 22:06:55,219:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-03 22:06:55,219:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-03 22:06:55,219:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-03 22:06:55,219:INFO:PyCaret required dependencies:
2023-03-03 22:06:55,220:INFO:                 pip: 22.2.2
2023-03-03 22:06:55,220:INFO:          setuptools: 63.4.1
2023-03-03 22:06:55,220:INFO:             pycaret: 3.0.0rc9
2023-03-03 22:06:55,220:INFO:             IPython: 7.31.1
2023-03-03 22:06:55,220:INFO:          ipywidgets: 7.6.5
2023-03-03 22:06:55,220:INFO:                tqdm: 4.64.1
2023-03-03 22:06:55,220:INFO:               numpy: 1.21.5
2023-03-03 22:06:55,221:INFO:              pandas: 1.4.4
2023-03-03 22:06:55,221:INFO:              jinja2: 2.11.3
2023-03-03 22:06:55,221:INFO:               scipy: 1.9.1
2023-03-03 22:06:55,221:INFO:              joblib: 1.2.0
2023-03-03 22:06:55,221:INFO:             sklearn: 1.0.2
2023-03-03 22:06:55,221:INFO:                pyod: 1.0.7
2023-03-03 22:06:55,221:INFO:            imblearn: 0.10.1
2023-03-03 22:06:55,222:INFO:   category_encoders: 2.6.0
2023-03-03 22:06:55,222:INFO:            lightgbm: 3.3.5
2023-03-03 22:06:55,222:INFO:               numba: 0.55.1
2023-03-03 22:06:55,223:INFO:            requests: 2.28.1
2023-03-03 22:06:55,223:INFO:          matplotlib: 3.5.2
2023-03-03 22:06:55,223:INFO:          scikitplot: 0.3.7
2023-03-03 22:06:55,223:INFO:         yellowbrick: 1.5
2023-03-03 22:06:55,223:INFO:              plotly: 5.9.0
2023-03-03 22:06:55,223:INFO:             kaleido: 0.2.1
2023-03-03 22:06:55,223:INFO:         statsmodels: 0.13.2
2023-03-03 22:06:55,223:INFO:              sktime: 0.16.1
2023-03-03 22:06:55,223:INFO:               tbats: 1.1.2
2023-03-03 22:06:55,223:INFO:            pmdarima: 2.0.2
2023-03-03 22:06:55,223:INFO:              psutil: 5.9.0
2023-03-03 22:06:55,223:INFO:PyCaret optional dependencies:
2023-03-03 22:06:55,224:INFO:                shap: Not installed
2023-03-03 22:06:55,224:INFO:           interpret: Not installed
2023-03-03 22:06:55,224:INFO:                umap: Not installed
2023-03-03 22:06:55,224:INFO:    pandas_profiling: Not installed
2023-03-03 22:06:55,224:INFO:  explainerdashboard: Not installed
2023-03-03 22:06:55,224:INFO:             autoviz: Not installed
2023-03-03 22:06:55,225:INFO:           fairlearn: Not installed
2023-03-03 22:06:55,225:INFO:             xgboost: 1.7.4
2023-03-03 22:06:55,225:INFO:            catboost: Not installed
2023-03-03 22:06:55,225:INFO:              kmodes: Not installed
2023-03-03 22:06:55,226:INFO:             mlxtend: Not installed
2023-03-03 22:06:55,226:INFO:       statsforecast: Not installed
2023-03-03 22:06:55,226:INFO:        tune_sklearn: Not installed
2023-03-03 22:06:55,226:INFO:                 ray: Not installed
2023-03-03 22:06:55,226:INFO:            hyperopt: Not installed
2023-03-03 22:06:55,226:INFO:              optuna: Not installed
2023-03-03 22:06:55,226:INFO:               skopt: Not installed
2023-03-03 22:06:55,226:INFO:              mlflow: Not installed
2023-03-03 22:06:55,226:INFO:              gradio: Not installed
2023-03-03 22:06:55,227:INFO:             fastapi: Not installed
2023-03-03 22:06:55,227:INFO:             uvicorn: Not installed
2023-03-03 22:06:55,227:INFO:              m2cgen: Not installed
2023-03-03 22:06:55,227:INFO:           evidently: Not installed
2023-03-03 22:06:55,227:INFO:               fugue: Not installed
2023-03-03 22:06:55,227:INFO:           streamlit: Not installed
2023-03-03 22:06:55,227:INFO:             prophet: Not installed
2023-03-03 22:06:55,227:INFO:None
2023-03-03 22:06:55,228:INFO:Set up data.
2023-03-03 22:06:55,248:INFO:Set up train/test split.
2023-03-04 16:58:50,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 16:58:50,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 16:58:50,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 16:58:50,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 16:58:52,426:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-04 16:58:52,827:INFO:PyCaret RegressionExperiment
2023-03-04 16:58:52,828:INFO:Logging name: reg-default-name
2023-03-04 16:58:52,828:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-04 16:58:52,828:INFO:version 3.0.0.rc9
2023-03-04 16:58:52,828:INFO:Initializing setup()
2023-03-04 16:58:52,828:INFO:self.USI: e2de
2023-03-04 16:58:52,828:INFO:self._variable_keys: {'log_plots_param', 'pipeline', 'fold_generator', 'target_param', 'X_test', 'y_train', 'idx', 'data', 'seed', 'USI', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', '_ml_usecase', 'gpu_param', '_available_plots', 'y_test', 'fold_groups_param', 'logging_param', 'y', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_name_log', 'X_train', 'memory', 'X'}
2023-03-04 16:58:52,828:INFO:Checking environment
2023-03-04 16:58:52,828:INFO:python_version: 3.9.13
2023-03-04 16:58:52,828:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-04 16:58:52,828:INFO:machine: AMD64
2023-03-04 16:58:52,828:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-04 16:58:52,828:INFO:Memory: svmem(total=17009516544, available=3945406464, percent=76.8, used=13064110080, free=3945406464)
2023-03-04 16:58:52,828:INFO:Physical Core: 4
2023-03-04 16:58:52,829:INFO:Logical Core: 8
2023-03-04 16:58:52,829:INFO:Checking libraries
2023-03-04 16:58:52,829:INFO:System:
2023-03-04 16:58:52,829:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-04 16:58:52,829:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-04 16:58:52,829:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-04 16:58:52,829:INFO:PyCaret required dependencies:
2023-03-04 16:58:52,829:INFO:                 pip: 22.2.2
2023-03-04 16:58:52,829:INFO:          setuptools: 63.4.1
2023-03-04 16:58:52,829:INFO:             pycaret: 3.0.0rc9
2023-03-04 16:58:52,829:INFO:             IPython: 7.31.1
2023-03-04 16:58:52,829:INFO:          ipywidgets: 7.6.5
2023-03-04 16:58:52,829:INFO:                tqdm: 4.64.1
2023-03-04 16:58:52,829:INFO:               numpy: 1.21.5
2023-03-04 16:58:52,829:INFO:              pandas: 1.4.4
2023-03-04 16:58:52,829:INFO:              jinja2: 2.11.3
2023-03-04 16:58:52,830:INFO:               scipy: 1.9.1
2023-03-04 16:58:52,830:INFO:              joblib: 1.2.0
2023-03-04 16:58:52,830:INFO:             sklearn: 1.0.2
2023-03-04 16:58:52,830:INFO:                pyod: 1.0.7
2023-03-04 16:58:52,830:INFO:            imblearn: 0.10.1
2023-03-04 16:58:52,830:INFO:   category_encoders: 2.6.0
2023-03-04 16:58:52,830:INFO:            lightgbm: 3.3.5
2023-03-04 16:58:52,830:INFO:               numba: 0.55.1
2023-03-04 16:58:52,830:INFO:            requests: 2.28.1
2023-03-04 16:58:52,830:INFO:          matplotlib: 3.5.2
2023-03-04 16:58:52,830:INFO:          scikitplot: 0.3.7
2023-03-04 16:58:52,830:INFO:         yellowbrick: 1.5
2023-03-04 16:58:52,830:INFO:              plotly: 5.9.0
2023-03-04 16:58:52,830:INFO:             kaleido: 0.2.1
2023-03-04 16:58:52,830:INFO:         statsmodels: 0.13.2
2023-03-04 16:58:52,830:INFO:              sktime: 0.16.1
2023-03-04 16:58:52,830:INFO:               tbats: 1.1.2
2023-03-04 16:58:52,830:INFO:            pmdarima: 2.0.2
2023-03-04 16:58:52,830:INFO:              psutil: 5.9.0
2023-03-04 16:58:52,831:INFO:PyCaret optional dependencies:
2023-03-04 16:58:52,855:INFO:                shap: Not installed
2023-03-04 16:58:52,855:INFO:           interpret: Not installed
2023-03-04 16:58:52,855:INFO:                umap: Not installed
2023-03-04 16:58:52,855:INFO:    pandas_profiling: Not installed
2023-03-04 16:58:52,856:INFO:  explainerdashboard: Not installed
2023-03-04 16:58:52,856:INFO:             autoviz: Not installed
2023-03-04 16:58:52,856:INFO:           fairlearn: Not installed
2023-03-04 16:58:52,856:INFO:             xgboost: 1.7.4
2023-03-04 16:58:52,856:INFO:            catboost: Not installed
2023-03-04 16:58:52,856:INFO:              kmodes: Not installed
2023-03-04 16:58:52,856:INFO:             mlxtend: Not installed
2023-03-04 16:58:52,856:INFO:       statsforecast: Not installed
2023-03-04 16:58:52,856:INFO:        tune_sklearn: Not installed
2023-03-04 16:58:52,856:INFO:                 ray: Not installed
2023-03-04 16:58:52,856:INFO:            hyperopt: Not installed
2023-03-04 16:58:52,856:INFO:              optuna: Not installed
2023-03-04 16:58:52,856:INFO:               skopt: Not installed
2023-03-04 16:58:52,856:INFO:              mlflow: Not installed
2023-03-04 16:58:52,856:INFO:              gradio: Not installed
2023-03-04 16:58:52,856:INFO:             fastapi: Not installed
2023-03-04 16:58:52,856:INFO:             uvicorn: Not installed
2023-03-04 16:58:52,856:INFO:              m2cgen: Not installed
2023-03-04 16:58:52,857:INFO:           evidently: Not installed
2023-03-04 16:58:52,857:INFO:               fugue: Not installed
2023-03-04 16:58:52,857:INFO:           streamlit: Not installed
2023-03-04 16:58:52,857:INFO:             prophet: Not installed
2023-03-04 16:58:52,857:INFO:None
2023-03-04 16:58:52,857:INFO:Set up data.
2023-03-04 17:00:02,946:INFO:PyCaret RegressionExperiment
2023-03-04 17:00:02,946:INFO:Logging name: reg-default-name
2023-03-04 17:00:02,946:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-04 17:00:02,946:INFO:version 3.0.0.rc9
2023-03-04 17:00:02,946:INFO:Initializing setup()
2023-03-04 17:00:02,946:INFO:self.USI: 7e8c
2023-03-04 17:00:02,946:INFO:self._variable_keys: {'log_plots_param', 'pipeline', 'fold_generator', 'target_param', 'X_test', 'y_train', 'idx', 'data', 'seed', 'USI', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', '_ml_usecase', 'gpu_param', '_available_plots', 'y_test', 'fold_groups_param', 'logging_param', 'y', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_name_log', 'X_train', 'memory', 'X'}
2023-03-04 17:00:02,947:INFO:Checking environment
2023-03-04 17:00:02,947:INFO:python_version: 3.9.13
2023-03-04 17:00:02,947:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-04 17:00:02,947:INFO:machine: AMD64
2023-03-04 17:00:02,947:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-04 17:00:02,947:INFO:Memory: svmem(total=17009516544, available=3673432064, percent=78.4, used=13336084480, free=3673432064)
2023-03-04 17:00:02,947:INFO:Physical Core: 4
2023-03-04 17:00:02,947:INFO:Logical Core: 8
2023-03-04 17:00:02,947:INFO:Checking libraries
2023-03-04 17:00:02,947:INFO:System:
2023-03-04 17:00:02,947:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-04 17:00:02,947:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-04 17:00:02,947:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-04 17:00:02,947:INFO:PyCaret required dependencies:
2023-03-04 17:00:02,947:INFO:                 pip: 22.2.2
2023-03-04 17:00:02,948:INFO:          setuptools: 63.4.1
2023-03-04 17:00:02,948:INFO:             pycaret: 3.0.0rc9
2023-03-04 17:00:02,948:INFO:             IPython: 7.31.1
2023-03-04 17:00:02,948:INFO:          ipywidgets: 7.6.5
2023-03-04 17:00:02,948:INFO:                tqdm: 4.64.1
2023-03-04 17:00:02,948:INFO:               numpy: 1.21.5
2023-03-04 17:00:02,948:INFO:              pandas: 1.4.4
2023-03-04 17:00:02,948:INFO:              jinja2: 2.11.3
2023-03-04 17:00:02,948:INFO:               scipy: 1.9.1
2023-03-04 17:00:02,948:INFO:              joblib: 1.2.0
2023-03-04 17:00:02,948:INFO:             sklearn: 1.0.2
2023-03-04 17:00:02,948:INFO:                pyod: 1.0.7
2023-03-04 17:00:02,948:INFO:            imblearn: 0.10.1
2023-03-04 17:00:02,948:INFO:   category_encoders: 2.6.0
2023-03-04 17:00:02,948:INFO:            lightgbm: 3.3.5
2023-03-04 17:00:02,948:INFO:               numba: 0.55.1
2023-03-04 17:00:02,948:INFO:            requests: 2.28.1
2023-03-04 17:00:02,948:INFO:          matplotlib: 3.5.2
2023-03-04 17:00:02,948:INFO:          scikitplot: 0.3.7
2023-03-04 17:00:02,949:INFO:         yellowbrick: 1.5
2023-03-04 17:00:02,949:INFO:              plotly: 5.9.0
2023-03-04 17:00:02,949:INFO:             kaleido: 0.2.1
2023-03-04 17:00:02,949:INFO:         statsmodels: 0.13.2
2023-03-04 17:00:02,949:INFO:              sktime: 0.16.1
2023-03-04 17:00:02,949:INFO:               tbats: 1.1.2
2023-03-04 17:00:02,949:INFO:            pmdarima: 2.0.2
2023-03-04 17:00:02,949:INFO:              psutil: 5.9.0
2023-03-04 17:00:02,949:INFO:PyCaret optional dependencies:
2023-03-04 17:00:02,949:INFO:                shap: Not installed
2023-03-04 17:00:02,949:INFO:           interpret: Not installed
2023-03-04 17:00:02,949:INFO:                umap: Not installed
2023-03-04 17:00:02,950:INFO:    pandas_profiling: Not installed
2023-03-04 17:00:02,950:INFO:  explainerdashboard: Not installed
2023-03-04 17:00:02,950:INFO:             autoviz: Not installed
2023-03-04 17:00:02,950:INFO:           fairlearn: Not installed
2023-03-04 17:00:02,950:INFO:             xgboost: 1.7.4
2023-03-04 17:00:02,950:INFO:            catboost: Not installed
2023-03-04 17:00:02,950:INFO:              kmodes: Not installed
2023-03-04 17:00:02,950:INFO:             mlxtend: Not installed
2023-03-04 17:00:02,950:INFO:       statsforecast: Not installed
2023-03-04 17:00:02,950:INFO:        tune_sklearn: Not installed
2023-03-04 17:00:02,950:INFO:                 ray: Not installed
2023-03-04 17:00:02,951:INFO:            hyperopt: Not installed
2023-03-04 17:00:02,951:INFO:              optuna: Not installed
2023-03-04 17:00:02,951:INFO:               skopt: Not installed
2023-03-04 17:00:02,951:INFO:              mlflow: Not installed
2023-03-04 17:00:02,951:INFO:              gradio: Not installed
2023-03-04 17:00:02,951:INFO:             fastapi: Not installed
2023-03-04 17:00:02,951:INFO:             uvicorn: Not installed
2023-03-04 17:00:02,951:INFO:              m2cgen: Not installed
2023-03-04 17:00:02,951:INFO:           evidently: Not installed
2023-03-04 17:00:02,951:INFO:               fugue: Not installed
2023-03-04 17:00:02,952:INFO:           streamlit: Not installed
2023-03-04 17:00:02,952:INFO:             prophet: Not installed
2023-03-04 17:00:02,952:INFO:None
2023-03-04 17:00:02,952:INFO:Set up data.
2023-03-04 17:00:03,001:INFO:Set up train/test split.
2023-03-04 17:00:03,010:INFO:Set up index.
2023-03-04 17:00:03,012:INFO:Set up folding strategy.
2023-03-04 17:00:03,012:INFO:Assigning column types.
2023-03-04 17:00:03,017:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-04 17:00:03,017:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,023:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,029:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,155:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:03,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:03,158:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,164:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,169:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,288:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:03,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:03,291:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-04 17:00:03,297:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,370:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,423:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:03,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:03,432:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,437:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,504:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,557:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:03,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:03,560:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-04 17:00:03,571:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,695:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:03,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:03,709:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,777:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,828:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,829:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:03,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:03,832:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-04 17:00:03,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:03,968:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:03,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:04,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:04,121:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:00:04,122:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:04,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:04,126:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-04 17:00:04,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:04,267:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:04,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:04,357:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:00:04,419:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:04,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:04,422:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-04 17:00:04,563:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:04,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:04,699:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:04,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:04,704:INFO:Preparing preprocessing pipeline...
2023-03-04 17:00:04,705:INFO:Set up column name cleaning.
2023-03-04 17:00:04,705:INFO:Set up simple imputation.
2023-03-04 17:00:04,749:INFO:Finished creating preprocessing pipeline.
2023-03-04 17:00:04,756:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Alvaro\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['work_year', 'remote_ratio',
                                             'experience_level_EX',
                                             'experience_level_MI',
                                             'experience_level_SE',
                                             'employment_type_FL',
                                             'employment_type_FT',
                                             'emplo...
                                             'job_title_Data Architect',
                                             'job_title_Data Engineer',
                                             'job_title_Data Engineering '
                                             'Manager',
                                             'job_title_Data Science '
                                             'Consultant',
                                             'job_title_Data Science Engineer',
                                             'job_title_Data Science Manager',
                                             'job_title_Data Scientist', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-03-04 17:00:04,756:INFO:Creating final display dataframe.
2023-03-04 17:00:04,997:INFO:Setup _display_container:                     Description             Value
0                    Session id              6865
1                        Target     salary_in_usd
2                   Target type        Regression
3           Original data shape        (499, 165)
4        Transformed data shape        (499, 165)
5   Transformed train set shape        (349, 165)
6    Transformed test set shape        (150, 165)
7              Numeric features               164
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7e8c
2023-03-04 17:00:05,154:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:05,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:05,295:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:00:05,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:00:05,299:INFO:setup() successfully completed in 2.36s...............
2023-03-04 17:00:25,224:INFO:Initializing compare_models()
2023-03-04 17:00:25,225:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-03-04 17:00:25,225:INFO:Checking exceptions
2023-03-04 17:00:25,229:INFO:Preparing display monitor
2023-03-04 17:00:25,279:INFO:Initializing Linear Regression
2023-03-04 17:00:25,280:INFO:Total runtime is 1.6729036966959637e-05 minutes
2023-03-04 17:00:25,286:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:25,287:INFO:Initializing create_model()
2023-03-04 17:00:25,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:25,287:INFO:Checking exceptions
2023-03-04 17:00:25,288:INFO:Importing libraries
2023-03-04 17:00:25,288:INFO:Copying training dataset
2023-03-04 17:00:25,297:INFO:Defining folds
2023-03-04 17:00:25,298:INFO:Declaring metric variables
2023-03-04 17:00:25,301:INFO:Importing untrained model
2023-03-04 17:00:25,304:INFO:Linear Regression Imported successfully
2023-03-04 17:00:25,318:INFO:Starting cross validation
2023-03-04 17:00:25,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:38,401:INFO:Calculating mean and std
2023-03-04 17:00:38,404:INFO:Creating metrics dataframe
2023-03-04 17:00:38,408:INFO:Uploading results into container
2023-03-04 17:00:38,409:INFO:Uploading model into container now
2023-03-04 17:00:38,410:INFO:_master_model_container: 1
2023-03-04 17:00:38,410:INFO:_display_container: 2
2023-03-04 17:00:38,411:INFO:LinearRegression(n_jobs=-1)
2023-03-04 17:00:38,411:INFO:create_model() successfully completed......................................
2023-03-04 17:00:38,547:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:38,547:INFO:Creating metrics dataframe
2023-03-04 17:00:38,558:INFO:Initializing Lasso Regression
2023-03-04 17:00:38,558:INFO:Total runtime is 0.22130781014760334 minutes
2023-03-04 17:00:38,562:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:38,563:INFO:Initializing create_model()
2023-03-04 17:00:38,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:38,563:INFO:Checking exceptions
2023-03-04 17:00:38,563:INFO:Importing libraries
2023-03-04 17:00:38,563:INFO:Copying training dataset
2023-03-04 17:00:38,573:INFO:Defining folds
2023-03-04 17:00:38,574:INFO:Declaring metric variables
2023-03-04 17:00:38,580:INFO:Importing untrained model
2023-03-04 17:00:38,587:INFO:Lasso Regression Imported successfully
2023-03-04 17:00:38,602:INFO:Starting cross validation
2023-03-04 17:00:38,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:38,793:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.118e+10, tolerance: 1.627e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:38,842:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.977e+09, tolerance: 1.571e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:38,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.677e+10, tolerance: 1.616e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:38,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+10, tolerance: 1.538e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:38,899:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.294e+10, tolerance: 1.572e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:38,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+10, tolerance: 1.577e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:38,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.005e+10, tolerance: 1.423e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:38,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.577e+10, tolerance: 1.521e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:39,075:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.795e+10, tolerance: 1.481e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:39,109:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.066e+10, tolerance: 1.528e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:00:39,274:INFO:Calculating mean and std
2023-03-04 17:00:39,276:INFO:Creating metrics dataframe
2023-03-04 17:00:39,281:INFO:Uploading results into container
2023-03-04 17:00:39,282:INFO:Uploading model into container now
2023-03-04 17:00:39,282:INFO:_master_model_container: 2
2023-03-04 17:00:39,283:INFO:_display_container: 2
2023-03-04 17:00:39,283:INFO:Lasso(random_state=6865)
2023-03-04 17:00:39,283:INFO:create_model() successfully completed......................................
2023-03-04 17:00:39,418:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:39,418:INFO:Creating metrics dataframe
2023-03-04 17:00:39,429:INFO:Initializing Ridge Regression
2023-03-04 17:00:39,429:INFO:Total runtime is 0.23583558400472004 minutes
2023-03-04 17:00:39,433:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:39,434:INFO:Initializing create_model()
2023-03-04 17:00:39,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:39,434:INFO:Checking exceptions
2023-03-04 17:00:39,434:INFO:Importing libraries
2023-03-04 17:00:39,435:INFO:Copying training dataset
2023-03-04 17:00:39,445:INFO:Defining folds
2023-03-04 17:00:39,445:INFO:Declaring metric variables
2023-03-04 17:00:39,452:INFO:Importing untrained model
2023-03-04 17:00:39,459:INFO:Ridge Regression Imported successfully
2023-03-04 17:00:39,475:INFO:Starting cross validation
2023-03-04 17:00:39,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:39,840:INFO:Calculating mean and std
2023-03-04 17:00:39,842:INFO:Creating metrics dataframe
2023-03-04 17:00:39,846:INFO:Uploading results into container
2023-03-04 17:00:39,847:INFO:Uploading model into container now
2023-03-04 17:00:39,848:INFO:_master_model_container: 3
2023-03-04 17:00:39,848:INFO:_display_container: 2
2023-03-04 17:00:39,849:INFO:Ridge(random_state=6865)
2023-03-04 17:00:39,849:INFO:create_model() successfully completed......................................
2023-03-04 17:00:39,981:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:39,981:INFO:Creating metrics dataframe
2023-03-04 17:00:39,994:INFO:Initializing Elastic Net
2023-03-04 17:00:39,994:INFO:Total runtime is 0.24524393081665039 minutes
2023-03-04 17:00:39,998:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:39,998:INFO:Initializing create_model()
2023-03-04 17:00:39,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:39,999:INFO:Checking exceptions
2023-03-04 17:00:39,999:INFO:Importing libraries
2023-03-04 17:00:40,000:INFO:Copying training dataset
2023-03-04 17:00:40,009:INFO:Defining folds
2023-03-04 17:00:40,010:INFO:Declaring metric variables
2023-03-04 17:00:40,016:INFO:Importing untrained model
2023-03-04 17:00:40,023:INFO:Elastic Net Imported successfully
2023-03-04 17:00:40,037:INFO:Starting cross validation
2023-03-04 17:00:40,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:40,420:INFO:Calculating mean and std
2023-03-04 17:00:40,422:INFO:Creating metrics dataframe
2023-03-04 17:00:40,427:INFO:Uploading results into container
2023-03-04 17:00:40,427:INFO:Uploading model into container now
2023-03-04 17:00:40,428:INFO:_master_model_container: 4
2023-03-04 17:00:40,428:INFO:_display_container: 2
2023-03-04 17:00:40,429:INFO:ElasticNet(random_state=6865)
2023-03-04 17:00:40,429:INFO:create_model() successfully completed......................................
2023-03-04 17:00:40,562:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:40,563:INFO:Creating metrics dataframe
2023-03-04 17:00:40,575:INFO:Initializing Least Angle Regression
2023-03-04 17:00:40,575:INFO:Total runtime is 0.2549347956975301 minutes
2023-03-04 17:00:40,580:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:40,580:INFO:Initializing create_model()
2023-03-04 17:00:40,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:40,581:INFO:Checking exceptions
2023-03-04 17:00:40,581:INFO:Importing libraries
2023-03-04 17:00:40,581:INFO:Copying training dataset
2023-03-04 17:00:40,593:INFO:Defining folds
2023-03-04 17:00:40,593:INFO:Declaring metric variables
2023-03-04 17:00:40,600:INFO:Importing untrained model
2023-03-04 17:00:40,607:INFO:Least Angle Regression Imported successfully
2023-03-04 17:00:40,620:INFO:Starting cross validation
2023-03-04 17:00:40,623:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:40,782:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,782:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,799:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.261e+02, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,803:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.718e+02, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,805:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.546e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,805:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.546e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,812:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.399e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,814:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,815:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.269e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,816:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=8.018e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,817:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=8.018e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,817:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.844e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

odel = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,818:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.844e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,819:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.844e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,819:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.515e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,822:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=5.597e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,822:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.032e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,822:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.032e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,823:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=5.242e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,823:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=6.996e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,824:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=6.996e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,825:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.119e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,826:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.788e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,826:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.771e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,827:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.771e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,827:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.422e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,828:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.422e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,828:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.214e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,833:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.625e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,834:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.701e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,834:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.701e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,836:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,837:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.796e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,837:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.506e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,838:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.506e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,838:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.611e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,838:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,838:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.611e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,839:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.575e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,839:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.575e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,841:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.219e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,842:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.370e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,844:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.344e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,844:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.805e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,844:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=4.546e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,845:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=4.140e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,845:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.959e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,846:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=8.726e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,846:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.959e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,846:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=8.726e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,846:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.959e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,847:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.337e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,848:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.664e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,848:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.203e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,849:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.323e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,849:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.323e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,850:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.965e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,850:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.718e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,851:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.965e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,851:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=6.302e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,851:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.189e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,851:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=6.302e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,852:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.859e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,852:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.859e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,852:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.965e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,852:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.641e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,853:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.793e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,853:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=3.050e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,853:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.641e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,853:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.566e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,853:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=3.050e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,853:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.641e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,854:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.957e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,854:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.368e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,854:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.443e+02, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,854:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.894e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,854:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.734e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,855:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.702e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,855:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.894e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,855:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.702e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,855:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.633e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,856:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.911e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,858:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=9.791e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,858:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.455e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,858:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=9.791e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,859:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=2.371e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,859:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.529e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,860:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=2.343e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,860:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.272e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,862:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.166e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,862:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,862:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,863:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,863:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.919e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,863:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.176e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,863:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,864:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.176e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,864:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,865:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.560e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,865:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.742e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,865:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.812e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,865:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.683e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,866:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.001e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,866:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.267e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,866:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.807e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,867:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.310e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,867:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.001e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,867:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.267e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,867:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:40,868:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.832e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,868:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.477e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,869:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.832e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,869:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.477e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,870:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.494e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,870:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.458e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,871:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=2.319e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,871:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.437e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,872:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.245e+02, with an active set of 76 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,872:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.658e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,872:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.658e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,873:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.432e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,873:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=2.165e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,873:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.023e+02, with an active set of 78 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,874:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.203e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,874:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.646e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,874:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=9.660e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.646e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.549e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.359e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=7.902e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,876:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.348e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,876:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=7.902e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,877:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.319e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,877:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.822e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,877:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=4.948e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,877:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.822e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=4.948e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=6.167e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.418e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=4.948e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=6.167e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.125e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.698e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.124e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=5.837e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.119e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.535e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.118e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.453e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=5.509e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.115e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=5.509e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.108e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.370e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,881:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.102e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,881:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.099e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,881:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=5.398e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.091e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=5.398e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.650e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.561e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.195e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.450e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,883:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.190e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,883:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.349e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,883:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.705e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,883:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=5.250e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,883:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.583e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,883:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.155e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,884:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=4.475e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,884:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.361e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,884:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.155e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,884:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.066e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,885:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.924e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,885:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=3.926e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,885:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.725e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.855e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.295e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.855e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.276e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=3.408e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,887:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.010e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,887:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=3.408e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,887:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=8.176e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,887:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.228e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.226e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=8.176e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=2.680e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.166e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.993e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=9.469e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.151e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.993e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.993e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=7.677e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=5.249e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.121e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=2.556e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.990e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=5.249e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.108e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=8.619e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.018e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=7.938e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.421e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=1.980e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.364e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=3.740e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=1.917e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.952e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=3.648e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=1.899e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.575e+00, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=1.674e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.911e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=8.784e+04, with an active set of 100 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.196e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.911e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.015e+02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=1.043e+06, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=5.263e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=3.123e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.408e+05, with an active set of 105 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.950e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,895:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.551e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,895:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.921e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,896:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.796e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,896:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.744e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,896:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.184e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,896:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.752e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(
2023-03-04 17:00:40,896:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=3.342e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.733e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.011e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.386e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.599e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.010e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.582e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.931e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,898:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.565e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,898:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.171e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,898:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.040e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,898:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.156e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.wwarn(

2023-03-04 17:00:40,898:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.040e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,899:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.155e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,899:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.665e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,899:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.153e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,899:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.028e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,899:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.152e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,899:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.017e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.681e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=6.509e+00, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.972e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.389e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.638e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.723e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.389e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,901:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.769e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,901:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.714e+03, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,901:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.582e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,901:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.599e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=9.550e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.631e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.599e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=8.713e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.575e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=2.882e+04, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=8.564e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.572e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.672e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=8.466e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.572e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.066e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=6.810e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.549e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,904:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.672e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,904:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.816e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,904:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.672e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,904:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.948e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,904:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.375e+06, with an active set of 97 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,905:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.887e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,905:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.305e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,906:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.887e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,906:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.264e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,906:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.887e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,907:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.838e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,907:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.098e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,907:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=9.866e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=9.081e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.854e+08, with an active set of 100 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=5.342e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=2.267e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.111e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.690e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,909:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=2.038e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,909:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.090e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,909:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.989e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,909:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.074e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.923e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.072e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.932e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.517e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.472e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.058e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.932e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.517e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.343e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.056e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.054e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.517e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.629e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.052e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.403e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.242e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.231e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.048e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.038e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.047e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.195e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.036e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.829e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.021e+07, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.195e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.032e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=8.402e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.024e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.759e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.006e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.107e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=6.630e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.994e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.502e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.990e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.395e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,916:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.930e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,916:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=2.248e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,916:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.536e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.319e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=2.618e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=3.356e+05, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.678e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.319e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=2.579e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,918:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.831e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,918:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.010e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,920:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.263e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,920:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.263e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,920:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.905e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.263e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.709e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.192e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.782e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.877e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=3.937e+06, with an active set of 97 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.660e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.611e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.611e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.562e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.513e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.056e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.439e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.031e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.427e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.031e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.415e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.317e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=9.403e+00, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.388e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.532e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=9.095e+00, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.361e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.837e+07, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.219e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.361e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.837e+07, with an active set of 101 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.219e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.739e+07, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,927:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.120e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,927:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=8.609e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,928:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.022e-02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,927:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.209e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,928:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.281e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,928:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=5.030e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,929:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.693e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,929:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.259e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,929:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=7.499e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,930:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=7.499e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,930:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.488e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,930:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.461e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,931:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.189e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,931:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.350e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,931:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=6.400e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,931:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.177e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,932:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=6.399e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:40,932:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.848e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,932:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.190e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,932:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.840e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.146e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.840e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.926e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.033e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.319e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.976e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.191e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.942e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.917e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.833e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.917e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.833e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.595e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.917e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.807e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.595e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.765e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.692e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.595e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.259e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.692e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.071e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.028e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=3.571e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.501e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=7.966e+05, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.586e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=6.264e+05, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.177e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=5.838e+05, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.336e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.177e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.448e+05, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.263e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.177e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.177e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.263e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.061e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.262e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.267e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=8.553e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=6.887e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,943:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=4.493e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,943:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.099e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,943:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=4.488e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,944:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=3.193e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,944:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.139e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,944:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.272e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,945:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.578e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,945:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.577e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,945:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.032e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.334e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.331e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=2.962e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.331e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,947:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.330e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,947:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.330e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.329e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.727e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.329e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,949:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.328e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,949:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.326e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,949:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.145e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,950:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.145e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,951:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.033e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,952:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=9.641e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,952:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=9.444e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.467e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,954:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=9.628e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.278e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=9.588e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=8.628e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.714e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=8.628e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=6.797e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,957:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=6.797e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,957:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=5.836e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,958:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=5.520e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,958:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.639e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,959:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=5.463e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,960:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.823e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,960:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.500e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.355e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.355e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,962:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.155e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,964:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.577e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,965:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.577e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,965:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=3.927e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,965:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.521e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,966:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=3.644e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,966:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.470e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,966:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.423e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,967:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.423e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,968:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.364e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,968:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.115e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.185e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.292e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,970:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.285e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,970:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.204e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,971:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.078e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,971:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.021e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,972:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.015e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,972:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.014e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,973:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.008e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,973:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.037e+01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,973:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.986e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,974:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.979e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,974:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.002e+01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,974:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.978e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,975:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.970e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,975:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.964e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,974:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=9.915e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,976:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.958e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,976:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=9.863e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,976:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.944e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,977:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=9.782e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,977:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.942e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,977:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=9.780e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.925e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=7.267e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.902e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=6.087e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.880e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,979:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.547e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,979:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.845e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,979:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.845e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,980:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.806e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,980:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.691e+01, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,980:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=4.170e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,982:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.425e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,983:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.412e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,983:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.886e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,984:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.865e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,984:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.844e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,984:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.842e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,985:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.841e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,985:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.743e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,986:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.659e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,987:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.397e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,987:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.152e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,988:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.967e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,989:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.182e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,989:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.116e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,992:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.052e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,992:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.041e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,993:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.036e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,994:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.022e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,994:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.019e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:40,999:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=9.648e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,000:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=8.375e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,000:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.248e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,001:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.814e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,447:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:41,497:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:41,637:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:41,642:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:41,643:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.278e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,649:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.478e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,650:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.893e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,652:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.304e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,652:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.304e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,653:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.634e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,654:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.246e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,654:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.720e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,655:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.720e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,656:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,656:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,656:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.781e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,656:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,657:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,659:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=8.194e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,659:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.276e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,659:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.057e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,659:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.057e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,660:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=7.522e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,660:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=7.522e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,660:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.918e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,661:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.134e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,661:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.134e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,661:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.222e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,662:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.222e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,663:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.879e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,663:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.755e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,663:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=5.820e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,663:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=5.820e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,664:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.325e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,664:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.325e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,664:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.163e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,665:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.991e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,666:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.991e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,666:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.991e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,666:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.686e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,666:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.991e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,666:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.686e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,667:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.278e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,667:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.059e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,667:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.455e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,667:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.059e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,667:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.455e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,667:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.019e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,668:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=4.234e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,668:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.977e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,668:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=4.038e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,668:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=4.038e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,669:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.677e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,669:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.882e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,669:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.649e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,669:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.649e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,671:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.747e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,671:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.747e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,672:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.747e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,672:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.747e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,673:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.028e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,674:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.840e+06, with an active set of 96 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,674:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.955e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,675:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.955e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,675:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.955e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,675:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.955e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,675:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.059e+06, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,676:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.696e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,676:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.694e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,677:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.540e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,677:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.526e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,677:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.519e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,677:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.517e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,678:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.346e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:00:41,678:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.515e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,678:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.317e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,678:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.512e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,678:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.138e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,678:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.503e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,678:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.125e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,679:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.498e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,679:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.099e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,679:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.489e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,679:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.484e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,679:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.524e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,679:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.472e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.504e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.470e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.478e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.468e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.475e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.467e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.140e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.448e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,680:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.444e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,681:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.038e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,681:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.161e+06, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,681:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.013e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,681:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.159e+06, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,681:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=9.810e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,682:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=9.609e+05, with an active set of 101 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,682:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=9.635e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,682:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=9.617e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,682:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=9.553e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,682:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=9.223e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,683:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=8.946e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,684:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=7.122e+00, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,684:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.364e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,684:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.375e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.279e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.253e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.085e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.220e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.892e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.209e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.882e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,685:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.182e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.541e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.158e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.486e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.121e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.423e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.087e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.381e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.080e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,686:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.343e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.023e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.307e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.928e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.824e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.922e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.717e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.905e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.610e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,687:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.904e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.603e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.881e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.583e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.831e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.583e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.640e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.257e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.621e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,688:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.197e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.480e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.924e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.478e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.446e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.443e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=9.747e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.442e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.443e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.429e+11, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,690:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.175e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:41,749:INFO:Calculating mean and std
2023-03-04 17:00:41,751:INFO:Creating metrics dataframe
2023-03-04 17:00:41,756:INFO:Uploading results into container
2023-03-04 17:00:41,757:INFO:Uploading model into container now
2023-03-04 17:00:41,757:INFO:_master_model_container: 5
2023-03-04 17:00:41,758:INFO:_display_container: 2
2023-03-04 17:00:41,758:INFO:Lars(random_state=6865)
2023-03-04 17:00:41,759:INFO:create_model() successfully completed......................................
2023-03-04 17:00:41,894:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:41,894:INFO:Creating metrics dataframe
2023-03-04 17:00:41,907:INFO:Initializing Lasso Least Angle Regression
2023-03-04 17:00:41,907:INFO:Total runtime is 0.2771254142125447 minutes
2023-03-04 17:00:41,912:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:41,912:INFO:Initializing create_model()
2023-03-04 17:00:41,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:41,913:INFO:Checking exceptions
2023-03-04 17:00:41,913:INFO:Importing libraries
2023-03-04 17:00:41,913:INFO:Copying training dataset
2023-03-04 17:00:41,923:INFO:Defining folds
2023-03-04 17:00:41,923:INFO:Declaring metric variables
2023-03-04 17:00:41,930:INFO:Importing untrained model
2023-03-04 17:00:41,937:INFO:Lasso Least Angle Regression Imported successfully
2023-03-04 17:00:41,951:INFO:Starting cross validation
2023-03-04 17:00:41,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:42,106:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,125:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,128:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,134:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.625e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,135:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.399e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,137:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.796e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,137:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.269e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,139:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.261e+02, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,141:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.219e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,143:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.032e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,143:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.805e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,144:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.032e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,144:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.718e+02, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,145:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=6.996e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,145:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=6.996e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,146:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.546e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,147:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.546e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,149:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.214e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,150:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.189e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,153:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.894e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,154:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.894e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,156:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=5.493e+01, previous alpha=5.332e+01, with an active set of 62 regressors.
  warnings.warn(

2023-03-04 17:00:42,158:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=8.547e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,159:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=3.873e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,159:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,159:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.931e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,160:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.931e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,161:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.516e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,161:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.542e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,161:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.516e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,162:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.480e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,162:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.480e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,163:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.440e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,165:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.054e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,166:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.043e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,167:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=2.676e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,167:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=2.536e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,169:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.123e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,163:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=5.627e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,170:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=2.047e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,170:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.976e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,171:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.818e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,171:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.312e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,172:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.701e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,173:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.720e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,174:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.506e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,174:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.720e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,174:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.506e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,174:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.368e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,175:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.307e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,175:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.196e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,177:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.455e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,178:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 97 iterations, alpha=2.598e+01, previous alpha=9.784e+00, with an active set of 92 regressors.
  warnings.warn(

2023-03-04 17:00:42,178:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=4.799e+01, previous alpha=4.455e+01, with an active set of 72 regressors.
  warnings.warn(

2023-03-04 17:00:42,179:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,179:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.344e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,181:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=8.726e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,182:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=8.726e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,183:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.337e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,184:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.323e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,185:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.323e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,186:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=6.302e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,186:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=6.302e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,187:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.965e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,189:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.734e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,191:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.718e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,191:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=5.789e+01, previous alpha=5.611e+01, with an active set of 60 regressors.
  warnings.warn(

2023-03-04 17:00:42,193:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.641e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,193:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.641e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,194:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.641e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,196:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,198:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=9.791e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,198:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=9.791e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,202:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,202:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,203:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,203:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,203:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.914e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,204:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=7.820e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,206:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.566e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,207:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.443e+02, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,207:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.437e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,210:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.455e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,211:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.455e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,211:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,212:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.549e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,212:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=4.948e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,212:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=4.948e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,213:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=4.948e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,216:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.176e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,216:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.176e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,216:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.650e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,218:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=4.639e+01, previous alpha=4.591e+01, with an active set of 71 regressors.
  warnings.warn(

2023-03-04 17:00:42,219:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.561e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,219:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.001e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,219:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.001e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,220:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.361e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,221:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.361e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,224:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.658e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,224:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.658e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,226:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.203e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,227:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.551e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,227:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.924e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,228:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.386e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,228:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.855e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,229:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.386e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,229:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.855e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,231:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 53 iterations, alpha=8.180e+01, previous alpha=7.957e+01, with an active set of 52 regressors.
  warnings.warn(

2023-03-04 17:00:42,232:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=5.249e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,232:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.015e+02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,232:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=5.249e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,234:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.948e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,234:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=5.211e+01, previous alpha=4.391e+01, with an active set of 66 regressors.
  warnings.warn(

2023-03-04 17:00:42,236:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=8.005e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,237:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.629e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,238:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.829e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,239:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.759e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,243:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.782e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,246:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=4.649e+01, previous alpha=4.482e+01, with an active set of 69 regressors.
  warnings.warn(

2023-03-04 17:00:42,365:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,371:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.278e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.304e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.304e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:00:42,379:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.634e+01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,380:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.720e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,380:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.720e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,382:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.781e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,382:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.781e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,383:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.478e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,384:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.276e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,384:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.057e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,385:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.893e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,385:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.057e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,386:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.845e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,389:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.152e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,390:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.246e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,391:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=4.005e+01, previous alpha=3.769e+01, with an active set of 75 regressors.
  warnings.warn(

2023-03-04 17:00:42,394:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,394:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,394:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,395:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.463e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,398:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=8.194e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,400:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=7.522e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,400:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=7.522e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,401:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.134e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,401:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.134e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:00:42,403:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=7.105e+01, previous alpha=6.908e+01, with an active set of 60 regressors.
  warnings.warn(

2023-03-04 17:00:42,456:INFO:Calculating mean and std
2023-03-04 17:00:42,458:INFO:Creating metrics dataframe
2023-03-04 17:00:42,464:INFO:Uploading results into container
2023-03-04 17:00:42,465:INFO:Uploading model into container now
2023-03-04 17:00:42,467:INFO:_master_model_container: 6
2023-03-04 17:00:42,467:INFO:_display_container: 2
2023-03-04 17:00:42,468:INFO:LassoLars(random_state=6865)
2023-03-04 17:00:42,469:INFO:create_model() successfully completed......................................
2023-03-04 17:00:42,594:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:42,594:INFO:Creating metrics dataframe
2023-03-04 17:00:42,607:INFO:Initializing Orthogonal Matching Pursuit
2023-03-04 17:00:42,607:INFO:Total runtime is 0.2887948393821716 minutes
2023-03-04 17:00:42,613:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:42,613:INFO:Initializing create_model()
2023-03-04 17:00:42,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:42,614:INFO:Checking exceptions
2023-03-04 17:00:42,614:INFO:Importing libraries
2023-03-04 17:00:42,614:INFO:Copying training dataset
2023-03-04 17:00:42,623:INFO:Defining folds
2023-03-04 17:00:42,623:INFO:Declaring metric variables
2023-03-04 17:00:42,628:INFO:Importing untrained model
2023-03-04 17:00:42,636:INFO:Orthogonal Matching Pursuit Imported successfully
2023-03-04 17:00:42,650:INFO:Starting cross validation
2023-03-04 17:00:42,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:42,774:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,817:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,816:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,841:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,841:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,856:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,874:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:42,999:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:00:43,049:INFO:Calculating mean and std
2023-03-04 17:00:43,051:INFO:Creating metrics dataframe
2023-03-04 17:00:43,055:INFO:Uploading results into container
2023-03-04 17:00:43,055:INFO:Uploading model into container now
2023-03-04 17:00:43,056:INFO:_master_model_container: 7
2023-03-04 17:00:43,056:INFO:_display_container: 2
2023-03-04 17:00:43,057:INFO:OrthogonalMatchingPursuit()
2023-03-04 17:00:43,057:INFO:create_model() successfully completed......................................
2023-03-04 17:00:43,185:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:43,185:INFO:Creating metrics dataframe
2023-03-04 17:00:43,203:INFO:Initializing Bayesian Ridge
2023-03-04 17:00:43,203:INFO:Total runtime is 0.2987342874209086 minutes
2023-03-04 17:00:43,208:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:43,208:INFO:Initializing create_model()
2023-03-04 17:00:43,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:43,209:INFO:Checking exceptions
2023-03-04 17:00:43,209:INFO:Importing libraries
2023-03-04 17:00:43,210:INFO:Copying training dataset
2023-03-04 17:00:43,218:INFO:Defining folds
2023-03-04 17:00:43,218:INFO:Declaring metric variables
2023-03-04 17:00:43,223:INFO:Importing untrained model
2023-03-04 17:00:43,230:INFO:Bayesian Ridge Imported successfully
2023-03-04 17:00:43,241:INFO:Starting cross validation
2023-03-04 17:00:43,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:43,664:INFO:Calculating mean and std
2023-03-04 17:00:43,667:INFO:Creating metrics dataframe
2023-03-04 17:00:43,673:INFO:Uploading results into container
2023-03-04 17:00:43,673:INFO:Uploading model into container now
2023-03-04 17:00:43,674:INFO:_master_model_container: 8
2023-03-04 17:00:43,674:INFO:_display_container: 2
2023-03-04 17:00:43,675:INFO:BayesianRidge()
2023-03-04 17:00:43,675:INFO:create_model() successfully completed......................................
2023-03-04 17:00:43,814:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:43,814:INFO:Creating metrics dataframe
2023-03-04 17:00:43,827:INFO:Initializing Passive Aggressive Regressor
2023-03-04 17:00:43,827:INFO:Total runtime is 0.3091319322586059 minutes
2023-03-04 17:00:43,832:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:43,833:INFO:Initializing create_model()
2023-03-04 17:00:43,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:43,833:INFO:Checking exceptions
2023-03-04 17:00:43,833:INFO:Importing libraries
2023-03-04 17:00:43,834:INFO:Copying training dataset
2023-03-04 17:00:43,846:INFO:Defining folds
2023-03-04 17:00:43,847:INFO:Declaring metric variables
2023-03-04 17:00:43,851:INFO:Importing untrained model
2023-03-04 17:00:43,859:INFO:Passive Aggressive Regressor Imported successfully
2023-03-04 17:00:43,874:INFO:Starting cross validation
2023-03-04 17:00:43,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:44,280:INFO:Calculating mean and std
2023-03-04 17:00:44,282:INFO:Creating metrics dataframe
2023-03-04 17:00:44,287:INFO:Uploading results into container
2023-03-04 17:00:44,288:INFO:Uploading model into container now
2023-03-04 17:00:44,288:INFO:_master_model_container: 9
2023-03-04 17:00:44,288:INFO:_display_container: 2
2023-03-04 17:00:44,289:INFO:PassiveAggressiveRegressor(random_state=6865)
2023-03-04 17:00:44,289:INFO:create_model() successfully completed......................................
2023-03-04 17:00:44,416:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:44,416:INFO:Creating metrics dataframe
2023-03-04 17:00:44,430:INFO:Initializing Huber Regressor
2023-03-04 17:00:44,430:INFO:Total runtime is 0.3191883325576782 minutes
2023-03-04 17:00:44,435:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:44,436:INFO:Initializing create_model()
2023-03-04 17:00:44,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:44,437:INFO:Checking exceptions
2023-03-04 17:00:44,437:INFO:Importing libraries
2023-03-04 17:00:44,437:INFO:Copying training dataset
2023-03-04 17:00:44,445:INFO:Defining folds
2023-03-04 17:00:44,446:INFO:Declaring metric variables
2023-03-04 17:00:44,451:INFO:Importing untrained model
2023-03-04 17:00:44,457:INFO:Huber Regressor Imported successfully
2023-03-04 17:00:44,471:INFO:Starting cross validation
2023-03-04 17:00:44,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:44,799:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:44,854:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:44,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:44,881:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:44,929:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:44,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:44,949:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:44,962:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:45,412:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:45,491:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:45,656:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:45,693:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:00:45,958:INFO:Calculating mean and std
2023-03-04 17:00:45,960:INFO:Creating metrics dataframe
2023-03-04 17:00:45,964:INFO:Uploading results into container
2023-03-04 17:00:45,965:INFO:Uploading model into container now
2023-03-04 17:00:45,966:INFO:_master_model_container: 10
2023-03-04 17:00:45,966:INFO:_display_container: 2
2023-03-04 17:00:45,966:INFO:HuberRegressor()
2023-03-04 17:00:45,967:INFO:create_model() successfully completed......................................
2023-03-04 17:00:46,097:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:46,098:INFO:Creating metrics dataframe
2023-03-04 17:00:46,111:INFO:Initializing K Neighbors Regressor
2023-03-04 17:00:46,112:INFO:Total runtime is 0.347213339805603 minutes
2023-03-04 17:00:46,116:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:46,117:INFO:Initializing create_model()
2023-03-04 17:00:46,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:46,117:INFO:Checking exceptions
2023-03-04 17:00:46,117:INFO:Importing libraries
2023-03-04 17:00:46,117:INFO:Copying training dataset
2023-03-04 17:00:46,127:INFO:Defining folds
2023-03-04 17:00:46,128:INFO:Declaring metric variables
2023-03-04 17:00:46,134:INFO:Importing untrained model
2023-03-04 17:00:46,141:INFO:K Neighbors Regressor Imported successfully
2023-03-04 17:00:46,156:INFO:Starting cross validation
2023-03-04 17:00:46,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:46,593:INFO:Calculating mean and std
2023-03-04 17:00:46,595:INFO:Creating metrics dataframe
2023-03-04 17:00:46,600:INFO:Uploading results into container
2023-03-04 17:00:46,600:INFO:Uploading model into container now
2023-03-04 17:00:46,601:INFO:_master_model_container: 11
2023-03-04 17:00:46,601:INFO:_display_container: 2
2023-03-04 17:00:46,602:INFO:KNeighborsRegressor(n_jobs=-1)
2023-03-04 17:00:46,602:INFO:create_model() successfully completed......................................
2023-03-04 17:00:46,731:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:46,731:INFO:Creating metrics dataframe
2023-03-04 17:00:46,746:INFO:Initializing Decision Tree Regressor
2023-03-04 17:00:46,747:INFO:Total runtime is 0.3578017155329386 minutes
2023-03-04 17:00:46,751:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:46,752:INFO:Initializing create_model()
2023-03-04 17:00:46,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:46,753:INFO:Checking exceptions
2023-03-04 17:00:46,753:INFO:Importing libraries
2023-03-04 17:00:46,753:INFO:Copying training dataset
2023-03-04 17:00:46,765:INFO:Defining folds
2023-03-04 17:00:46,765:INFO:Declaring metric variables
2023-03-04 17:00:46,773:INFO:Importing untrained model
2023-03-04 17:00:46,780:INFO:Decision Tree Regressor Imported successfully
2023-03-04 17:00:46,793:INFO:Starting cross validation
2023-03-04 17:00:46,796:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:47,261:INFO:Calculating mean and std
2023-03-04 17:00:47,264:INFO:Creating metrics dataframe
2023-03-04 17:00:47,269:INFO:Uploading results into container
2023-03-04 17:00:47,269:INFO:Uploading model into container now
2023-03-04 17:00:47,270:INFO:_master_model_container: 12
2023-03-04 17:00:47,270:INFO:_display_container: 2
2023-03-04 17:00:47,271:INFO:DecisionTreeRegressor(random_state=6865)
2023-03-04 17:00:47,271:INFO:create_model() successfully completed......................................
2023-03-04 17:00:47,402:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:47,403:INFO:Creating metrics dataframe
2023-03-04 17:00:47,418:INFO:Initializing Random Forest Regressor
2023-03-04 17:00:47,418:INFO:Total runtime is 0.3689811031023661 minutes
2023-03-04 17:00:47,423:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:47,423:INFO:Initializing create_model()
2023-03-04 17:00:47,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:47,423:INFO:Checking exceptions
2023-03-04 17:00:47,424:INFO:Importing libraries
2023-03-04 17:00:47,424:INFO:Copying training dataset
2023-03-04 17:00:47,434:INFO:Defining folds
2023-03-04 17:00:47,434:INFO:Declaring metric variables
2023-03-04 17:00:47,440:INFO:Importing untrained model
2023-03-04 17:00:47,446:INFO:Random Forest Regressor Imported successfully
2023-03-04 17:00:47,459:INFO:Starting cross validation
2023-03-04 17:00:47,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:48,975:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:49,050:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:49,112:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:49,121:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:49,137:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:49,147:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:49,207:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:49,251:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:50,223:INFO:Calculating mean and std
2023-03-04 17:00:50,226:INFO:Creating metrics dataframe
2023-03-04 17:00:50,230:INFO:Uploading results into container
2023-03-04 17:00:50,231:INFO:Uploading model into container now
2023-03-04 17:00:50,231:INFO:_master_model_container: 13
2023-03-04 17:00:50,232:INFO:_display_container: 2
2023-03-04 17:00:50,232:INFO:RandomForestRegressor(n_jobs=-1, random_state=6865)
2023-03-04 17:00:50,232:INFO:create_model() successfully completed......................................
2023-03-04 17:00:50,375:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:50,375:INFO:Creating metrics dataframe
2023-03-04 17:00:50,394:INFO:Initializing Extra Trees Regressor
2023-03-04 17:00:50,394:INFO:Total runtime is 0.4185819784800211 minutes
2023-03-04 17:00:50,399:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:50,400:INFO:Initializing create_model()
2023-03-04 17:00:50,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:50,400:INFO:Checking exceptions
2023-03-04 17:00:50,401:INFO:Importing libraries
2023-03-04 17:00:50,401:INFO:Copying training dataset
2023-03-04 17:00:50,413:INFO:Defining folds
2023-03-04 17:00:50,414:INFO:Declaring metric variables
2023-03-04 17:00:50,419:INFO:Importing untrained model
2023-03-04 17:00:50,427:INFO:Extra Trees Regressor Imported successfully
2023-03-04 17:00:50,441:INFO:Starting cross validation
2023-03-04 17:00:50,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:52,175:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:52,247:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:52,256:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:52,261:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:52,294:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:52,349:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:52,445:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:52,507:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:53,358:INFO:Calculating mean and std
2023-03-04 17:00:53,360:INFO:Creating metrics dataframe
2023-03-04 17:00:53,364:INFO:Uploading results into container
2023-03-04 17:00:53,365:INFO:Uploading model into container now
2023-03-04 17:00:53,365:INFO:_master_model_container: 14
2023-03-04 17:00:53,365:INFO:_display_container: 2
2023-03-04 17:00:53,366:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6865)
2023-03-04 17:00:53,366:INFO:create_model() successfully completed......................................
2023-03-04 17:00:53,496:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:53,496:INFO:Creating metrics dataframe
2023-03-04 17:00:53,511:INFO:Initializing AdaBoost Regressor
2023-03-04 17:00:53,511:INFO:Total runtime is 0.47053037087122596 minutes
2023-03-04 17:00:53,515:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:53,516:INFO:Initializing create_model()
2023-03-04 17:00:53,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:53,516:INFO:Checking exceptions
2023-03-04 17:00:53,517:INFO:Importing libraries
2023-03-04 17:00:53,517:INFO:Copying training dataset
2023-03-04 17:00:53,528:INFO:Defining folds
2023-03-04 17:00:53,529:INFO:Declaring metric variables
2023-03-04 17:00:53,534:INFO:Importing untrained model
2023-03-04 17:00:53,541:INFO:AdaBoost Regressor Imported successfully
2023-03-04 17:00:53,552:INFO:Starting cross validation
2023-03-04 17:00:53,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:54,532:INFO:Calculating mean and std
2023-03-04 17:00:54,534:INFO:Creating metrics dataframe
2023-03-04 17:00:54,539:INFO:Uploading results into container
2023-03-04 17:00:54,540:INFO:Uploading model into container now
2023-03-04 17:00:54,540:INFO:_master_model_container: 15
2023-03-04 17:00:54,541:INFO:_display_container: 2
2023-03-04 17:00:54,541:INFO:AdaBoostRegressor(random_state=6865)
2023-03-04 17:00:54,541:INFO:create_model() successfully completed......................................
2023-03-04 17:00:54,666:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:54,666:INFO:Creating metrics dataframe
2023-03-04 17:00:54,682:INFO:Initializing Gradient Boosting Regressor
2023-03-04 17:00:54,683:INFO:Total runtime is 0.490044895807902 minutes
2023-03-04 17:00:54,689:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:54,690:INFO:Initializing create_model()
2023-03-04 17:00:54,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:54,691:INFO:Checking exceptions
2023-03-04 17:00:54,691:INFO:Importing libraries
2023-03-04 17:00:54,691:INFO:Copying training dataset
2023-03-04 17:00:54,702:INFO:Defining folds
2023-03-04 17:00:54,702:INFO:Declaring metric variables
2023-03-04 17:00:54,709:INFO:Importing untrained model
2023-03-04 17:00:54,717:INFO:Gradient Boosting Regressor Imported successfully
2023-03-04 17:00:54,729:INFO:Starting cross validation
2023-03-04 17:00:54,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:55,740:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:55,741:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:55,756:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:55,779:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:55,793:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:55,794:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:55,837:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:55,883:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:56,550:INFO:Calculating mean and std
2023-03-04 17:00:56,552:INFO:Creating metrics dataframe
2023-03-04 17:00:56,556:INFO:Uploading results into container
2023-03-04 17:00:56,557:INFO:Uploading model into container now
2023-03-04 17:00:56,557:INFO:_master_model_container: 16
2023-03-04 17:00:56,557:INFO:_display_container: 2
2023-03-04 17:00:56,558:INFO:GradientBoostingRegressor(random_state=6865)
2023-03-04 17:00:56,558:INFO:create_model() successfully completed......................................
2023-03-04 17:00:56,679:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:56,679:INFO:Creating metrics dataframe
2023-03-04 17:00:56,700:INFO:Initializing Extreme Gradient Boosting
2023-03-04 17:00:56,701:INFO:Total runtime is 0.523704715569814 minutes
2023-03-04 17:00:56,706:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:56,706:INFO:Initializing create_model()
2023-03-04 17:00:56,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:56,706:INFO:Checking exceptions
2023-03-04 17:00:56,707:INFO:Importing libraries
2023-03-04 17:00:56,707:INFO:Copying training dataset
2023-03-04 17:00:56,718:INFO:Defining folds
2023-03-04 17:00:56,718:INFO:Declaring metric variables
2023-03-04 17:00:56,723:INFO:Importing untrained model
2023-03-04 17:00:56,732:INFO:Extreme Gradient Boosting Imported successfully
2023-03-04 17:00:56,742:INFO:Starting cross validation
2023-03-04 17:00:56,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:00:58,636:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-04 17:00:59,455:INFO:Calculating mean and std
2023-03-04 17:00:59,457:INFO:Creating metrics dataframe
2023-03-04 17:00:59,461:INFO:Uploading results into container
2023-03-04 17:00:59,462:INFO:Uploading model into container now
2023-03-04 17:00:59,463:INFO:_master_model_container: 17
2023-03-04 17:00:59,463:INFO:_display_container: 2
2023-03-04 17:00:59,464:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=6865, ...)
2023-03-04 17:00:59,464:INFO:create_model() successfully completed......................................
2023-03-04 17:00:59,584:INFO:SubProcess create_model() end ==================================
2023-03-04 17:00:59,584:INFO:Creating metrics dataframe
2023-03-04 17:00:59,603:INFO:Initializing Light Gradient Boosting Machine
2023-03-04 17:00:59,603:INFO:Total runtime is 0.5720674316088358 minutes
2023-03-04 17:00:59,609:INFO:SubProcess create_model() called ==================================
2023-03-04 17:00:59,609:INFO:Initializing create_model()
2023-03-04 17:00:59,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:00:59,610:INFO:Checking exceptions
2023-03-04 17:00:59,610:INFO:Importing libraries
2023-03-04 17:00:59,611:INFO:Copying training dataset
2023-03-04 17:00:59,622:INFO:Defining folds
2023-03-04 17:00:59,622:INFO:Declaring metric variables
2023-03-04 17:00:59,628:INFO:Importing untrained model
2023-03-04 17:00:59,635:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-04 17:00:59,646:INFO:Starting cross validation
2023-03-04 17:00:59,648:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:01:02,709:INFO:Calculating mean and std
2023-03-04 17:01:02,711:INFO:Creating metrics dataframe
2023-03-04 17:01:02,716:INFO:Uploading results into container
2023-03-04 17:01:02,717:INFO:Uploading model into container now
2023-03-04 17:01:02,717:INFO:_master_model_container: 18
2023-03-04 17:01:02,717:INFO:_display_container: 2
2023-03-04 17:01:02,718:INFO:LGBMRegressor(random_state=6865)
2023-03-04 17:01:02,719:INFO:create_model() successfully completed......................................
2023-03-04 17:01:02,849:INFO:SubProcess create_model() end ==================================
2023-03-04 17:01:02,850:INFO:Creating metrics dataframe
2023-03-04 17:01:02,866:INFO:Initializing Dummy Regressor
2023-03-04 17:01:02,867:INFO:Total runtime is 0.6264638026555378 minutes
2023-03-04 17:01:02,871:INFO:SubProcess create_model() called ==================================
2023-03-04 17:01:02,871:INFO:Initializing create_model()
2023-03-04 17:01:02,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BC65C9820>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:01:02,872:INFO:Checking exceptions
2023-03-04 17:01:02,872:INFO:Importing libraries
2023-03-04 17:01:02,872:INFO:Copying training dataset
2023-03-04 17:01:02,882:INFO:Defining folds
2023-03-04 17:01:02,882:INFO:Declaring metric variables
2023-03-04 17:01:02,887:INFO:Importing untrained model
2023-03-04 17:01:02,893:INFO:Dummy Regressor Imported successfully
2023-03-04 17:01:02,904:INFO:Starting cross validation
2023-03-04 17:01:02,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:01:03,304:INFO:Calculating mean and std
2023-03-04 17:01:03,306:INFO:Creating metrics dataframe
2023-03-04 17:01:03,311:INFO:Uploading results into container
2023-03-04 17:01:03,311:INFO:Uploading model into container now
2023-03-04 17:01:03,312:INFO:_master_model_container: 19
2023-03-04 17:01:03,312:INFO:_display_container: 2
2023-03-04 17:01:03,312:INFO:DummyRegressor()
2023-03-04 17:01:03,312:INFO:create_model() successfully completed......................................
2023-03-04 17:01:03,443:INFO:SubProcess create_model() end ==================================
2023-03-04 17:01:03,443:INFO:Creating metrics dataframe
2023-03-04 17:01:03,478:INFO:Initializing create_model()
2023-03-04 17:01:03,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:01:03,478:INFO:Checking exceptions
2023-03-04 17:01:03,481:INFO:Importing libraries
2023-03-04 17:01:03,482:INFO:Copying training dataset
2023-03-04 17:01:03,490:INFO:Defining folds
2023-03-04 17:01:03,491:INFO:Declaring metric variables
2023-03-04 17:01:03,491:INFO:Importing untrained model
2023-03-04 17:01:03,491:INFO:Declaring custom model
2023-03-04 17:01:03,491:INFO:Huber Regressor Imported successfully
2023-03-04 17:01:03,493:INFO:Cross validation set to False
2023-03-04 17:01:03,493:INFO:Fitting Model
2023-03-04 17:01:03,624:INFO:HuberRegressor()
2023-03-04 17:01:03,624:INFO:create_model() successfully completed......................................
2023-03-04 17:01:03,835:INFO:_master_model_container: 19
2023-03-04 17:01:03,836:INFO:_display_container: 2
2023-03-04 17:01:03,836:INFO:HuberRegressor()
2023-03-04 17:01:03,836:INFO:compare_models() successfully completed......................................
2023-03-04 17:02:04,766:INFO:Initializing evaluate_model()
2023-03-04 17:02:04,767:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-03-04 17:02:04,799:INFO:Initializing plot_model()
2023-03-04 17:02:04,799:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, system=True)
2023-03-04 17:02:04,800:INFO:Checking exceptions
2023-03-04 17:02:04,803:INFO:Preloading libraries
2023-03-04 17:02:04,803:INFO:Copying training dataset
2023-03-04 17:02:04,803:INFO:Plot type: pipeline
2023-03-04 17:02:05,059:INFO:Visual Rendered Successfully
2023-03-04 17:02:05,172:INFO:plot_model() successfully completed......................................
2023-03-04 17:02:21,679:INFO:Initializing plot_model()
2023-03-04 17:02:21,679:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, system=True)
2023-03-04 17:02:21,680:INFO:Checking exceptions
2023-03-04 17:02:21,684:INFO:Preloading libraries
2023-03-04 17:02:21,684:INFO:Copying training dataset
2023-03-04 17:02:21,684:INFO:Plot type: feature
2023-03-04 17:02:21,920:INFO:Visual Rendered Successfully
2023-03-04 17:02:22,041:INFO:plot_model() successfully completed......................................
2023-03-04 17:02:32,296:INFO:Initializing plot_model()
2023-03-04 17:02:32,297:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, system=True)
2023-03-04 17:02:32,297:INFO:Checking exceptions
2023-03-04 17:02:32,300:INFO:Preloading libraries
2023-03-04 17:02:32,301:INFO:Copying training dataset
2023-03-04 17:02:32,301:INFO:Plot type: parameter
2023-03-04 17:02:32,305:INFO:Visual Rendered Successfully
2023-03-04 17:02:32,418:INFO:plot_model() successfully completed......................................
2023-03-04 17:02:38,777:INFO:Initializing plot_model()
2023-03-04 17:02:38,777:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, system=True)
2023-03-04 17:02:38,778:INFO:Checking exceptions
2023-03-04 17:02:38,781:INFO:Preloading libraries
2023-03-04 17:02:38,781:INFO:Copying training dataset
2023-03-04 17:02:38,781:INFO:Plot type: pipeline
2023-03-04 17:02:38,854:INFO:Visual Rendered Successfully
2023-03-04 17:02:38,960:INFO:plot_model() successfully completed......................................
2023-03-04 17:04:23,936:INFO:Initializing predict_model()
2023-03-04 17:04:23,937:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC6DA9730>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000011BD294FF70>)
2023-03-04 17:04:23,937:INFO:Checking exceptions
2023-03-04 17:04:23,937:INFO:Preloading libraries
2023-03-04 17:04:23,939:INFO:Set up data.
2023-03-04 17:06:58,265:INFO:PyCaret RegressionExperiment
2023-03-04 17:06:58,265:INFO:Logging name: reg-default-name
2023-03-04 17:06:58,265:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-04 17:06:58,265:INFO:version 3.0.0.rc9
2023-03-04 17:06:58,266:INFO:Initializing setup()
2023-03-04 17:06:58,266:INFO:self.USI: aa84
2023-03-04 17:06:58,266:INFO:self._variable_keys: {'log_plots_param', 'pipeline', 'fold_generator', 'target_param', 'X_test', 'y_train', 'idx', 'data', 'seed', 'USI', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', '_ml_usecase', 'gpu_param', '_available_plots', 'y_test', 'fold_groups_param', 'logging_param', 'y', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_name_log', 'X_train', 'memory', 'X'}
2023-03-04 17:06:58,266:INFO:Checking environment
2023-03-04 17:06:58,266:INFO:python_version: 3.9.13
2023-03-04 17:06:58,266:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-04 17:06:58,266:INFO:machine: AMD64
2023-03-04 17:06:58,266:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-04 17:06:58,266:INFO:Memory: svmem(total=17009516544, available=3402575872, percent=80.0, used=13606940672, free=3402575872)
2023-03-04 17:06:58,266:INFO:Physical Core: 4
2023-03-04 17:06:58,266:INFO:Logical Core: 8
2023-03-04 17:06:58,266:INFO:Checking libraries
2023-03-04 17:06:58,266:INFO:System:
2023-03-04 17:06:58,266:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-04 17:06:58,266:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-04 17:06:58,266:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-04 17:06:58,266:INFO:PyCaret required dependencies:
2023-03-04 17:06:58,266:INFO:                 pip: 22.2.2
2023-03-04 17:06:58,267:INFO:          setuptools: 63.4.1
2023-03-04 17:06:58,267:INFO:             pycaret: 3.0.0rc9
2023-03-04 17:06:58,267:INFO:             IPython: 7.31.1
2023-03-04 17:06:58,267:INFO:          ipywidgets: 7.6.5
2023-03-04 17:06:58,267:INFO:                tqdm: 4.64.1
2023-03-04 17:06:58,267:INFO:               numpy: 1.21.5
2023-03-04 17:06:58,267:INFO:              pandas: 1.4.4
2023-03-04 17:06:58,267:INFO:              jinja2: 2.11.3
2023-03-04 17:06:58,267:INFO:               scipy: 1.9.1
2023-03-04 17:06:58,267:INFO:              joblib: 1.2.0
2023-03-04 17:06:58,267:INFO:             sklearn: 1.0.2
2023-03-04 17:06:58,267:INFO:                pyod: 1.0.7
2023-03-04 17:06:58,267:INFO:            imblearn: 0.10.1
2023-03-04 17:06:58,267:INFO:   category_encoders: 2.6.0
2023-03-04 17:06:58,267:INFO:            lightgbm: 3.3.5
2023-03-04 17:06:58,267:INFO:               numba: 0.55.1
2023-03-04 17:06:58,267:INFO:            requests: 2.28.1
2023-03-04 17:06:58,267:INFO:          matplotlib: 3.5.2
2023-03-04 17:06:58,267:INFO:          scikitplot: 0.3.7
2023-03-04 17:06:58,267:INFO:         yellowbrick: 1.5
2023-03-04 17:06:58,267:INFO:              plotly: 5.9.0
2023-03-04 17:06:58,267:INFO:             kaleido: 0.2.1
2023-03-04 17:06:58,267:INFO:         statsmodels: 0.13.2
2023-03-04 17:06:58,267:INFO:              sktime: 0.16.1
2023-03-04 17:06:58,268:INFO:               tbats: 1.1.2
2023-03-04 17:06:58,268:INFO:            pmdarima: 2.0.2
2023-03-04 17:06:58,268:INFO:              psutil: 5.9.0
2023-03-04 17:06:58,268:INFO:PyCaret optional dependencies:
2023-03-04 17:06:58,268:INFO:                shap: Not installed
2023-03-04 17:06:58,268:INFO:           interpret: Not installed
2023-03-04 17:06:58,268:INFO:                umap: Not installed
2023-03-04 17:06:58,268:INFO:    pandas_profiling: Not installed
2023-03-04 17:06:58,268:INFO:  explainerdashboard: Not installed
2023-03-04 17:06:58,268:INFO:             autoviz: Not installed
2023-03-04 17:06:58,268:INFO:           fairlearn: Not installed
2023-03-04 17:06:58,268:INFO:             xgboost: 1.7.4
2023-03-04 17:06:58,268:INFO:            catboost: Not installed
2023-03-04 17:06:58,268:INFO:              kmodes: Not installed
2023-03-04 17:06:58,268:INFO:             mlxtend: Not installed
2023-03-04 17:06:58,268:INFO:       statsforecast: Not installed
2023-03-04 17:06:58,268:INFO:        tune_sklearn: Not installed
2023-03-04 17:06:58,268:INFO:                 ray: Not installed
2023-03-04 17:06:58,268:INFO:            hyperopt: Not installed
2023-03-04 17:06:58,268:INFO:              optuna: Not installed
2023-03-04 17:06:58,268:INFO:               skopt: Not installed
2023-03-04 17:06:58,268:INFO:              mlflow: Not installed
2023-03-04 17:06:58,268:INFO:              gradio: Not installed
2023-03-04 17:06:58,269:INFO:             fastapi: Not installed
2023-03-04 17:06:58,269:INFO:             uvicorn: Not installed
2023-03-04 17:06:58,269:INFO:              m2cgen: Not installed
2023-03-04 17:06:58,269:INFO:           evidently: Not installed
2023-03-04 17:06:58,269:INFO:               fugue: Not installed
2023-03-04 17:06:58,269:INFO:           streamlit: Not installed
2023-03-04 17:06:58,269:INFO:             prophet: Not installed
2023-03-04 17:06:58,269:INFO:None
2023-03-04 17:06:58,269:INFO:Set up data.
2023-03-04 17:06:58,310:INFO:Set up train/test split.
2023-03-04 17:06:58,314:INFO:Set up index.
2023-03-04 17:06:58,314:INFO:Set up folding strategy.
2023-03-04 17:06:58,314:INFO:Assigning column types.
2023-03-04 17:06:58,317:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-04 17:06:58,318:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,322:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,326:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,380:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,421:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:58,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:58,424:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,428:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,432:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,527:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,528:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:58,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:58,530:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-04 17:06:58,535:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,540:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,634:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:58,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:58,640:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,740:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:58,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:58,743:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-04 17:06:58,751:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,846:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:58,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:58,857:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:58,950:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:58,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:58,952:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-04 17:06:59,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:59,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:59,053:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:59,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:59,116:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:59,157:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:06:59,157:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:59,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:59,160:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-04 17:06:59,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:59,268:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:59,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:59,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:06:59,375:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:59,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:59,378:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-04 17:06:59,492:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:59,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:59,604:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:59,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:06:59,607:INFO:Preparing preprocessing pipeline...
2023-03-04 17:06:59,608:INFO:Set up column name cleaning.
2023-03-04 17:06:59,608:INFO:Set up simple imputation.
2023-03-04 17:06:59,637:INFO:Finished creating preprocessing pipeline.
2023-03-04 17:06:59,642:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Alvaro\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['work_year', 'remote_ratio',
                                             'experience_level_EX',
                                             'experience_level_MI',
                                             'experience_level_SE',
                                             'employment_type_FL',
                                             'employment_type_FT',
                                             'emplo...
                                             'job_title_Data Architect',
                                             'job_title_Data Engineer',
                                             'job_title_Data Engineering '
                                             'Manager',
                                             'job_title_Data Science '
                                             'Consultant',
                                             'job_title_Data Science Engineer',
                                             'job_title_Data Science Manager',
                                             'job_title_Data Scientist', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-03-04 17:06:59,642:INFO:Creating final display dataframe.
2023-03-04 17:06:59,820:INFO:Setup _display_container:                     Description             Value
0                    Session id              1873
1                        Target     salary_in_usd
2                   Target type        Regression
3           Original data shape        (499, 165)
4        Transformed data shape        (499, 165)
5   Transformed train set shape        (349, 165)
6    Transformed test set shape        (150, 165)
7              Numeric features               164
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              aa84
2023-03-04 17:06:59,943:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:06:59,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:07:00,058:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:07:00,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:07:00,061:INFO:setup() successfully completed in 1.8s...............
2023-03-04 17:07:18,277:INFO:PyCaret RegressionExperiment
2023-03-04 17:07:18,277:INFO:Logging name: reg-default-name
2023-03-04 17:07:18,277:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-04 17:07:18,277:INFO:version 3.0.0.rc9
2023-03-04 17:07:18,277:INFO:Initializing setup()
2023-03-04 17:07:18,277:INFO:self.USI: e4a5
2023-03-04 17:07:18,277:INFO:self._variable_keys: {'log_plots_param', 'pipeline', 'fold_generator', 'target_param', 'X_test', 'y_train', 'idx', 'data', 'seed', 'USI', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', '_ml_usecase', 'gpu_param', '_available_plots', 'y_test', 'fold_groups_param', 'logging_param', 'y', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_name_log', 'X_train', 'memory', 'X'}
2023-03-04 17:07:18,278:INFO:Checking environment
2023-03-04 17:07:18,278:INFO:python_version: 3.9.13
2023-03-04 17:07:18,278:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-04 17:07:18,278:INFO:machine: AMD64
2023-03-04 17:07:18,278:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-04 17:07:18,278:INFO:Memory: svmem(total=17009516544, available=3376713728, percent=80.1, used=13632802816, free=3376713728)
2023-03-04 17:07:18,278:INFO:Physical Core: 4
2023-03-04 17:07:18,278:INFO:Logical Core: 8
2023-03-04 17:07:18,278:INFO:Checking libraries
2023-03-04 17:07:18,278:INFO:System:
2023-03-04 17:07:18,278:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-04 17:07:18,278:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-04 17:07:18,278:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-04 17:07:18,279:INFO:PyCaret required dependencies:
2023-03-04 17:07:18,279:INFO:                 pip: 22.2.2
2023-03-04 17:07:18,279:INFO:          setuptools: 63.4.1
2023-03-04 17:07:18,279:INFO:             pycaret: 3.0.0rc9
2023-03-04 17:07:18,279:INFO:             IPython: 7.31.1
2023-03-04 17:07:18,279:INFO:          ipywidgets: 7.6.5
2023-03-04 17:07:18,279:INFO:                tqdm: 4.64.1
2023-03-04 17:07:18,279:INFO:               numpy: 1.21.5
2023-03-04 17:07:18,279:INFO:              pandas: 1.4.4
2023-03-04 17:07:18,279:INFO:              jinja2: 2.11.3
2023-03-04 17:07:18,279:INFO:               scipy: 1.9.1
2023-03-04 17:07:18,279:INFO:              joblib: 1.2.0
2023-03-04 17:07:18,279:INFO:             sklearn: 1.0.2
2023-03-04 17:07:18,280:INFO:                pyod: 1.0.7
2023-03-04 17:07:18,280:INFO:            imblearn: 0.10.1
2023-03-04 17:07:18,280:INFO:   category_encoders: 2.6.0
2023-03-04 17:07:18,280:INFO:            lightgbm: 3.3.5
2023-03-04 17:07:18,280:INFO:               numba: 0.55.1
2023-03-04 17:07:18,280:INFO:            requests: 2.28.1
2023-03-04 17:07:18,280:INFO:          matplotlib: 3.5.2
2023-03-04 17:07:18,280:INFO:          scikitplot: 0.3.7
2023-03-04 17:07:18,280:INFO:         yellowbrick: 1.5
2023-03-04 17:07:18,280:INFO:              plotly: 5.9.0
2023-03-04 17:07:18,280:INFO:             kaleido: 0.2.1
2023-03-04 17:07:18,280:INFO:         statsmodels: 0.13.2
2023-03-04 17:07:18,280:INFO:              sktime: 0.16.1
2023-03-04 17:07:18,280:INFO:               tbats: 1.1.2
2023-03-04 17:07:18,280:INFO:            pmdarima: 2.0.2
2023-03-04 17:07:18,280:INFO:              psutil: 5.9.0
2023-03-04 17:07:18,280:INFO:PyCaret optional dependencies:
2023-03-04 17:07:18,281:INFO:                shap: Not installed
2023-03-04 17:07:18,281:INFO:           interpret: Not installed
2023-03-04 17:07:18,281:INFO:                umap: Not installed
2023-03-04 17:07:18,281:INFO:    pandas_profiling: Not installed
2023-03-04 17:07:18,281:INFO:  explainerdashboard: Not installed
2023-03-04 17:07:18,281:INFO:             autoviz: Not installed
2023-03-04 17:07:18,281:INFO:           fairlearn: Not installed
2023-03-04 17:07:18,281:INFO:             xgboost: 1.7.4
2023-03-04 17:07:18,281:INFO:            catboost: Not installed
2023-03-04 17:07:18,281:INFO:              kmodes: Not installed
2023-03-04 17:07:18,281:INFO:             mlxtend: Not installed
2023-03-04 17:07:18,281:INFO:       statsforecast: Not installed
2023-03-04 17:07:18,281:INFO:        tune_sklearn: Not installed
2023-03-04 17:07:18,281:INFO:                 ray: Not installed
2023-03-04 17:07:18,281:INFO:            hyperopt: Not installed
2023-03-04 17:07:18,281:INFO:              optuna: Not installed
2023-03-04 17:07:18,281:INFO:               skopt: Not installed
2023-03-04 17:07:18,281:INFO:              mlflow: Not installed
2023-03-04 17:07:18,281:INFO:              gradio: Not installed
2023-03-04 17:07:18,281:INFO:             fastapi: Not installed
2023-03-04 17:07:18,281:INFO:             uvicorn: Not installed
2023-03-04 17:07:18,281:INFO:              m2cgen: Not installed
2023-03-04 17:07:18,281:INFO:           evidently: Not installed
2023-03-04 17:07:18,281:INFO:               fugue: Not installed
2023-03-04 17:07:18,282:INFO:           streamlit: Not installed
2023-03-04 17:07:18,282:INFO:             prophet: Not installed
2023-03-04 17:07:18,282:INFO:None
2023-03-04 17:07:18,282:INFO:Set up data.
2023-03-04 17:09:03,017:INFO:PyCaret RegressionExperiment
2023-03-04 17:09:03,017:INFO:Logging name: reg-default-name
2023-03-04 17:09:03,017:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-04 17:09:03,018:INFO:version 3.0.0.rc9
2023-03-04 17:09:03,018:INFO:Initializing setup()
2023-03-04 17:09:03,018:INFO:self.USI: 3d6c
2023-03-04 17:09:03,018:INFO:self._variable_keys: {'log_plots_param', 'pipeline', 'fold_generator', 'target_param', 'X_test', 'y_train', 'idx', 'data', 'seed', 'USI', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', '_ml_usecase', 'gpu_param', '_available_plots', 'y_test', 'fold_groups_param', 'logging_param', 'y', 'html_param', 'fold_shuffle_param', 'transform_target_param', 'exp_name_log', 'X_train', 'memory', 'X'}
2023-03-04 17:09:03,018:INFO:Checking environment
2023-03-04 17:09:03,018:INFO:python_version: 3.9.13
2023-03-04 17:09:03,018:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-04 17:09:03,018:INFO:machine: AMD64
2023-03-04 17:09:03,018:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-04 17:09:03,018:INFO:Memory: svmem(total=17009516544, available=3412193280, percent=79.9, used=13597323264, free=3412193280)
2023-03-04 17:09:03,018:INFO:Physical Core: 4
2023-03-04 17:09:03,018:INFO:Logical Core: 8
2023-03-04 17:09:03,018:INFO:Checking libraries
2023-03-04 17:09:03,018:INFO:System:
2023-03-04 17:09:03,018:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-04 17:09:03,018:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-04 17:09:03,018:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-04 17:09:03,018:INFO:PyCaret required dependencies:
2023-03-04 17:09:03,019:INFO:                 pip: 22.2.2
2023-03-04 17:09:03,019:INFO:          setuptools: 63.4.1
2023-03-04 17:09:03,019:INFO:             pycaret: 3.0.0rc9
2023-03-04 17:09:03,019:INFO:             IPython: 7.31.1
2023-03-04 17:09:03,019:INFO:          ipywidgets: 7.6.5
2023-03-04 17:09:03,019:INFO:                tqdm: 4.64.1
2023-03-04 17:09:03,019:INFO:               numpy: 1.21.5
2023-03-04 17:09:03,019:INFO:              pandas: 1.4.4
2023-03-04 17:09:03,019:INFO:              jinja2: 2.11.3
2023-03-04 17:09:03,019:INFO:               scipy: 1.9.1
2023-03-04 17:09:03,019:INFO:              joblib: 1.2.0
2023-03-04 17:09:03,019:INFO:             sklearn: 1.0.2
2023-03-04 17:09:03,019:INFO:                pyod: 1.0.7
2023-03-04 17:09:03,019:INFO:            imblearn: 0.10.1
2023-03-04 17:09:03,019:INFO:   category_encoders: 2.6.0
2023-03-04 17:09:03,019:INFO:            lightgbm: 3.3.5
2023-03-04 17:09:03,019:INFO:               numba: 0.55.1
2023-03-04 17:09:03,019:INFO:            requests: 2.28.1
2023-03-04 17:09:03,019:INFO:          matplotlib: 3.5.2
2023-03-04 17:09:03,019:INFO:          scikitplot: 0.3.7
2023-03-04 17:09:03,019:INFO:         yellowbrick: 1.5
2023-03-04 17:09:03,019:INFO:              plotly: 5.9.0
2023-03-04 17:09:03,019:INFO:             kaleido: 0.2.1
2023-03-04 17:09:03,020:INFO:         statsmodels: 0.13.2
2023-03-04 17:09:03,020:INFO:              sktime: 0.16.1
2023-03-04 17:09:03,020:INFO:               tbats: 1.1.2
2023-03-04 17:09:03,020:INFO:            pmdarima: 2.0.2
2023-03-04 17:09:03,020:INFO:              psutil: 5.9.0
2023-03-04 17:09:03,020:INFO:PyCaret optional dependencies:
2023-03-04 17:09:03,020:INFO:                shap: Not installed
2023-03-04 17:09:03,020:INFO:           interpret: Not installed
2023-03-04 17:09:03,020:INFO:                umap: Not installed
2023-03-04 17:09:03,020:INFO:    pandas_profiling: Not installed
2023-03-04 17:09:03,020:INFO:  explainerdashboard: Not installed
2023-03-04 17:09:03,020:INFO:             autoviz: Not installed
2023-03-04 17:09:03,020:INFO:           fairlearn: Not installed
2023-03-04 17:09:03,020:INFO:             xgboost: 1.7.4
2023-03-04 17:09:03,020:INFO:            catboost: Not installed
2023-03-04 17:09:03,020:INFO:              kmodes: Not installed
2023-03-04 17:09:03,020:INFO:             mlxtend: Not installed
2023-03-04 17:09:03,020:INFO:       statsforecast: Not installed
2023-03-04 17:09:03,020:INFO:        tune_sklearn: Not installed
2023-03-04 17:09:03,020:INFO:                 ray: Not installed
2023-03-04 17:09:03,020:INFO:            hyperopt: Not installed
2023-03-04 17:09:03,020:INFO:              optuna: Not installed
2023-03-04 17:09:03,020:INFO:               skopt: Not installed
2023-03-04 17:09:03,020:INFO:              mlflow: Not installed
2023-03-04 17:09:03,021:INFO:              gradio: Not installed
2023-03-04 17:09:03,021:INFO:             fastapi: Not installed
2023-03-04 17:09:03,021:INFO:             uvicorn: Not installed
2023-03-04 17:09:03,021:INFO:              m2cgen: Not installed
2023-03-04 17:09:03,021:INFO:           evidently: Not installed
2023-03-04 17:09:03,021:INFO:               fugue: Not installed
2023-03-04 17:09:03,021:INFO:           streamlit: Not installed
2023-03-04 17:09:03,021:INFO:             prophet: Not installed
2023-03-04 17:09:03,021:INFO:None
2023-03-04 17:09:03,021:INFO:Set up data.
2023-03-04 17:09:03,058:INFO:Set up train/test split.
2023-03-04 17:09:03,065:INFO:Set up index.
2023-03-04 17:09:03,065:INFO:Set up folding strategy.
2023-03-04 17:09:03,065:INFO:Assigning column types.
2023-03-04 17:09:03,068:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-04 17:09:03,068:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,073:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,077:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,132:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,173:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,176:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,180:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,238:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,279:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,282:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-04 17:09:03,287:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,292:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,345:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,387:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,394:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,398:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,452:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,492:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,495:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-04 17:09:03,506:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,601:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,612:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,707:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,708:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,711:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-04 17:09:03,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,813:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,880:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:09:03,920:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:03,922:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:03,923:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-04 17:09:03,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:04,021:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:04,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:04,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:09:04,123:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:04,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:04,126:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-04 17:09:04,232:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:04,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:04,336:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:04,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:04,340:INFO:Preparing preprocessing pipeline...
2023-03-04 17:09:04,341:INFO:Set up column name cleaning.
2023-03-04 17:09:04,341:INFO:Set up simple imputation.
2023-03-04 17:09:04,370:INFO:Finished creating preprocessing pipeline.
2023-03-04 17:09:04,375:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Alvaro\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['work_year', 'remote_ratio',
                                             'experience_level_EX',
                                             'experience_level_MI',
                                             'experience_level_SE',
                                             'employment_type_FL',
                                             'employment_type_FT',
                                             'emplo...
                                             'job_title_Data Architect',
                                             'job_title_Data Engineer',
                                             'job_title_Data Engineering '
                                             'Manager',
                                             'job_title_Data Science '
                                             'Consultant',
                                             'job_title_Data Science Engineer',
                                             'job_title_Data Science Manager',
                                             'job_title_Data Scientist', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-03-04 17:09:04,375:INFO:Creating final display dataframe.
2023-03-04 17:09:04,552:INFO:Setup _display_container:                     Description             Value
0                    Session id              1516
1                        Target     salary_in_usd
2                   Target type        Regression
3           Original data shape        (499, 165)
4        Transformed data shape        (499, 165)
5   Transformed train set shape        (349, 165)
6    Transformed test set shape        (150, 165)
7              Numeric features               164
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3d6c
2023-03-04 17:09:04,670:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:04,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:04,772:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:09:04,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:09:04,774:INFO:setup() successfully completed in 1.76s...............
2023-03-04 17:09:06,457:INFO:Initializing compare_models()
2023-03-04 17:09:06,457:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-03-04 17:09:06,458:INFO:Checking exceptions
2023-03-04 17:09:06,461:INFO:Preparing display monitor
2023-03-04 17:09:06,512:INFO:Initializing Linear Regression
2023-03-04 17:09:06,512:INFO:Total runtime is 0.0 minutes
2023-03-04 17:09:06,522:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:06,523:INFO:Initializing create_model()
2023-03-04 17:09:06,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:06,523:INFO:Checking exceptions
2023-03-04 17:09:06,523:INFO:Importing libraries
2023-03-04 17:09:06,523:INFO:Copying training dataset
2023-03-04 17:09:06,535:INFO:Defining folds
2023-03-04 17:09:06,535:INFO:Declaring metric variables
2023-03-04 17:09:06,538:INFO:Importing untrained model
2023-03-04 17:09:06,541:INFO:Linear Regression Imported successfully
2023-03-04 17:09:06,551:INFO:Starting cross validation
2023-03-04 17:09:06,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:14,215:INFO:Calculating mean and std
2023-03-04 17:09:14,216:INFO:Creating metrics dataframe
2023-03-04 17:09:14,219:INFO:Uploading results into container
2023-03-04 17:09:14,219:INFO:Uploading model into container now
2023-03-04 17:09:14,220:INFO:_master_model_container: 1
2023-03-04 17:09:14,220:INFO:_display_container: 2
2023-03-04 17:09:14,220:INFO:LinearRegression(n_jobs=-1)
2023-03-04 17:09:14,220:INFO:create_model() successfully completed......................................
2023-03-04 17:09:14,323:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:14,324:INFO:Creating metrics dataframe
2023-03-04 17:09:14,330:INFO:Initializing Lasso Regression
2023-03-04 17:09:14,330:INFO:Total runtime is 0.13031154076258342 minutes
2023-03-04 17:09:14,335:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:14,335:INFO:Initializing create_model()
2023-03-04 17:09:14,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:14,335:INFO:Checking exceptions
2023-03-04 17:09:14,336:INFO:Importing libraries
2023-03-04 17:09:14,336:INFO:Copying training dataset
2023-03-04 17:09:14,344:INFO:Defining folds
2023-03-04 17:09:14,345:INFO:Declaring metric variables
2023-03-04 17:09:14,348:INFO:Importing untrained model
2023-03-04 17:09:14,352:INFO:Lasso Regression Imported successfully
2023-03-04 17:09:14,363:INFO:Starting cross validation
2023-03-04 17:09:14,365:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:14,523:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+10, tolerance: 1.565e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,535:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+09, tolerance: 1.535e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,567:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+10, tolerance: 1.583e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,573:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e+10, tolerance: 1.571e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,586:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+10, tolerance: 1.491e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,602:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+10, tolerance: 1.491e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,615:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+10, tolerance: 1.587e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,689:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e+10, tolerance: 1.413e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,693:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.733e+10, tolerance: 1.527e+08
  model = cd_fast.enet_coordinate_descent(

2023-03-04 17:09:14,720:INFO:Calculating mean and std
2023-03-04 17:09:14,722:INFO:Creating metrics dataframe
2023-03-04 17:09:14,725:INFO:Uploading results into container
2023-03-04 17:09:14,726:INFO:Uploading model into container now
2023-03-04 17:09:14,726:INFO:_master_model_container: 2
2023-03-04 17:09:14,726:INFO:_display_container: 2
2023-03-04 17:09:14,727:INFO:Lasso(random_state=1516)
2023-03-04 17:09:14,727:INFO:create_model() successfully completed......................................
2023-03-04 17:09:14,824:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:14,824:INFO:Creating metrics dataframe
2023-03-04 17:09:14,835:INFO:Initializing Ridge Regression
2023-03-04 17:09:14,835:INFO:Total runtime is 0.13872245947519937 minutes
2023-03-04 17:09:14,842:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:14,842:INFO:Initializing create_model()
2023-03-04 17:09:14,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:14,843:INFO:Checking exceptions
2023-03-04 17:09:14,843:INFO:Importing libraries
2023-03-04 17:09:14,843:INFO:Copying training dataset
2023-03-04 17:09:14,849:INFO:Defining folds
2023-03-04 17:09:14,849:INFO:Declaring metric variables
2023-03-04 17:09:14,852:INFO:Importing untrained model
2023-03-04 17:09:14,860:INFO:Ridge Regression Imported successfully
2023-03-04 17:09:14,868:INFO:Starting cross validation
2023-03-04 17:09:14,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:15,139:INFO:Calculating mean and std
2023-03-04 17:09:15,140:INFO:Creating metrics dataframe
2023-03-04 17:09:15,143:INFO:Uploading results into container
2023-03-04 17:09:15,143:INFO:Uploading model into container now
2023-03-04 17:09:15,144:INFO:_master_model_container: 3
2023-03-04 17:09:15,144:INFO:_display_container: 2
2023-03-04 17:09:15,144:INFO:Ridge(random_state=1516)
2023-03-04 17:09:15,144:INFO:create_model() successfully completed......................................
2023-03-04 17:09:15,248:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:15,249:INFO:Creating metrics dataframe
2023-03-04 17:09:15,259:INFO:Initializing Elastic Net
2023-03-04 17:09:15,259:INFO:Total runtime is 0.1457809527715047 minutes
2023-03-04 17:09:15,263:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:15,263:INFO:Initializing create_model()
2023-03-04 17:09:15,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:15,264:INFO:Checking exceptions
2023-03-04 17:09:15,264:INFO:Importing libraries
2023-03-04 17:09:15,264:INFO:Copying training dataset
2023-03-04 17:09:15,270:INFO:Defining folds
2023-03-04 17:09:15,270:INFO:Declaring metric variables
2023-03-04 17:09:15,275:INFO:Importing untrained model
2023-03-04 17:09:15,280:INFO:Elastic Net Imported successfully
2023-03-04 17:09:15,288:INFO:Starting cross validation
2023-03-04 17:09:15,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:15,570:INFO:Calculating mean and std
2023-03-04 17:09:15,571:INFO:Creating metrics dataframe
2023-03-04 17:09:15,574:INFO:Uploading results into container
2023-03-04 17:09:15,574:INFO:Uploading model into container now
2023-03-04 17:09:15,574:INFO:_master_model_container: 4
2023-03-04 17:09:15,575:INFO:_display_container: 2
2023-03-04 17:09:15,575:INFO:ElasticNet(random_state=1516)
2023-03-04 17:09:15,575:INFO:create_model() successfully completed......................................
2023-03-04 17:09:15,672:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:15,672:INFO:Creating metrics dataframe
2023-03-04 17:09:15,684:INFO:Initializing Least Angle Regression
2023-03-04 17:09:15,684:INFO:Total runtime is 0.1528620481491089 minutes
2023-03-04 17:09:15,687:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:15,688:INFO:Initializing create_model()
2023-03-04 17:09:15,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:15,688:INFO:Checking exceptions
2023-03-04 17:09:15,688:INFO:Importing libraries
2023-03-04 17:09:15,689:INFO:Copying training dataset
2023-03-04 17:09:15,697:INFO:Defining folds
2023-03-04 17:09:15,698:INFO:Declaring metric variables
2023-03-04 17:09:15,702:INFO:Importing untrained model
2023-03-04 17:09:15,709:INFO:Least Angle Regression Imported successfully
2023-03-04 17:09:15,718:INFO:Starting cross validation
2023-03-04 17:09:15,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:15,816:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,832:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.429e+02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,833:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,842:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.529e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,846:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.368e+02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,846:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.368e+02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,847:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.368e+02, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,847:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.641e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,848:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.368e+02, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,848:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.641e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,851:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.237e+02, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,852:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.220e+02, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,854:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.164e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,855:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.153e+02, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,855:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,856:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.098e+02, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,856:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.098e+02, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,858:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.006e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,859:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.189e+02, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,864:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=8.322e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,865:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=8.322e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,865:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.339e+02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,866:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=8.189e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,866:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,866:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=8.189e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,867:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=8.089e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,867:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=8.089e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,868:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.065e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,869:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.032e+02, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,870:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,871:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=8.224e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,874:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=5.103e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.733e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.427e+02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.577e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,875:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.477e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,876:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.401e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,876:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.398e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,876:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.138e+02, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,877:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.101e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,877:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.946e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,877:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.926e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.641e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.526e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,878:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.511e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.993e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=2.029e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.993e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,879:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.913e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.797e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.298e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,880:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.249e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,881:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.170e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,881:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=6.944e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,881:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.239e+02, with an active set of 96 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.836e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,882:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.170e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,884:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=1.223e+02, with an active set of 101 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,884:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.027e+02, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,884:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.533e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,885:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.458e+02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.022e+05, with an active set of 103 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.051e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.329e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,887:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.242e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,887:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,887:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.232e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.184e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.166e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.147e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,888:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.691e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.122e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.276e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.089e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.691e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.454e+02, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.073e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.691e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,889:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.276e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.050e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.034e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.437e+02, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,890:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.033e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.261e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.941e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,891:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.901e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.837e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.577e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.176e+02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.574e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=1.382e+02, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.859e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,892:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=1.382e+02, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.547e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=1.342e+02, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,893:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=7.848e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.295e+02, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,894:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.215e+02, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,895:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.188e+02, with an active set of 79 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,896:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.063e+02, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,896:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.024e+02, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.854e+01, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.026e+02, with an active set of 83 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,898:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.017e+02, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,898:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=9.657e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.057e+02, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.942e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.182e+04, with an active set of 87 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.942e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.569e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,902:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.941e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.938e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.511e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,903:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.935e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,904:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.220e+04, with an active set of 89 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,905:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.394e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,906:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=9.282e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,906:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=9.128e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,907:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.933e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,907:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.164e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,907:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.930e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.876e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.863e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,908:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.061e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,909:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.061e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,909:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.806e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,909:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.806e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.008e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.777e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.763e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.245e+02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,910:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.757e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.740e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.700e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,911:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.696e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=9.927e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.684e+03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=9.927e+01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.358e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.181e+04, with an active set of 95 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.846e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=6.680e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.846e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=6.676e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=8.799e+01, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.846e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=6.410e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=6.344e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=6.335e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:15,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=6.316e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=2.396e+04, with an active set of 97 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=8.806e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=3.952e+03, with an active set of 97 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.517e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.517e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,915:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.428e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,916:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=8.629e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,916:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=8.629e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=7.072e+03, with an active set of 99 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.249e+04, with an active set of 100 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=7.243e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,917:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=7.318e+01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,918:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.961e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,918:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.130e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,919:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.069e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,919:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.859e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,919:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=6.781e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,919:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.859e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,919:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=6.717e+04, with an active set of 103 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,920:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=6.561e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,920:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.859e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,920:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.495e+07, with an active set of 102 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,920:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.875e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.473e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.256e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=7.946e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,921:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.352e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.220e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.228e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.348e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.205e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.228e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=5.594e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,922:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.197e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.332e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.180e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.267e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.172e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.830e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.266e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,923:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.163e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.149e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.253e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.148e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=4.492e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.234e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.141e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.213e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,924:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.262e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.140e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=4.490e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.209e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.097e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=4.489e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.180e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,925:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.149e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.105e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.055e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.941e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.094e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.025e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.092e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=9.451e+03, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.859e+02, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,926:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.118e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,927:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.084e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,927:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.859e+02, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,927:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.048e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,927:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.021e+06, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,928:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.042e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,928:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.042e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,928:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.880e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,929:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=5.781e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,929:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.595e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,930:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.649e+01, with an active set of 99 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,930:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=6.147e+06, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,932:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.411e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,932:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.411e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.411e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.373e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.765e+03, with an active set of 102 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,933:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.299e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.361e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=3.223e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=9.258e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,934:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.357e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=9.237e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.956e+07, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.889e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.785e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,935:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.687e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=5.099e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.369e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=5.099e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.297e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.513e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.243e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,936:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.365e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.238e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.354e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.227e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.351e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.191e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.494e+07, with an active set of 93 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,937:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.231e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.381e+07, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.367e+07, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=4.202e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=8.115e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,938:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.206e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=4.202e+01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=7.956e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.204e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=7.934e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=7.065e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,939:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=9.690e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=6.896e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.736e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=6.410e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.714e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.716e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.547e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-03-04 17:09:15,940:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=4.418e+01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.691e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.547e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=9.353e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.671e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,941:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.666e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.661e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.402e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.655e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=9.034e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.218e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,942:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.640e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,943:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.630e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,943:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.628e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,943:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.584e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,944:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.112e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,944:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.934e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,944:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.108e+07, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,944:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.934e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,945:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=6.895e+06, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,945:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=6.699e+06, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=2.631e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=3.860e+06, with an active set of 98 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=2.631e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,946:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=2.896e+06, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,947:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.768e+06, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.712e+06, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.437e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=8.141e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.685e+06, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,948:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=2.637e+06, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,949:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.249e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,949:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.379e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,949:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.110e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,950:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.098e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,950:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.084e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,950:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.082e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,951:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.074e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,951:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.060e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,951:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.043e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,951:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=8.651e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,952:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.042e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,952:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=5.567e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,952:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.032e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,952:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.516e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,952:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.030e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.192e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.004e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.740e+02, with an active set of 80 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.188e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.985e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.139e+01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,953:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.917e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,954:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.817e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,954:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.259e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,954:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.817e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,954:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.227e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,954:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=3.523e+05, with an active set of 100 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.315e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.770e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=2.268e+05, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.059e+05, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.770e+01, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.059e+05, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,955:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.100e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.033e+05, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.888e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=9.816e+04, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.888e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=6.623e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,956:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.869e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,957:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.820e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,958:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.064e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,958:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.719e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,958:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.064e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,958:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.706e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,959:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.673e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,959:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.631e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,959:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.465e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,959:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=5.937e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,960:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.378e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,960:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=5.937e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,960:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.189e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.118e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.025e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.768e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.017e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.768e+01, with an active set of 90 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,961:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=9.523e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,962:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=9.406e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,962:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=8.401e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,962:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.724e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,962:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.692e+01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,963:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=7.971e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,963:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.667e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,964:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.260e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,964:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.417e+01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,964:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.586e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,964:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.242e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,965:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.070e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,965:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.932e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,965:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=5.470e+01, with an active set of 94 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,965:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.019e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,966:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.990e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,966:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.287e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,966:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.963e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,966:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.137e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,967:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.085e+01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,967:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.936e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,967:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.850e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,967:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.650e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,968:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.908e+01, with an active set of 96 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,968:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.849e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.630e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.041e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.530e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.005e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.530e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,969:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.952e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,970:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.363e+01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,970:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.848e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,970:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.542e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,970:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.498e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,971:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=7.995e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,971:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=3.487e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,971:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=7.512e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,971:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.900e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,971:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.978e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,972:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.775e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,972:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.484e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,972:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.303e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,972:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.960e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,973:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.938e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,973:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.251e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,973:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.748e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,974:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.933e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,974:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.755e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,974:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.737e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,975:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.497e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,975:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.298e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,975:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.154e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,976:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.915e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,976:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.943e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,976:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=3.009e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,976:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.920e-02, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,977:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=3.008e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,977:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.954e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,977:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.322e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.211e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.181e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.490e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,978:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.487e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,979:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.468e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,979:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.464e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,979:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.464e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,980:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.436e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,980:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.373e+06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,980:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=7.477e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,981:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=7.185e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,981:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=6.941e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,981:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=6.618e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,982:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=5.298e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:15,982:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.704e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,034:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,039:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.150e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,041:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.739e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,041:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.739e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,043:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.030e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,043:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.644e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,044:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.644e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,044:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.491e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,045:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.491e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,045:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.491e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,046:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.932e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,046:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.932e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,047:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.012e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,048:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,048:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.012e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,049:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=6.459e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,049:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.056e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,049:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=5.934e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,051:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=5.651e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,052:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.819e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,052:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.819e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,052:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.819e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,052:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=4.534e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,052:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.227e+02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,053:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.909e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,053:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.909e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,053:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.064e+02, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,054:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.898e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,054:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=3.592e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,054:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=3.592e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,054:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=3.394e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,054:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=3.391e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,055:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=3.274e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,055:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=3.078e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,056:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.507e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,058:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.291e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,058:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.291e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,059:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.265e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,059:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.256e+02, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,059:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=1.609e+05, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,059:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.256e+02, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,060:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.551e+05, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.169e+02, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.222e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.169e+02, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.204e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.195e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.159e+02, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.193e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.167e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.166e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,061:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.162e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.157e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.139e+02, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.155e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.148e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.147e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.139e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.137e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,062:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.132e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,063:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.130e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,063:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.029e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,063:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=9.780e+04, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,063:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=6.092e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,063:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=5.232e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,063:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=4.549e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.090e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.062e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.041e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.037e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.024e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.060e+02, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.023e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,064:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.019e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,065:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.019e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,065:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.012e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,065:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.009e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,065:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.005e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,065:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.001e+04, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,065:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=9.970e+03, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,065:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=9.935e+03, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,066:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=9.935e+03, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,066:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=9.723e+03, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,066:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=4.687e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,067:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.691e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,067:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.668e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,067:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.618e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,068:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.611e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,068:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.583e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,068:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.536e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,068:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.535e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,068:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.533e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,068:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.533e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,068:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.531e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,069:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.515e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,069:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.512e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,069:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.493e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,069:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.485e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,069:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.484e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,069:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.463e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,069:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.403e+03, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,070:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.773e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,070:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.594e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,070:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.572e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,070:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.570e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,070:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.508e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,071:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.501e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,071:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.490e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,071:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.441e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,071:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.419e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,071:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.388e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,071:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.366e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,071:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.332e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,072:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.308e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,072:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.303e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,072:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.288e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,072:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.272e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,072:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.156e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,105:INFO:Calculating mean and std
2023-03-04 17:09:16,106:INFO:Creating metrics dataframe
2023-03-04 17:09:16,110:INFO:Uploading results into container
2023-03-04 17:09:16,111:INFO:Uploading model into container now
2023-03-04 17:09:16,111:INFO:_master_model_container: 5
2023-03-04 17:09:16,111:INFO:_display_container: 2
2023-03-04 17:09:16,111:INFO:Lars(random_state=1516)
2023-03-04 17:09:16,111:INFO:create_model() successfully completed......................................
2023-03-04 17:09:16,217:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:16,217:INFO:Creating metrics dataframe
2023-03-04 17:09:16,226:INFO:Initializing Lasso Least Angle Regression
2023-03-04 17:09:16,226:INFO:Total runtime is 0.1619062344233195 minutes
2023-03-04 17:09:16,229:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:16,230:INFO:Initializing create_model()
2023-03-04 17:09:16,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:16,230:INFO:Checking exceptions
2023-03-04 17:09:16,230:INFO:Importing libraries
2023-03-04 17:09:16,230:INFO:Copying training dataset
2023-03-04 17:09:16,236:INFO:Defining folds
2023-03-04 17:09:16,236:INFO:Declaring metric variables
2023-03-04 17:09:16,240:INFO:Importing untrained model
2023-03-04 17:09:16,245:INFO:Lasso Least Angle Regression Imported successfully
2023-03-04 17:09:16,253:INFO:Starting cross validation
2023-03-04 17:09:16,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:16,343:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,351:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.429e+02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,355:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.894e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,361:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.116e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,366:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.164e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,366:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.164e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,367:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=8.902e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,368:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=8.435e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,369:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.967e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,370:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=7.765e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,372:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=7.647e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,374:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=6.720e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,375:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=6.720e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,376:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=5.621e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=5.426e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=5.123e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,379:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=4.643e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,383:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=4.032e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,383:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=4.032e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,384:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=3.993e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,384:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,384:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=3.813e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,385:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=3.608e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,385:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=3.524e+01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,386:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=3.223e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,387:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=3.029e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,389:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 95 iterations, alpha=4.144e+01, previous alpha=2.707e+01, with an active set of 88 regressors.
  warnings.warn(

2023-03-04 17:09:16,394:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.469e+02, previous alpha=2.443e+02, with an active set of 22 regressors.
  warnings.warn(

2023-03-04 17:09:16,396:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.779e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,396:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.779e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,398:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,398:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.245e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,399:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.141e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,401:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.037e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,402:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.002e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,405:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.883e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,405:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.883e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,406:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.883e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,408:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=7.813e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,409:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.393e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

odel = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,410:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.691e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,410:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.189e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,410:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.691e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,411:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.691e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,411:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.324e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,412:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.324e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,412:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.259e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,413:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=1.454e+02, previous alpha=1.442e+02, with an active set of 37 regressors.
  warnings.warn(

2023-03-04 17:09:16,415:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.454e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,417:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=5.255e+01, previous alpha=5.062e+01, with an active set of 71 regressors.
  warnings.warn(

2023-03-04 17:09:16,417:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,426:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.566e+02, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,426:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.196e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,429:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.859e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,430:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.638e+02, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,430:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.638e+02, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,431:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=9.082e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,431:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=9.082e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,432:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.413e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,432:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=8.689e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,433:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.268e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,433:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.797e+01, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,434:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,435:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.005e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,436:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.941e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,436:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 43 iterations, alpha=1.030e+02, previous alpha=1.005e+02, with an active set of 40 regressors.
  warnings.warn(

2023-03-04 17:09:16,438:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.982e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,439:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=5.875e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,439:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=5.795e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,441:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=5.461e+01, previous alpha=5.340e+01, with an active set of 68 regressors.
  warnings.warn(

2023-03-04 17:09:16,442:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.245e+02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,444:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.846e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,445:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.846e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,445:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.846e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,447:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.428e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,450:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,450:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.130e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,451:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.069e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,453:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.228e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,453:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.228e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,454:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.830e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,456:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.073e+01, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,457:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.941e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,461:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=5.781e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,461:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.922e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,462:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=5.729e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,463:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.660e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,464:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.408e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,465:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.394e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,465:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.394e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,466:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.284e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,466:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.227e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,468:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.090e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,468:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=5.162e+01, previous alpha=4.975e+01, with an active set of 70 regressors.
  warnings.warn(

2023-03-04 17:09:16,470:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.611e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,471:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.611e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,471:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.611e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,472:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.538e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,473:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.538e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,474:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=8.202e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,475:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=8.202e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,476:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.336e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,477:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.336e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,479:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.696e+01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,480:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=6.584e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,481:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=6.968e+01, previous alpha=6.584e+01, with an active set of 65 regressors.
  warnings.warn(

2023-03-04 17:09:16,535:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,540:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:09:16,542:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.150e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,544:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.739e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,544:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.739e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,544:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.816e+02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,546:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.030e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,546:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.644e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,546:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.744e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,546:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.644e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,546:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.744e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,547:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.717e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,547:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.491e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,547:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.491e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,547:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.491e+01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,548:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.293e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,548:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.932e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,548:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.043e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,549:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.606e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,550:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.012e+01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,550:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=8.562e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,550:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=8.562e+01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,551:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=6.459e+01, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,551:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.858e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,551:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.858e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,551:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.056e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,551:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=7.431e+01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,551:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=5.934e+01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,552:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=5.934e+01, previous alpha=5.888e+01, with an active set of 67 regressors.
  warnings.warn(

2023-03-04 17:09:16,552:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.659e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,552:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.659e+01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,553:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.906e+01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,554:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.478e+01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,554:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.049e+01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,554:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.751e+01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,555:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.159e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,555:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.159e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,556:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=3.577e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,556:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=3.577e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,556:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=3.577e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,557:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.391e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,557:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.346e+01, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,558:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.958e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,558:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.958e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,558:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.729e+01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,558:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.464e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,558:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.288e+01, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,559:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.174e+01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,559:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.944e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,559:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.944e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,560:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.522e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,560:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.501e+01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-03-04 17:09:16,560:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 93 iterations, alpha=2.079e+01, previous alpha=1.291e+01, with an active set of 88 regressors.
  warnings.warn(

2023-03-04 17:09:16,593:INFO:Calculating mean and std
2023-03-04 17:09:16,594:INFO:Creating metrics dataframe
2023-03-04 17:09:16,598:INFO:Uploading results into container
2023-03-04 17:09:16,599:INFO:Uploading model into container now
2023-03-04 17:09:16,599:INFO:_master_model_container: 6
2023-03-04 17:09:16,599:INFO:_display_container: 2
2023-03-04 17:09:16,600:INFO:LassoLars(random_state=1516)
2023-03-04 17:09:16,600:INFO:create_model() successfully completed......................................
2023-03-04 17:09:16,705:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:16,705:INFO:Creating metrics dataframe
2023-03-04 17:09:16,713:INFO:Initializing Orthogonal Matching Pursuit
2023-03-04 17:09:16,713:INFO:Total runtime is 0.17002710501352947 minutes
2023-03-04 17:09:16,716:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:16,717:INFO:Initializing create_model()
2023-03-04 17:09:16,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:16,717:INFO:Checking exceptions
2023-03-04 17:09:16,717:INFO:Importing libraries
2023-03-04 17:09:16,717:INFO:Copying training dataset
2023-03-04 17:09:16,725:INFO:Defining folds
2023-03-04 17:09:16,725:INFO:Declaring metric variables
2023-03-04 17:09:16,730:INFO:Importing untrained model
2023-03-04 17:09:16,736:INFO:Orthogonal Matching Pursuit Imported successfully
2023-03-04 17:09:16,747:INFO:Starting cross validation
2023-03-04 17:09:16,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:16,840:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,849:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,871:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,886:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,897:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,906:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,914:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,930:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,981:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:16,988:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:09:17,021:INFO:Calculating mean and std
2023-03-04 17:09:17,023:INFO:Creating metrics dataframe
2023-03-04 17:09:17,026:INFO:Uploading results into container
2023-03-04 17:09:17,026:INFO:Uploading model into container now
2023-03-04 17:09:17,027:INFO:_master_model_container: 7
2023-03-04 17:09:17,027:INFO:_display_container: 2
2023-03-04 17:09:17,027:INFO:OrthogonalMatchingPursuit()
2023-03-04 17:09:17,027:INFO:create_model() successfully completed......................................
2023-03-04 17:09:17,134:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:17,135:INFO:Creating metrics dataframe
2023-03-04 17:09:17,143:INFO:Initializing Bayesian Ridge
2023-03-04 17:09:17,143:INFO:Total runtime is 0.1771912415822347 minutes
2023-03-04 17:09:17,146:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:17,146:INFO:Initializing create_model()
2023-03-04 17:09:17,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:17,147:INFO:Checking exceptions
2023-03-04 17:09:17,147:INFO:Importing libraries
2023-03-04 17:09:17,147:INFO:Copying training dataset
2023-03-04 17:09:17,153:INFO:Defining folds
2023-03-04 17:09:17,154:INFO:Declaring metric variables
2023-03-04 17:09:17,158:INFO:Importing untrained model
2023-03-04 17:09:17,163:INFO:Bayesian Ridge Imported successfully
2023-03-04 17:09:17,172:INFO:Starting cross validation
2023-03-04 17:09:17,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:17,497:INFO:Calculating mean and std
2023-03-04 17:09:17,499:INFO:Creating metrics dataframe
2023-03-04 17:09:17,501:INFO:Uploading results into container
2023-03-04 17:09:17,502:INFO:Uploading model into container now
2023-03-04 17:09:17,502:INFO:_master_model_container: 8
2023-03-04 17:09:17,502:INFO:_display_container: 2
2023-03-04 17:09:17,503:INFO:BayesianRidge()
2023-03-04 17:09:17,503:INFO:create_model() successfully completed......................................
2023-03-04 17:09:17,612:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:17,613:INFO:Creating metrics dataframe
2023-03-04 17:09:17,621:INFO:Initializing Passive Aggressive Regressor
2023-03-04 17:09:17,621:INFO:Total runtime is 0.1851485331853231 minutes
2023-03-04 17:09:17,624:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:17,625:INFO:Initializing create_model()
2023-03-04 17:09:17,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:17,625:INFO:Checking exceptions
2023-03-04 17:09:17,625:INFO:Importing libraries
2023-03-04 17:09:17,625:INFO:Copying training dataset
2023-03-04 17:09:17,631:INFO:Defining folds
2023-03-04 17:09:17,632:INFO:Declaring metric variables
2023-03-04 17:09:17,636:INFO:Importing untrained model
2023-03-04 17:09:17,639:INFO:Passive Aggressive Regressor Imported successfully
2023-03-04 17:09:17,649:INFO:Starting cross validation
2023-03-04 17:09:17,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:17,922:INFO:Calculating mean and std
2023-03-04 17:09:17,924:INFO:Creating metrics dataframe
2023-03-04 17:09:17,927:INFO:Uploading results into container
2023-03-04 17:09:17,928:INFO:Uploading model into container now
2023-03-04 17:09:17,928:INFO:_master_model_container: 9
2023-03-04 17:09:17,928:INFO:_display_container: 2
2023-03-04 17:09:17,929:INFO:PassiveAggressiveRegressor(random_state=1516)
2023-03-04 17:09:17,929:INFO:create_model() successfully completed......................................
2023-03-04 17:09:18,031:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:18,031:INFO:Creating metrics dataframe
2023-03-04 17:09:18,043:INFO:Initializing Huber Regressor
2023-03-04 17:09:18,044:INFO:Total runtime is 0.1921974539756775 minutes
2023-03-04 17:09:18,047:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:18,047:INFO:Initializing create_model()
2023-03-04 17:09:18,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:18,048:INFO:Checking exceptions
2023-03-04 17:09:18,048:INFO:Importing libraries
2023-03-04 17:09:18,048:INFO:Copying training dataset
2023-03-04 17:09:18,054:INFO:Defining folds
2023-03-04 17:09:18,054:INFO:Declaring metric variables
2023-03-04 17:09:18,057:INFO:Importing untrained model
2023-03-04 17:09:18,062:INFO:Huber Regressor Imported successfully
2023-03-04 17:09:18,070:INFO:Starting cross validation
2023-03-04 17:09:18,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:18,304:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,319:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,371:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,421:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,422:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,460:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,460:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,865:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,870:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-04 17:09:18,897:INFO:Calculating mean and std
2023-03-04 17:09:18,898:INFO:Creating metrics dataframe
2023-03-04 17:09:18,901:INFO:Uploading results into container
2023-03-04 17:09:18,902:INFO:Uploading model into container now
2023-03-04 17:09:18,902:INFO:_master_model_container: 10
2023-03-04 17:09:18,902:INFO:_display_container: 2
2023-03-04 17:09:18,903:INFO:HuberRegressor()
2023-03-04 17:09:18,903:INFO:create_model() successfully completed......................................
2023-03-04 17:09:19,007:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:19,007:INFO:Creating metrics dataframe
2023-03-04 17:09:19,017:INFO:Initializing K Neighbors Regressor
2023-03-04 17:09:19,017:INFO:Total runtime is 0.2084206541379293 minutes
2023-03-04 17:09:19,020:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:19,020:INFO:Initializing create_model()
2023-03-04 17:09:19,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:19,020:INFO:Checking exceptions
2023-03-04 17:09:19,021:INFO:Importing libraries
2023-03-04 17:09:19,021:INFO:Copying training dataset
2023-03-04 17:09:19,027:INFO:Defining folds
2023-03-04 17:09:19,027:INFO:Declaring metric variables
2023-03-04 17:09:19,031:INFO:Importing untrained model
2023-03-04 17:09:19,035:INFO:K Neighbors Regressor Imported successfully
2023-03-04 17:09:19,046:INFO:Starting cross validation
2023-03-04 17:09:19,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:19,349:INFO:Calculating mean and std
2023-03-04 17:09:19,351:INFO:Creating metrics dataframe
2023-03-04 17:09:19,354:INFO:Uploading results into container
2023-03-04 17:09:19,354:INFO:Uploading model into container now
2023-03-04 17:09:19,354:INFO:_master_model_container: 11
2023-03-04 17:09:19,355:INFO:_display_container: 2
2023-03-04 17:09:19,355:INFO:KNeighborsRegressor(n_jobs=-1)
2023-03-04 17:09:19,355:INFO:create_model() successfully completed......................................
2023-03-04 17:09:19,459:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:19,459:INFO:Creating metrics dataframe
2023-03-04 17:09:19,469:INFO:Initializing Decision Tree Regressor
2023-03-04 17:09:19,469:INFO:Total runtime is 0.21595194737116497 minutes
2023-03-04 17:09:19,472:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:19,473:INFO:Initializing create_model()
2023-03-04 17:09:19,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:19,473:INFO:Checking exceptions
2023-03-04 17:09:19,473:INFO:Importing libraries
2023-03-04 17:09:19,473:INFO:Copying training dataset
2023-03-04 17:09:19,480:INFO:Defining folds
2023-03-04 17:09:19,480:INFO:Declaring metric variables
2023-03-04 17:09:19,484:INFO:Importing untrained model
2023-03-04 17:09:19,488:INFO:Decision Tree Regressor Imported successfully
2023-03-04 17:09:19,497:INFO:Starting cross validation
2023-03-04 17:09:19,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:19,784:INFO:Calculating mean and std
2023-03-04 17:09:19,786:INFO:Creating metrics dataframe
2023-03-04 17:09:19,789:INFO:Uploading results into container
2023-03-04 17:09:19,789:INFO:Uploading model into container now
2023-03-04 17:09:19,789:INFO:_master_model_container: 12
2023-03-04 17:09:19,790:INFO:_display_container: 2
2023-03-04 17:09:19,790:INFO:DecisionTreeRegressor(random_state=1516)
2023-03-04 17:09:19,790:INFO:create_model() successfully completed......................................
2023-03-04 17:09:19,907:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:19,907:INFO:Creating metrics dataframe
2023-03-04 17:09:19,918:INFO:Initializing Random Forest Regressor
2023-03-04 17:09:19,918:INFO:Total runtime is 0.22343307733535767 minutes
2023-03-04 17:09:19,921:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:19,921:INFO:Initializing create_model()
2023-03-04 17:09:19,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:19,921:INFO:Checking exceptions
2023-03-04 17:09:19,921:INFO:Importing libraries
2023-03-04 17:09:19,922:INFO:Copying training dataset
2023-03-04 17:09:19,930:INFO:Defining folds
2023-03-04 17:09:19,930:INFO:Declaring metric variables
2023-03-04 17:09:19,934:INFO:Importing untrained model
2023-03-04 17:09:19,940:INFO:Random Forest Regressor Imported successfully
2023-03-04 17:09:19,951:INFO:Starting cross validation
2023-03-04 17:09:19,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:21,713:INFO:Calculating mean and std
2023-03-04 17:09:21,715:INFO:Creating metrics dataframe
2023-03-04 17:09:21,718:INFO:Uploading results into container
2023-03-04 17:09:21,718:INFO:Uploading model into container now
2023-03-04 17:09:21,718:INFO:_master_model_container: 13
2023-03-04 17:09:21,719:INFO:_display_container: 2
2023-03-04 17:09:21,719:INFO:RandomForestRegressor(n_jobs=-1, random_state=1516)
2023-03-04 17:09:21,719:INFO:create_model() successfully completed......................................
2023-03-04 17:09:21,823:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:21,823:INFO:Creating metrics dataframe
2023-03-04 17:09:21,833:INFO:Initializing Extra Trees Regressor
2023-03-04 17:09:21,834:INFO:Total runtime is 0.25536471605300903 minutes
2023-03-04 17:09:21,837:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:21,837:INFO:Initializing create_model()
2023-03-04 17:09:21,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:21,837:INFO:Checking exceptions
2023-03-04 17:09:21,837:INFO:Importing libraries
2023-03-04 17:09:21,837:INFO:Copying training dataset
2023-03-04 17:09:21,843:INFO:Defining folds
2023-03-04 17:09:21,844:INFO:Declaring metric variables
2023-03-04 17:09:21,849:INFO:Importing untrained model
2023-03-04 17:09:21,854:INFO:Extra Trees Regressor Imported successfully
2023-03-04 17:09:21,863:INFO:Starting cross validation
2023-03-04 17:09:21,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:23,708:INFO:Calculating mean and std
2023-03-04 17:09:23,709:INFO:Creating metrics dataframe
2023-03-04 17:09:23,712:INFO:Uploading results into container
2023-03-04 17:09:23,712:INFO:Uploading model into container now
2023-03-04 17:09:23,713:INFO:_master_model_container: 14
2023-03-04 17:09:23,713:INFO:_display_container: 2
2023-03-04 17:09:23,713:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1516)
2023-03-04 17:09:23,714:INFO:create_model() successfully completed......................................
2023-03-04 17:09:23,827:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:23,827:INFO:Creating metrics dataframe
2023-03-04 17:09:23,838:INFO:Initializing AdaBoost Regressor
2023-03-04 17:09:23,838:INFO:Total runtime is 0.288770866394043 minutes
2023-03-04 17:09:23,842:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:23,842:INFO:Initializing create_model()
2023-03-04 17:09:23,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:23,843:INFO:Checking exceptions
2023-03-04 17:09:23,843:INFO:Importing libraries
2023-03-04 17:09:23,843:INFO:Copying training dataset
2023-03-04 17:09:23,849:INFO:Defining folds
2023-03-04 17:09:23,849:INFO:Declaring metric variables
2023-03-04 17:09:23,853:INFO:Importing untrained model
2023-03-04 17:09:23,857:INFO:AdaBoost Regressor Imported successfully
2023-03-04 17:09:23,866:INFO:Starting cross validation
2023-03-04 17:09:23,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:25,027:INFO:Calculating mean and std
2023-03-04 17:09:25,029:INFO:Creating metrics dataframe
2023-03-04 17:09:25,034:INFO:Uploading results into container
2023-03-04 17:09:25,035:INFO:Uploading model into container now
2023-03-04 17:09:25,035:INFO:_master_model_container: 15
2023-03-04 17:09:25,035:INFO:_display_container: 2
2023-03-04 17:09:25,036:INFO:AdaBoostRegressor(random_state=1516)
2023-03-04 17:09:25,036:INFO:create_model() successfully completed......................................
2023-03-04 17:09:25,140:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:25,140:INFO:Creating metrics dataframe
2023-03-04 17:09:25,152:INFO:Initializing Gradient Boosting Regressor
2023-03-04 17:09:25,152:INFO:Total runtime is 0.310664439201355 minutes
2023-03-04 17:09:25,156:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:25,157:INFO:Initializing create_model()
2023-03-04 17:09:25,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:25,157:INFO:Checking exceptions
2023-03-04 17:09:25,157:INFO:Importing libraries
2023-03-04 17:09:25,157:INFO:Copying training dataset
2023-03-04 17:09:25,163:INFO:Defining folds
2023-03-04 17:09:25,163:INFO:Declaring metric variables
2023-03-04 17:09:25,169:INFO:Importing untrained model
2023-03-04 17:09:25,175:INFO:Gradient Boosting Regressor Imported successfully
2023-03-04 17:09:25,184:INFO:Starting cross validation
2023-03-04 17:09:25,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:26,290:INFO:Calculating mean and std
2023-03-04 17:09:26,292:INFO:Creating metrics dataframe
2023-03-04 17:09:26,296:INFO:Uploading results into container
2023-03-04 17:09:26,296:INFO:Uploading model into container now
2023-03-04 17:09:26,297:INFO:_master_model_container: 16
2023-03-04 17:09:26,297:INFO:_display_container: 2
2023-03-04 17:09:26,297:INFO:GradientBoostingRegressor(random_state=1516)
2023-03-04 17:09:26,297:INFO:create_model() successfully completed......................................
2023-03-04 17:09:26,410:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:26,410:INFO:Creating metrics dataframe
2023-03-04 17:09:26,427:INFO:Initializing Extreme Gradient Boosting
2023-03-04 17:09:26,427:INFO:Total runtime is 0.3319277763366699 minutes
2023-03-04 17:09:26,431:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:26,431:INFO:Initializing create_model()
2023-03-04 17:09:26,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:26,431:INFO:Checking exceptions
2023-03-04 17:09:26,432:INFO:Importing libraries
2023-03-04 17:09:26,433:INFO:Copying training dataset
2023-03-04 17:09:26,443:INFO:Defining folds
2023-03-04 17:09:26,444:INFO:Declaring metric variables
2023-03-04 17:09:26,447:INFO:Importing untrained model
2023-03-04 17:09:26,456:INFO:Extreme Gradient Boosting Imported successfully
2023-03-04 17:09:26,464:INFO:Starting cross validation
2023-03-04 17:09:26,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:28,740:INFO:Calculating mean and std
2023-03-04 17:09:28,742:INFO:Creating metrics dataframe
2023-03-04 17:09:28,745:INFO:Uploading results into container
2023-03-04 17:09:28,746:INFO:Uploading model into container now
2023-03-04 17:09:28,746:INFO:_master_model_container: 17
2023-03-04 17:09:28,746:INFO:_display_container: 2
2023-03-04 17:09:28,747:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1516, ...)
2023-03-04 17:09:28,747:INFO:create_model() successfully completed......................................
2023-03-04 17:09:28,853:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:28,853:INFO:Creating metrics dataframe
2023-03-04 17:09:28,871:INFO:Initializing Light Gradient Boosting Machine
2023-03-04 17:09:28,871:INFO:Total runtime is 0.3726468841234843 minutes
2023-03-04 17:09:28,875:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:28,876:INFO:Initializing create_model()
2023-03-04 17:09:28,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:28,876:INFO:Checking exceptions
2023-03-04 17:09:28,876:INFO:Importing libraries
2023-03-04 17:09:28,876:INFO:Copying training dataset
2023-03-04 17:09:28,883:INFO:Defining folds
2023-03-04 17:09:28,883:INFO:Declaring metric variables
2023-03-04 17:09:28,889:INFO:Importing untrained model
2023-03-04 17:09:28,895:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-04 17:09:28,905:INFO:Starting cross validation
2023-03-04 17:09:28,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:31,306:INFO:Calculating mean and std
2023-03-04 17:09:31,308:INFO:Creating metrics dataframe
2023-03-04 17:09:31,313:INFO:Uploading results into container
2023-03-04 17:09:31,313:INFO:Uploading model into container now
2023-03-04 17:09:31,314:INFO:_master_model_container: 18
2023-03-04 17:09:31,314:INFO:_display_container: 2
2023-03-04 17:09:31,314:INFO:LGBMRegressor(random_state=1516)
2023-03-04 17:09:31,314:INFO:create_model() successfully completed......................................
2023-03-04 17:09:31,430:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:31,431:INFO:Creating metrics dataframe
2023-03-04 17:09:31,445:INFO:Initializing Dummy Regressor
2023-03-04 17:09:31,446:INFO:Total runtime is 0.41556534767150877 minutes
2023-03-04 17:09:31,451:INFO:SubProcess create_model() called ==================================
2023-03-04 17:09:31,451:INFO:Initializing create_model()
2023-03-04 17:09:31,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011BD2B364F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:31,451:INFO:Checking exceptions
2023-03-04 17:09:31,452:INFO:Importing libraries
2023-03-04 17:09:31,452:INFO:Copying training dataset
2023-03-04 17:09:31,462:INFO:Defining folds
2023-03-04 17:09:31,462:INFO:Declaring metric variables
2023-03-04 17:09:31,467:INFO:Importing untrained model
2023-03-04 17:09:31,473:INFO:Dummy Regressor Imported successfully
2023-03-04 17:09:31,483:INFO:Starting cross validation
2023-03-04 17:09:31,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:09:31,819:INFO:Calculating mean and std
2023-03-04 17:09:31,821:INFO:Creating metrics dataframe
2023-03-04 17:09:31,825:INFO:Uploading results into container
2023-03-04 17:09:31,826:INFO:Uploading model into container now
2023-03-04 17:09:31,827:INFO:_master_model_container: 19
2023-03-04 17:09:31,827:INFO:_display_container: 2
2023-03-04 17:09:31,827:INFO:DummyRegressor()
2023-03-04 17:09:31,827:INFO:create_model() successfully completed......................................
2023-03-04 17:09:31,947:INFO:SubProcess create_model() end ==================================
2023-03-04 17:09:31,947:INFO:Creating metrics dataframe
2023-03-04 17:09:31,974:INFO:Initializing create_model()
2023-03-04 17:09:31,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=Ridge(random_state=1516), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:09:31,974:INFO:Checking exceptions
2023-03-04 17:09:31,977:INFO:Importing libraries
2023-03-04 17:09:31,977:INFO:Copying training dataset
2023-03-04 17:09:31,983:INFO:Defining folds
2023-03-04 17:09:31,983:INFO:Declaring metric variables
2023-03-04 17:09:31,983:INFO:Importing untrained model
2023-03-04 17:09:31,983:INFO:Declaring custom model
2023-03-04 17:09:31,984:INFO:Ridge Regression Imported successfully
2023-03-04 17:09:31,985:INFO:Cross validation set to False
2023-03-04 17:09:31,985:INFO:Fitting Model
2023-03-04 17:09:32,035:INFO:Ridge(random_state=1516)
2023-03-04 17:09:32,035:INFO:create_model() successfully completed......................................
2023-03-04 17:09:32,202:INFO:_master_model_container: 19
2023-03-04 17:09:32,203:INFO:_display_container: 2
2023-03-04 17:09:32,203:INFO:Ridge(random_state=1516)
2023-03-04 17:09:32,203:INFO:compare_models() successfully completed......................................
2023-03-04 17:09:32,214:INFO:Initializing evaluate_model()
2023-03-04 17:09:32,214:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=Ridge(random_state=1516), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-03-04 17:09:32,243:INFO:Initializing plot_model()
2023-03-04 17:09:32,244:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Ridge(random_state=1516), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, system=True)
2023-03-04 17:09:32,244:INFO:Checking exceptions
2023-03-04 17:09:32,247:INFO:Preloading libraries
2023-03-04 17:09:32,247:INFO:Copying training dataset
2023-03-04 17:09:32,247:INFO:Plot type: pipeline
2023-03-04 17:09:32,334:INFO:Visual Rendered Successfully
2023-03-04 17:09:32,449:INFO:plot_model() successfully completed......................................
2023-03-04 17:09:32,460:INFO:Initializing predict_model()
2023-03-04 17:09:32,460:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=Ridge(random_state=1516), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000011BD25959D0>)
2023-03-04 17:09:32,460:INFO:Checking exceptions
2023-03-04 17:09:32,461:INFO:Preloading libraries
2023-03-04 17:09:32,463:INFO:Set up data.
2023-03-04 17:11:02,952:INFO:Initializing predict_model()
2023-03-04 17:11:02,952:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=Ridge(random_state=1516), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000011BD36131F0>)
2023-03-04 17:11:02,952:INFO:Checking exceptions
2023-03-04 17:11:02,952:INFO:Preloading libraries
2023-03-04 17:11:02,955:INFO:Set up data.
2023-03-04 17:13:19,328:INFO:Initializing predict_model()
2023-03-04 17:13:19,328:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=Ridge(random_state=1516), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000011BD3613D30>)
2023-03-04 17:13:19,329:INFO:Checking exceptions
2023-03-04 17:13:19,329:INFO:Preloading libraries
2023-03-04 17:13:19,331:INFO:Set up data.
2023-03-04 17:13:19,363:INFO:Set up index.
2023-03-04 17:25:59,530:INFO:Initializing predict_model()
2023-03-04 17:25:59,530:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011BC14B3A60>, estimator=Ridge(random_state=1516), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000011BD2C70310>)
2023-03-04 17:25:59,530:INFO:Checking exceptions
2023-03-04 17:25:59,530:INFO:Preloading libraries
2023-03-04 17:25:59,533:INFO:Set up data.
2023-03-04 17:25:59,574:INFO:Set up index.
2023-03-04 17:42:39,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 17:42:39,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 17:42:39,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 17:42:39,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-04 17:42:40,118:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-04 17:42:48,044:INFO:PyCaret RegressionExperiment
2023-03-04 17:42:48,044:INFO:Logging name: reg-default-name
2023-03-04 17:42:48,044:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-04 17:42:48,044:INFO:version 3.0.0.rc9
2023-03-04 17:42:48,044:INFO:Initializing setup()
2023-03-04 17:42:48,044:INFO:self.USI: 9cf2
2023-03-04 17:42:48,044:INFO:self._variable_keys: {'seed', 'transform_target_param', 'fold_groups_param', 'fold_generator', 'memory', 'fold_shuffle_param', 'USI', 'y_train', 'y', 'X_train', 'data', 'gpu_n_jobs_param', 'y_test', 'html_param', 'exp_name_log', 'X_test', 'target_param', 'log_plots_param', 'exp_id', '_available_plots', '_ml_usecase', 'idx', 'pipeline', 'gpu_param', 'n_jobs_param', 'logging_param', 'X'}
2023-03-04 17:42:48,044:INFO:Checking environment
2023-03-04 17:42:48,044:INFO:python_version: 3.9.13
2023-03-04 17:42:48,044:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-04 17:42:48,044:INFO:machine: AMD64
2023-03-04 17:42:48,044:INFO:platform: Windows-10-10.0.19044-SP0
2023-03-04 17:42:48,045:INFO:Memory: svmem(total=17009516544, available=4563148800, percent=73.2, used=12446367744, free=4563148800)
2023-03-04 17:42:48,045:INFO:Physical Core: 4
2023-03-04 17:42:48,045:INFO:Logical Core: 8
2023-03-04 17:42:48,045:INFO:Checking libraries
2023-03-04 17:42:48,045:INFO:System:
2023-03-04 17:42:48,045:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-04 17:42:48,045:INFO:executable: C:\Users\Alvaro\anaconda3\python.exe
2023-03-04 17:42:48,045:INFO:   machine: Windows-10-10.0.19044-SP0
2023-03-04 17:42:48,045:INFO:PyCaret required dependencies:
2023-03-04 17:42:48,045:INFO:                 pip: 22.2.2
2023-03-04 17:42:48,045:INFO:          setuptools: 63.4.1
2023-03-04 17:42:48,045:INFO:             pycaret: 3.0.0rc9
2023-03-04 17:42:48,045:INFO:             IPython: 7.31.1
2023-03-04 17:42:48,045:INFO:          ipywidgets: 7.6.5
2023-03-04 17:42:48,045:INFO:                tqdm: 4.64.1
2023-03-04 17:42:48,045:INFO:               numpy: 1.21.5
2023-03-04 17:42:48,046:INFO:              pandas: 1.4.4
2023-03-04 17:42:48,046:INFO:              jinja2: 2.11.3
2023-03-04 17:42:48,046:INFO:               scipy: 1.9.1
2023-03-04 17:42:48,046:INFO:              joblib: 1.2.0
2023-03-04 17:42:48,046:INFO:             sklearn: 1.0.2
2023-03-04 17:42:48,046:INFO:                pyod: 1.0.7
2023-03-04 17:42:48,046:INFO:            imblearn: 0.10.1
2023-03-04 17:42:48,046:INFO:   category_encoders: 2.6.0
2023-03-04 17:42:48,046:INFO:            lightgbm: 3.3.5
2023-03-04 17:42:48,046:INFO:               numba: 0.55.1
2023-03-04 17:42:48,046:INFO:            requests: 2.28.1
2023-03-04 17:42:48,046:INFO:          matplotlib: 3.5.2
2023-03-04 17:42:48,046:INFO:          scikitplot: 0.3.7
2023-03-04 17:42:48,046:INFO:         yellowbrick: 1.5
2023-03-04 17:42:48,046:INFO:              plotly: 5.9.0
2023-03-04 17:42:48,046:INFO:             kaleido: 0.2.1
2023-03-04 17:42:48,046:INFO:         statsmodels: 0.13.2
2023-03-04 17:42:48,046:INFO:              sktime: 0.16.1
2023-03-04 17:42:48,047:INFO:               tbats: 1.1.2
2023-03-04 17:42:48,047:INFO:            pmdarima: 2.0.2
2023-03-04 17:42:48,047:INFO:              psutil: 5.9.0
2023-03-04 17:42:48,047:INFO:PyCaret optional dependencies:
2023-03-04 17:42:48,068:INFO:                shap: Not installed
2023-03-04 17:42:48,069:INFO:           interpret: Not installed
2023-03-04 17:42:48,069:INFO:                umap: Not installed
2023-03-04 17:42:48,069:INFO:    pandas_profiling: Not installed
2023-03-04 17:42:48,069:INFO:  explainerdashboard: Not installed
2023-03-04 17:42:48,069:INFO:             autoviz: Not installed
2023-03-04 17:42:48,069:INFO:           fairlearn: Not installed
2023-03-04 17:42:48,069:INFO:             xgboost: 1.7.4
2023-03-04 17:42:48,069:INFO:            catboost: Not installed
2023-03-04 17:42:48,069:INFO:              kmodes: Not installed
2023-03-04 17:42:48,069:INFO:             mlxtend: Not installed
2023-03-04 17:42:48,069:INFO:       statsforecast: Not installed
2023-03-04 17:42:48,069:INFO:        tune_sklearn: Not installed
2023-03-04 17:42:48,069:INFO:                 ray: Not installed
2023-03-04 17:42:48,069:INFO:            hyperopt: Not installed
2023-03-04 17:42:48,069:INFO:              optuna: Not installed
2023-03-04 17:42:48,069:INFO:               skopt: Not installed
2023-03-04 17:42:48,069:INFO:              mlflow: Not installed
2023-03-04 17:42:48,069:INFO:              gradio: Not installed
2023-03-04 17:42:48,069:INFO:             fastapi: Not installed
2023-03-04 17:42:48,069:INFO:             uvicorn: Not installed
2023-03-04 17:42:48,069:INFO:              m2cgen: Not installed
2023-03-04 17:42:48,069:INFO:           evidently: Not installed
2023-03-04 17:42:48,069:INFO:               fugue: Not installed
2023-03-04 17:42:48,069:INFO:           streamlit: Not installed
2023-03-04 17:42:48,070:INFO:             prophet: Not installed
2023-03-04 17:42:48,070:INFO:None
2023-03-04 17:42:48,070:INFO:Set up data.
2023-03-04 17:42:48,076:INFO:Set up train/test split.
2023-03-04 17:42:48,081:INFO:Set up index.
2023-03-04 17:42:48,081:INFO:Set up folding strategy.
2023-03-04 17:42:48,081:INFO:Assigning column types.
2023-03-04 17:42:48,084:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-04 17:42:48,084:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,088:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,092:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,153:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,195:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,230:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,237:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,244:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,342:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,343:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,346:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-04 17:42:48,350:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,354:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,448:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,455:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,460:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,555:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,557:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-04 17:42:48,566:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,619:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,661:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,672:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,764:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,767:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-04 17:42:48,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,868:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,869:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-04 17:42:48,973:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:48,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:48,976:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-04 17:42:49,037:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:49,078:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:49,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:49,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-04 17:42:49,184:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:49,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:49,187:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-04 17:42:49,296:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:49,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:49,403:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:49,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:49,407:INFO:Preparing preprocessing pipeline...
2023-03-04 17:42:49,408:INFO:Set up simple imputation.
2023-03-04 17:42:49,410:INFO:Set up encoding of categorical features.
2023-03-04 17:42:49,503:INFO:Finished creating preprocessing pipeline.
2023-03-04 17:42:49,513:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Alvaro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['work_year', 'remote_ratio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['experience_level',
                                             'employment_type', 'job_title',
                                             'employee_residence',
                                             'company_location',
                                             'company_size'],
                                    t...
                                    transformer=OneHotEncoder(cols=['experience_level',
                                                                    'employment_type',
                                                                    'company_size'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['job_title', 'employee_residence',
                                             'company_location'],
                                    transformer=LeaveOneOutEncoder(cols=['job_title',
                                                                         'employee_residence',
                                                                         'company_location'],
                                                                   handle_missing='return_nan',
                                                                   random_state=4226)))])
2023-03-04 17:42:49,513:INFO:Creating final display dataframe.
2023-03-04 17:42:49,919:INFO:Setup _display_container:                     Description             Value
0                    Session id              4226
1                        Target     salary_in_usd
2                   Target type        Regression
3           Original data shape          (500, 9)
4        Transformed data shape         (500, 17)
5   Transformed train set shape         (350, 17)
6    Transformed test set shape         (150, 17)
7              Numeric features                 2
8          Categorical features                 6
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              9cf2
2023-03-04 17:42:50,044:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:50,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:50,150:INFO:Soft dependency imported: xgboost: 1.7.4
2023-03-04 17:42:50,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-04 17:42:50,153:INFO:setup() successfully completed in 2.14s...............
2023-03-04 17:43:08,538:INFO:Initializing compare_models()
2023-03-04 17:43:08,538:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-03-04 17:43:08,539:INFO:Checking exceptions
2023-03-04 17:43:08,542:INFO:Preparing display monitor
2023-03-04 17:43:08,590:INFO:Initializing Linear Regression
2023-03-04 17:43:08,591:INFO:Total runtime is 1.6641616821289062e-05 minutes
2023-03-04 17:43:08,598:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:08,598:INFO:Initializing create_model()
2023-03-04 17:43:08,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:08,598:INFO:Checking exceptions
2023-03-04 17:43:08,599:INFO:Importing libraries
2023-03-04 17:43:08,599:INFO:Copying training dataset
2023-03-04 17:43:08,606:INFO:Defining folds
2023-03-04 17:43:08,606:INFO:Declaring metric variables
2023-03-04 17:43:08,609:INFO:Importing untrained model
2023-03-04 17:43:08,613:INFO:Linear Regression Imported successfully
2023-03-04 17:43:08,619:INFO:Starting cross validation
2023-03-04 17:43:08,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:17,562:INFO:Calculating mean and std
2023-03-04 17:43:17,563:INFO:Creating metrics dataframe
2023-03-04 17:43:17,566:INFO:Uploading results into container
2023-03-04 17:43:17,567:INFO:Uploading model into container now
2023-03-04 17:43:17,567:INFO:_master_model_container: 1
2023-03-04 17:43:17,568:INFO:_display_container: 2
2023-03-04 17:43:17,568:INFO:LinearRegression(n_jobs=-1)
2023-03-04 17:43:17,568:INFO:create_model() successfully completed......................................
2023-03-04 17:43:17,721:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:17,721:INFO:Creating metrics dataframe
2023-03-04 17:43:17,728:INFO:Initializing Lasso Regression
2023-03-04 17:43:17,728:INFO:Total runtime is 0.15230112473169963 minutes
2023-03-04 17:43:17,731:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:17,732:INFO:Initializing create_model()
2023-03-04 17:43:17,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:17,732:INFO:Checking exceptions
2023-03-04 17:43:17,732:INFO:Importing libraries
2023-03-04 17:43:17,732:INFO:Copying training dataset
2023-03-04 17:43:17,737:INFO:Defining folds
2023-03-04 17:43:17,738:INFO:Declaring metric variables
2023-03-04 17:43:17,741:INFO:Importing untrained model
2023-03-04 17:43:17,745:INFO:Lasso Regression Imported successfully
2023-03-04 17:43:17,753:INFO:Starting cross validation
2023-03-04 17:43:17,755:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:18,532:INFO:Calculating mean and std
2023-03-04 17:43:18,534:INFO:Creating metrics dataframe
2023-03-04 17:43:18,537:INFO:Uploading results into container
2023-03-04 17:43:18,538:INFO:Uploading model into container now
2023-03-04 17:43:18,538:INFO:_master_model_container: 2
2023-03-04 17:43:18,538:INFO:_display_container: 2
2023-03-04 17:43:18,538:INFO:Lasso(random_state=4226)
2023-03-04 17:43:18,538:INFO:create_model() successfully completed......................................
2023-03-04 17:43:18,692:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:18,693:INFO:Creating metrics dataframe
2023-03-04 17:43:18,700:INFO:Initializing Ridge Regression
2023-03-04 17:43:18,700:INFO:Total runtime is 0.16849033832550048 minutes
2023-03-04 17:43:18,703:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:18,704:INFO:Initializing create_model()
2023-03-04 17:43:18,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:18,704:INFO:Checking exceptions
2023-03-04 17:43:18,704:INFO:Importing libraries
2023-03-04 17:43:18,704:INFO:Copying training dataset
2023-03-04 17:43:18,710:INFO:Defining folds
2023-03-04 17:43:18,710:INFO:Declaring metric variables
2023-03-04 17:43:18,713:INFO:Importing untrained model
2023-03-04 17:43:18,717:INFO:Ridge Regression Imported successfully
2023-03-04 17:43:18,724:INFO:Starting cross validation
2023-03-04 17:43:18,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:19,610:INFO:Calculating mean and std
2023-03-04 17:43:19,612:INFO:Creating metrics dataframe
2023-03-04 17:43:19,616:INFO:Uploading results into container
2023-03-04 17:43:19,616:INFO:Uploading model into container now
2023-03-04 17:43:19,617:INFO:_master_model_container: 3
2023-03-04 17:43:19,617:INFO:_display_container: 2
2023-03-04 17:43:19,617:INFO:Ridge(random_state=4226)
2023-03-04 17:43:19,617:INFO:create_model() successfully completed......................................
2023-03-04 17:43:19,794:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:19,794:INFO:Creating metrics dataframe
2023-03-04 17:43:19,803:INFO:Initializing Elastic Net
2023-03-04 17:43:19,803:INFO:Total runtime is 0.18688262303670247 minutes
2023-03-04 17:43:19,806:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:19,806:INFO:Initializing create_model()
2023-03-04 17:43:19,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:19,806:INFO:Checking exceptions
2023-03-04 17:43:19,807:INFO:Importing libraries
2023-03-04 17:43:19,807:INFO:Copying training dataset
2023-03-04 17:43:19,813:INFO:Defining folds
2023-03-04 17:43:19,814:INFO:Declaring metric variables
2023-03-04 17:43:19,819:INFO:Importing untrained model
2023-03-04 17:43:19,824:INFO:Elastic Net Imported successfully
2023-03-04 17:43:19,832:INFO:Starting cross validation
2023-03-04 17:43:19,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:20,825:INFO:Calculating mean and std
2023-03-04 17:43:20,827:INFO:Creating metrics dataframe
2023-03-04 17:43:20,830:INFO:Uploading results into container
2023-03-04 17:43:20,830:INFO:Uploading model into container now
2023-03-04 17:43:20,831:INFO:_master_model_container: 4
2023-03-04 17:43:20,831:INFO:_display_container: 2
2023-03-04 17:43:20,831:INFO:ElasticNet(random_state=4226)
2023-03-04 17:43:20,831:INFO:create_model() successfully completed......................................
2023-03-04 17:43:20,996:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:20,996:INFO:Creating metrics dataframe
2023-03-04 17:43:21,005:INFO:Initializing Least Angle Regression
2023-03-04 17:43:21,005:INFO:Total runtime is 0.20691858132680258 minutes
2023-03-04 17:43:21,008:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:21,009:INFO:Initializing create_model()
2023-03-04 17:43:21,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:21,009:INFO:Checking exceptions
2023-03-04 17:43:21,009:INFO:Importing libraries
2023-03-04 17:43:21,009:INFO:Copying training dataset
2023-03-04 17:43:21,015:INFO:Defining folds
2023-03-04 17:43:21,016:INFO:Declaring metric variables
2023-03-04 17:43:21,020:INFO:Importing untrained model
2023-03-04 17:43:21,026:INFO:Least Angle Regression Imported successfully
2023-03-04 17:43:21,036:INFO:Starting cross validation
2023-03-04 17:43:21,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:21,377:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,377:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,378:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,414:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,429:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,462:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,828:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,845:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:21,909:INFO:Calculating mean and std
2023-03-04 17:43:21,911:INFO:Creating metrics dataframe
2023-03-04 17:43:21,914:INFO:Uploading results into container
2023-03-04 17:43:21,915:INFO:Uploading model into container now
2023-03-04 17:43:21,915:INFO:_master_model_container: 5
2023-03-04 17:43:21,916:INFO:_display_container: 2
2023-03-04 17:43:21,916:INFO:Lars(random_state=4226)
2023-03-04 17:43:21,916:INFO:create_model() successfully completed......................................
2023-03-04 17:43:22,080:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:22,081:INFO:Creating metrics dataframe
2023-03-04 17:43:22,089:INFO:Initializing Lasso Least Angle Regression
2023-03-04 17:43:22,089:INFO:Total runtime is 0.22498721679051717 minutes
2023-03-04 17:43:22,092:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:22,093:INFO:Initializing create_model()
2023-03-04 17:43:22,093:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:22,093:INFO:Checking exceptions
2023-03-04 17:43:22,093:INFO:Importing libraries
2023-03-04 17:43:22,093:INFO:Copying training dataset
2023-03-04 17:43:22,100:INFO:Defining folds
2023-03-04 17:43:22,100:INFO:Declaring metric variables
2023-03-04 17:43:22,104:INFO:Importing untrained model
2023-03-04 17:43:22,109:INFO:Lasso Least Angle Regression Imported successfully
2023-03-04 17:43:22,117:INFO:Starting cross validation
2023-03-04 17:43:22,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:22,441:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,461:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,475:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,493:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,495:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,517:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,555:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,562:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,900:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,913:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-04 17:43:22,974:INFO:Calculating mean and std
2023-03-04 17:43:22,975:INFO:Creating metrics dataframe
2023-03-04 17:43:22,978:INFO:Uploading results into container
2023-03-04 17:43:22,979:INFO:Uploading model into container now
2023-03-04 17:43:22,979:INFO:_master_model_container: 6
2023-03-04 17:43:22,979:INFO:_display_container: 2
2023-03-04 17:43:22,980:INFO:LassoLars(random_state=4226)
2023-03-04 17:43:22,980:INFO:create_model() successfully completed......................................
2023-03-04 17:43:23,142:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:23,142:INFO:Creating metrics dataframe
2023-03-04 17:43:23,151:INFO:Initializing Orthogonal Matching Pursuit
2023-03-04 17:43:23,151:INFO:Total runtime is 0.24267954826354982 minutes
2023-03-04 17:43:23,154:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:23,154:INFO:Initializing create_model()
2023-03-04 17:43:23,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:23,155:INFO:Checking exceptions
2023-03-04 17:43:23,155:INFO:Importing libraries
2023-03-04 17:43:23,155:INFO:Copying training dataset
2023-03-04 17:43:23,160:INFO:Defining folds
2023-03-04 17:43:23,160:INFO:Declaring metric variables
2023-03-04 17:43:23,165:INFO:Importing untrained model
2023-03-04 17:43:23,169:INFO:Orthogonal Matching Pursuit Imported successfully
2023-03-04 17:43:23,178:INFO:Starting cross validation
2023-03-04 17:43:23,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:23,451:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,478:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,491:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,494:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,504:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,545:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,547:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,567:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,906:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,912:WARNING:C:\Users\Alvaro\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-04 17:43:23,975:INFO:Calculating mean and std
2023-03-04 17:43:23,977:INFO:Creating metrics dataframe
2023-03-04 17:43:23,980:INFO:Uploading results into container
2023-03-04 17:43:23,980:INFO:Uploading model into container now
2023-03-04 17:43:23,981:INFO:_master_model_container: 7
2023-03-04 17:43:23,981:INFO:_display_container: 2
2023-03-04 17:43:23,981:INFO:OrthogonalMatchingPursuit()
2023-03-04 17:43:23,981:INFO:create_model() successfully completed......................................
2023-03-04 17:43:24,144:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:24,145:INFO:Creating metrics dataframe
2023-03-04 17:43:24,153:INFO:Initializing Bayesian Ridge
2023-03-04 17:43:24,154:INFO:Total runtime is 0.2593921899795532 minutes
2023-03-04 17:43:24,157:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:24,157:INFO:Initializing create_model()
2023-03-04 17:43:24,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:24,157:INFO:Checking exceptions
2023-03-04 17:43:24,157:INFO:Importing libraries
2023-03-04 17:43:24,157:INFO:Copying training dataset
2023-03-04 17:43:24,163:INFO:Defining folds
2023-03-04 17:43:24,163:INFO:Declaring metric variables
2023-03-04 17:43:24,169:INFO:Importing untrained model
2023-03-04 17:43:24,175:INFO:Bayesian Ridge Imported successfully
2023-03-04 17:43:24,183:INFO:Starting cross validation
2023-03-04 17:43:24,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:24,999:INFO:Calculating mean and std
2023-03-04 17:43:25,001:INFO:Creating metrics dataframe
2023-03-04 17:43:25,004:INFO:Uploading results into container
2023-03-04 17:43:25,005:INFO:Uploading model into container now
2023-03-04 17:43:25,005:INFO:_master_model_container: 8
2023-03-04 17:43:25,005:INFO:_display_container: 2
2023-03-04 17:43:25,005:INFO:BayesianRidge()
2023-03-04 17:43:25,005:INFO:create_model() successfully completed......................................
2023-03-04 17:43:25,164:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:25,164:INFO:Creating metrics dataframe
2023-03-04 17:43:25,175:INFO:Initializing Passive Aggressive Regressor
2023-03-04 17:43:25,175:INFO:Total runtime is 0.2764112869898478 minutes
2023-03-04 17:43:25,180:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:25,181:INFO:Initializing create_model()
2023-03-04 17:43:25,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:25,181:INFO:Checking exceptions
2023-03-04 17:43:25,181:INFO:Importing libraries
2023-03-04 17:43:25,181:INFO:Copying training dataset
2023-03-04 17:43:25,188:INFO:Defining folds
2023-03-04 17:43:25,188:INFO:Declaring metric variables
2023-03-04 17:43:25,192:INFO:Importing untrained model
2023-03-04 17:43:25,198:INFO:Passive Aggressive Regressor Imported successfully
2023-03-04 17:43:25,207:INFO:Starting cross validation
2023-03-04 17:43:25,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:25,998:INFO:Calculating mean and std
2023-03-04 17:43:25,999:INFO:Creating metrics dataframe
2023-03-04 17:43:26,002:INFO:Uploading results into container
2023-03-04 17:43:26,003:INFO:Uploading model into container now
2023-03-04 17:43:26,003:INFO:_master_model_container: 9
2023-03-04 17:43:26,003:INFO:_display_container: 2
2023-03-04 17:43:26,004:INFO:PassiveAggressiveRegressor(random_state=4226)
2023-03-04 17:43:26,004:INFO:create_model() successfully completed......................................
2023-03-04 17:43:26,161:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:26,161:INFO:Creating metrics dataframe
2023-03-04 17:43:26,170:INFO:Initializing Huber Regressor
2023-03-04 17:43:26,171:INFO:Total runtime is 0.293017037709554 minutes
2023-03-04 17:43:26,173:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:26,174:INFO:Initializing create_model()
2023-03-04 17:43:26,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:26,174:INFO:Checking exceptions
2023-03-04 17:43:26,174:INFO:Importing libraries
2023-03-04 17:43:26,174:INFO:Copying training dataset
2023-03-04 17:43:26,180:INFO:Defining folds
2023-03-04 17:43:26,180:INFO:Declaring metric variables
2023-03-04 17:43:26,184:INFO:Importing untrained model
2023-03-04 17:43:26,190:INFO:Huber Regressor Imported successfully
2023-03-04 17:43:26,197:INFO:Starting cross validation
2023-03-04 17:43:26,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:27,072:INFO:Calculating mean and std
2023-03-04 17:43:27,074:INFO:Creating metrics dataframe
2023-03-04 17:43:27,076:INFO:Uploading results into container
2023-03-04 17:43:27,077:INFO:Uploading model into container now
2023-03-04 17:43:27,077:INFO:_master_model_container: 10
2023-03-04 17:43:27,077:INFO:_display_container: 2
2023-03-04 17:43:27,078:INFO:HuberRegressor()
2023-03-04 17:43:27,078:INFO:create_model() successfully completed......................................
2023-03-04 17:43:27,234:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:27,234:INFO:Creating metrics dataframe
2023-03-04 17:43:27,246:INFO:Initializing K Neighbors Regressor
2023-03-04 17:43:27,246:INFO:Total runtime is 0.3109355886777242 minutes
2023-03-04 17:43:27,248:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:27,249:INFO:Initializing create_model()
2023-03-04 17:43:27,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:27,249:INFO:Checking exceptions
2023-03-04 17:43:27,249:INFO:Importing libraries
2023-03-04 17:43:27,249:INFO:Copying training dataset
2023-03-04 17:43:27,256:INFO:Defining folds
2023-03-04 17:43:27,256:INFO:Declaring metric variables
2023-03-04 17:43:27,260:INFO:Importing untrained model
2023-03-04 17:43:27,265:INFO:K Neighbors Regressor Imported successfully
2023-03-04 17:43:27,275:INFO:Starting cross validation
2023-03-04 17:43:27,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:28,095:INFO:Calculating mean and std
2023-03-04 17:43:28,097:INFO:Creating metrics dataframe
2023-03-04 17:43:28,099:INFO:Uploading results into container
2023-03-04 17:43:28,100:INFO:Uploading model into container now
2023-03-04 17:43:28,100:INFO:_master_model_container: 11
2023-03-04 17:43:28,100:INFO:_display_container: 2
2023-03-04 17:43:28,101:INFO:KNeighborsRegressor(n_jobs=-1)
2023-03-04 17:43:28,101:INFO:create_model() successfully completed......................................
2023-03-04 17:43:28,262:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:28,262:INFO:Creating metrics dataframe
2023-03-04 17:43:28,272:INFO:Initializing Decision Tree Regressor
2023-03-04 17:43:28,273:INFO:Total runtime is 0.3280417124430339 minutes
2023-03-04 17:43:28,276:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:28,276:INFO:Initializing create_model()
2023-03-04 17:43:28,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:28,276:INFO:Checking exceptions
2023-03-04 17:43:28,276:INFO:Importing libraries
2023-03-04 17:43:28,276:INFO:Copying training dataset
2023-03-04 17:43:28,281:INFO:Defining folds
2023-03-04 17:43:28,282:INFO:Declaring metric variables
2023-03-04 17:43:28,286:INFO:Importing untrained model
2023-03-04 17:43:28,290:INFO:Decision Tree Regressor Imported successfully
2023-03-04 17:43:28,299:INFO:Starting cross validation
2023-03-04 17:43:28,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:29,242:INFO:Calculating mean and std
2023-03-04 17:43:29,243:INFO:Creating metrics dataframe
2023-03-04 17:43:29,248:INFO:Uploading results into container
2023-03-04 17:43:29,249:INFO:Uploading model into container now
2023-03-04 17:43:29,249:INFO:_master_model_container: 12
2023-03-04 17:43:29,250:INFO:_display_container: 2
2023-03-04 17:43:29,250:INFO:DecisionTreeRegressor(random_state=4226)
2023-03-04 17:43:29,250:INFO:create_model() successfully completed......................................
2023-03-04 17:43:29,428:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:29,428:INFO:Creating metrics dataframe
2023-03-04 17:43:29,440:INFO:Initializing Random Forest Regressor
2023-03-04 17:43:29,440:INFO:Total runtime is 0.3474903305371603 minutes
2023-03-04 17:43:29,444:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:29,444:INFO:Initializing create_model()
2023-03-04 17:43:29,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:29,445:INFO:Checking exceptions
2023-03-04 17:43:29,445:INFO:Importing libraries
2023-03-04 17:43:29,445:INFO:Copying training dataset
2023-03-04 17:43:29,451:INFO:Defining folds
2023-03-04 17:43:29,452:INFO:Declaring metric variables
2023-03-04 17:43:29,457:INFO:Importing untrained model
2023-03-04 17:43:29,462:INFO:Random Forest Regressor Imported successfully
2023-03-04 17:43:29,472:INFO:Starting cross validation
2023-03-04 17:43:29,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:31,922:INFO:Calculating mean and std
2023-03-04 17:43:31,924:INFO:Creating metrics dataframe
2023-03-04 17:43:31,928:INFO:Uploading results into container
2023-03-04 17:43:31,929:INFO:Uploading model into container now
2023-03-04 17:43:31,929:INFO:_master_model_container: 13
2023-03-04 17:43:31,929:INFO:_display_container: 2
2023-03-04 17:43:31,930:INFO:RandomForestRegressor(n_jobs=-1, random_state=4226)
2023-03-04 17:43:31,930:INFO:create_model() successfully completed......................................
2023-03-04 17:43:32,115:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:32,116:INFO:Creating metrics dataframe
2023-03-04 17:43:32,129:INFO:Initializing Extra Trees Regressor
2023-03-04 17:43:32,129:INFO:Total runtime is 0.39230887889862065 minutes
2023-03-04 17:43:32,133:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:32,133:INFO:Initializing create_model()
2023-03-04 17:43:32,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:32,133:INFO:Checking exceptions
2023-03-04 17:43:32,133:INFO:Importing libraries
2023-03-04 17:43:32,133:INFO:Copying training dataset
2023-03-04 17:43:32,140:INFO:Defining folds
2023-03-04 17:43:32,140:INFO:Declaring metric variables
2023-03-04 17:43:32,145:INFO:Importing untrained model
2023-03-04 17:43:32,149:INFO:Extra Trees Regressor Imported successfully
2023-03-04 17:43:32,161:INFO:Starting cross validation
2023-03-04 17:43:32,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:34,625:INFO:Calculating mean and std
2023-03-04 17:43:34,627:INFO:Creating metrics dataframe
2023-03-04 17:43:34,631:INFO:Uploading results into container
2023-03-04 17:43:34,631:INFO:Uploading model into container now
2023-03-04 17:43:34,632:INFO:_master_model_container: 14
2023-03-04 17:43:34,632:INFO:_display_container: 2
2023-03-04 17:43:34,632:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4226)
2023-03-04 17:43:34,632:INFO:create_model() successfully completed......................................
2023-03-04 17:43:34,807:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:34,808:INFO:Creating metrics dataframe
2023-03-04 17:43:34,820:INFO:Initializing AdaBoost Regressor
2023-03-04 17:43:34,820:INFO:Total runtime is 0.4371560136477153 minutes
2023-03-04 17:43:34,823:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:34,823:INFO:Initializing create_model()
2023-03-04 17:43:34,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:34,823:INFO:Checking exceptions
2023-03-04 17:43:34,823:INFO:Importing libraries
2023-03-04 17:43:34,823:INFO:Copying training dataset
2023-03-04 17:43:34,828:INFO:Defining folds
2023-03-04 17:43:34,829:INFO:Declaring metric variables
2023-03-04 17:43:34,833:INFO:Importing untrained model
2023-03-04 17:43:34,839:INFO:AdaBoost Regressor Imported successfully
2023-03-04 17:43:34,848:INFO:Starting cross validation
2023-03-04 17:43:34,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:36,423:INFO:Calculating mean and std
2023-03-04 17:43:36,425:INFO:Creating metrics dataframe
2023-03-04 17:43:36,428:INFO:Uploading results into container
2023-03-04 17:43:36,429:INFO:Uploading model into container now
2023-03-04 17:43:36,429:INFO:_master_model_container: 15
2023-03-04 17:43:36,430:INFO:_display_container: 2
2023-03-04 17:43:36,430:INFO:AdaBoostRegressor(random_state=4226)
2023-03-04 17:43:36,430:INFO:create_model() successfully completed......................................
2023-03-04 17:43:36,604:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:36,604:INFO:Creating metrics dataframe
2023-03-04 17:43:36,619:INFO:Initializing Gradient Boosting Regressor
2023-03-04 17:43:36,619:INFO:Total runtime is 0.467148502667745 minutes
2023-03-04 17:43:36,622:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:36,623:INFO:Initializing create_model()
2023-03-04 17:43:36,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:36,623:INFO:Checking exceptions
2023-03-04 17:43:36,623:INFO:Importing libraries
2023-03-04 17:43:36,623:INFO:Copying training dataset
2023-03-04 17:43:36,629:INFO:Defining folds
2023-03-04 17:43:36,629:INFO:Declaring metric variables
2023-03-04 17:43:36,635:INFO:Importing untrained model
2023-03-04 17:43:36,640:INFO:Gradient Boosting Regressor Imported successfully
2023-03-04 17:43:36,650:INFO:Starting cross validation
2023-03-04 17:43:36,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:38,315:INFO:Calculating mean and std
2023-03-04 17:43:38,318:INFO:Creating metrics dataframe
2023-03-04 17:43:38,321:INFO:Uploading results into container
2023-03-04 17:43:38,322:INFO:Uploading model into container now
2023-03-04 17:43:38,322:INFO:_master_model_container: 16
2023-03-04 17:43:38,322:INFO:_display_container: 2
2023-03-04 17:43:38,323:INFO:GradientBoostingRegressor(random_state=4226)
2023-03-04 17:43:38,323:INFO:create_model() successfully completed......................................
2023-03-04 17:43:38,490:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:38,490:INFO:Creating metrics dataframe
2023-03-04 17:43:38,505:INFO:Initializing Extreme Gradient Boosting
2023-03-04 17:43:38,505:INFO:Total runtime is 0.4985730568567912 minutes
2023-03-04 17:43:38,508:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:38,509:INFO:Initializing create_model()
2023-03-04 17:43:38,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:38,509:INFO:Checking exceptions
2023-03-04 17:43:38,509:INFO:Importing libraries
2023-03-04 17:43:38,509:INFO:Copying training dataset
2023-03-04 17:43:38,516:INFO:Defining folds
2023-03-04 17:43:38,516:INFO:Declaring metric variables
2023-03-04 17:43:38,520:INFO:Importing untrained model
2023-03-04 17:43:38,526:INFO:Extreme Gradient Boosting Imported successfully
2023-03-04 17:43:38,536:INFO:Starting cross validation
2023-03-04 17:43:38,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:40,316:INFO:Calculating mean and std
2023-03-04 17:43:40,318:INFO:Creating metrics dataframe
2023-03-04 17:43:40,322:INFO:Uploading results into container
2023-03-04 17:43:40,322:INFO:Uploading model into container now
2023-03-04 17:43:40,323:INFO:_master_model_container: 17
2023-03-04 17:43:40,323:INFO:_display_container: 2
2023-03-04 17:43:40,324:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=4226, ...)
2023-03-04 17:43:40,324:INFO:create_model() successfully completed......................................
2023-03-04 17:43:40,491:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:40,491:INFO:Creating metrics dataframe
2023-03-04 17:43:40,506:INFO:Initializing Light Gradient Boosting Machine
2023-03-04 17:43:40,506:INFO:Total runtime is 0.531930152575175 minutes
2023-03-04 17:43:40,510:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:40,510:INFO:Initializing create_model()
2023-03-04 17:43:40,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:40,510:INFO:Checking exceptions
2023-03-04 17:43:40,510:INFO:Importing libraries
2023-03-04 17:43:40,510:INFO:Copying training dataset
2023-03-04 17:43:40,516:INFO:Defining folds
2023-03-04 17:43:40,516:INFO:Declaring metric variables
2023-03-04 17:43:40,521:INFO:Importing untrained model
2023-03-04 17:43:40,528:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-04 17:43:40,537:INFO:Starting cross validation
2023-03-04 17:43:40,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:43,842:INFO:Calculating mean and std
2023-03-04 17:43:43,844:INFO:Creating metrics dataframe
2023-03-04 17:43:43,847:INFO:Uploading results into container
2023-03-04 17:43:43,848:INFO:Uploading model into container now
2023-03-04 17:43:43,848:INFO:_master_model_container: 18
2023-03-04 17:43:43,848:INFO:_display_container: 2
2023-03-04 17:43:43,849:INFO:LGBMRegressor(random_state=4226)
2023-03-04 17:43:43,849:INFO:create_model() successfully completed......................................
2023-03-04 17:43:44,017:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:44,017:INFO:Creating metrics dataframe
2023-03-04 17:43:44,031:INFO:Initializing Dummy Regressor
2023-03-04 17:43:44,031:INFO:Total runtime is 0.5906835436820984 minutes
2023-03-04 17:43:44,036:INFO:SubProcess create_model() called ==================================
2023-03-04 17:43:44,036:INFO:Initializing create_model()
2023-03-04 17:43:44,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248FB98F7F0>, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:44,036:INFO:Checking exceptions
2023-03-04 17:43:44,037:INFO:Importing libraries
2023-03-04 17:43:44,037:INFO:Copying training dataset
2023-03-04 17:43:44,045:INFO:Defining folds
2023-03-04 17:43:44,046:INFO:Declaring metric variables
2023-03-04 17:43:44,049:INFO:Importing untrained model
2023-03-04 17:43:44,055:INFO:Dummy Regressor Imported successfully
2023-03-04 17:43:44,063:INFO:Starting cross validation
2023-03-04 17:43:44,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-04 17:43:45,012:INFO:Calculating mean and std
2023-03-04 17:43:45,015:INFO:Creating metrics dataframe
2023-03-04 17:43:45,019:INFO:Uploading results into container
2023-03-04 17:43:45,019:INFO:Uploading model into container now
2023-03-04 17:43:45,020:INFO:_master_model_container: 19
2023-03-04 17:43:45,020:INFO:_display_container: 2
2023-03-04 17:43:45,021:INFO:DummyRegressor()
2023-03-04 17:43:45,021:INFO:create_model() successfully completed......................................
2023-03-04 17:43:45,195:INFO:SubProcess create_model() end ==================================
2023-03-04 17:43:45,196:INFO:Creating metrics dataframe
2023-03-04 17:43:45,221:INFO:Initializing create_model()
2023-03-04 17:43:45,221:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=Ridge(random_state=4226), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-04 17:43:45,222:INFO:Checking exceptions
2023-03-04 17:43:45,224:INFO:Importing libraries
2023-03-04 17:43:45,225:INFO:Copying training dataset
2023-03-04 17:43:45,229:INFO:Defining folds
2023-03-04 17:43:45,229:INFO:Declaring metric variables
2023-03-04 17:43:45,229:INFO:Importing untrained model
2023-03-04 17:43:45,230:INFO:Declaring custom model
2023-03-04 17:43:45,230:INFO:Ridge Regression Imported successfully
2023-03-04 17:43:45,232:INFO:Cross validation set to False
2023-03-04 17:43:45,232:INFO:Fitting Model
2023-03-04 17:43:45,373:INFO:Ridge(random_state=4226)
2023-03-04 17:43:45,373:INFO:create_model() successfully completed......................................
2023-03-04 17:43:45,584:INFO:_master_model_container: 19
2023-03-04 17:43:45,584:INFO:_display_container: 2
2023-03-04 17:43:45,585:INFO:Ridge(random_state=4226)
2023-03-04 17:43:45,585:INFO:compare_models() successfully completed......................................
2023-03-04 17:43:53,975:INFO:Initializing evaluate_model()
2023-03-04 17:43:53,975:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=Ridge(random_state=4226), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-03-04 17:43:54,009:INFO:Initializing plot_model()
2023-03-04 17:43:54,009:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Ridge(random_state=4226), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, system=True)
2023-03-04 17:43:54,010:INFO:Checking exceptions
2023-03-04 17:43:54,013:INFO:Preloading libraries
2023-03-04 17:43:54,014:INFO:Copying training dataset
2023-03-04 17:43:54,015:INFO:Plot type: pipeline
2023-03-04 17:43:54,169:INFO:Visual Rendered Successfully
2023-03-04 17:43:54,323:INFO:plot_model() successfully completed......................................
2023-03-04 17:44:23,109:INFO:Initializing plot_model()
2023-03-04 17:44:23,109:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Ridge(random_state=4226), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, system=True)
2023-03-04 17:44:23,110:INFO:Checking exceptions
2023-03-04 17:44:23,112:INFO:Preloading libraries
2023-03-04 17:44:23,112:INFO:Copying training dataset
2023-03-04 17:44:23,112:INFO:Plot type: parameter
2023-03-04 17:44:23,115:INFO:Visual Rendered Successfully
2023-03-04 17:44:23,282:INFO:plot_model() successfully completed......................................
2023-03-04 17:44:24,351:INFO:Initializing plot_model()
2023-03-04 17:44:24,351:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Ridge(random_state=4226), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, system=True)
2023-03-04 17:44:24,352:INFO:Checking exceptions
2023-03-04 17:44:24,354:INFO:Preloading libraries
2023-03-04 17:44:24,354:INFO:Copying training dataset
2023-03-04 17:44:24,354:INFO:Plot type: learning
2023-03-04 17:44:24,582:INFO:Fitting Model
2023-03-04 17:44:24,988:INFO:Visual Rendered Successfully
2023-03-04 17:44:25,163:INFO:plot_model() successfully completed......................................
2023-03-04 17:46:19,781:INFO:Initializing predict_model()
2023-03-04 17:46:19,781:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248F5A0B940>, estimator=Ridge(random_state=4226), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000248FC96F940>)
2023-03-04 17:46:19,781:INFO:Checking exceptions
2023-03-04 17:46:19,781:INFO:Preloading libraries
2023-03-04 17:46:19,783:INFO:Set up data.
2023-03-04 17:46:19,787:INFO:Set up index.
